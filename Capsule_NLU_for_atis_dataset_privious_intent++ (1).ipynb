{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Capsule_NLU_for_atis_dataset_privious_intent++.ipynb","provenance":[{"file_id":"1Qyh7QBvhqpe_I6aMdEWpMeSsKxRYSXYb","timestamp":1593063567711},{"file_id":"1DCEektoZZ5NyAtlAcYtFQqYpCtwsIO31","timestamp":1593056674185}],"collapsed_sections":[],"mount_file_id":"18jHyWpg5CHpJppfnv6_FGxQRrcly8AaI","authorship_tag":"ABX9TyNwu4lQbRwcBmmTAS94j757"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I5-V0A4GEWyG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"executionInfo":{"status":"ok","timestamp":1595694127704,"user_tz":-330,"elapsed":11661,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"3449ab6c-5b9a-4053-cf24-9897d279fe91"},"source":["!pip install tensorflow==1.14\n","!pip install tensorflow-gpu==1.14"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.30.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (49.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n","Requirement already satisfied: tensorflow-gpu==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.5)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.30.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.12.2)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (49.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oCX3UennU_GG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"ok","timestamp":1595694131287,"user_tz":-330,"elapsed":15232,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"d0f65448-c3a3-4aea-c8c0-df90f4f13327"},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","def margin_loss(labels, raw_logits, margin=0.4, downweight=0.5):\n","    \"\"\"Penalizes deviations from margin for each logit.\n","    Each wrong logit costs its distance to margin. For negative logits margin is\n","    0.1 and for positives it is 0.9. First subtract 0.5 from all logits. Now\n","    margin is 0.4 from each side.\n","    Args:\n","    labels: tensor, one hot encoding of ground truth.\n","    raw_logits: tensor, model predictions in range [0, 1]\n","    margin: scalar, the margin after subtracting 0.5 from raw_logits.\n","    downweight: scalar, the factor for negative cost.\n","    Returns:\n","    A tensor with cost for each data point of shape [batch_size].\n","    \"\"\"\n","    logits = raw_logits - 0.5\n","    positive_cost = labels * tf.cast(tf.less(logits, margin),\n","                                     tf.float32) * tf.pow(logits - margin, 2)\n","    negative_cost = (1 - labels) * tf.cast(\n","        tf.greater(logits, -margin), tf.float32) * tf.pow(logits + margin, 2)\n","    return 0.5 * positive_cost + downweight * 0.5 * negative_cost\n","\n","\n","def createVocabulary(input_path, output_path, pad=True, unk=True):\n","    if not isinstance(input_path, str):\n","        raise TypeError('input_path should be string')\n","\n","    if not isinstance(output_path, str):\n","        raise TypeError('output_path should be string')\n","\n","    vocab = {}\n","    with open(input_path, 'r') as fd, \\\n","            open(output_path, 'w+') as out:\n","        for line in fd:\n","            line = line.rstrip('\\r\\n')\n","            words = line.split()\n","\n","            for w in words:\n","                if w == '_UNK':\n","                    break\n","                if str.isdigit(w) == True:\n","                    w = '0'\n","                if w in vocab:\n","                    vocab[w] += 1\n","                else:\n","                    vocab[w] = 1\n","        init_vocab = []\n","        if pad:\n","            init_vocab.append('_PAD')\n","        if unk:\n","            init_vocab.append('_UNK')\n","        vocab = sorted(vocab, key=vocab.get, reverse=True) + init_vocab\n","\n","        for v in vocab:\n","            out.write(v + '\\n')\n","\n","\n","def loadVocabulary(path):\n","    if not isinstance(path, str):\n","        raise TypeError('path should be a string')\n","\n","    vocab = []\n","    rev = []\n","    with open(path) as fd:\n","        for line in fd:\n","            line = line.rstrip('\\r\\n')\n","            rev.append(line)\n","        vocab = dict([(x, y) for (y, x) in enumerate(rev)])\n","\n","    return {'vocab': vocab, 'rev': rev}\n","\n","\n","def sentenceToIds(data, vocab, unk):\n","    if not isinstance(vocab, dict):\n","        raise TypeError('vocab should be a dict that contains vocab and rev')\n","    vocab = vocab['vocab']\n","    if isinstance(data, str):\n","        words = data.split()\n","    elif isinstance(data, list):\n","        words = data\n","    else:\n","        raise TypeError('data should be a string or a list contains words')\n","\n","    ids = []\n","    if unk:\n","        for w in words:\n","            if str.isdigit(w) == True:\n","                w = '0'\n","            ids.append(vocab.get(w, vocab['_UNK']))\n","    else:\n","        for w in words:\n","            if str.isdigit(w) == True:\n","                w = '0'\n","            ids.append(vocab.get(w))\n","\n","    return ids\n","\n","\n","def padSentence(s, max_length, vocab):\n","    return s + [vocab['vocab']['_PAD']] * (max_length - len(s))\n","\n","\n","# compute f1 score is modified from conlleval.pl\n","def __startOfChunk(prevTag, tag, prevTagType, tagType, chunkStart=False):\n","    if prevTag == 'B' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'I' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'I':\n","        chunkStart = True\n","\n","    if prevTag == 'E' and tag == 'E':\n","        chunkStart = True\n","    if prevTag == 'E' and tag == 'I':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'E':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'I':\n","        chunkStart = True\n","\n","    if tag != 'O' and tag != '.' and prevTagType != tagType:\n","        chunkStart = True\n","    return chunkStart\n","\n","\n","def __endOfChunk(prevTag, tag, prevTagType, tagType, chunkEnd=False):\n","    if prevTag == 'B' and tag == 'B':\n","        chunkEnd = True\n","    if prevTag == 'B' and tag == 'O':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'B':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'O':\n","        chunkEnd = True\n","\n","    if prevTag == 'E' and tag == 'E':\n","        chunkEnd = True\n","    if prevTag == 'E' and tag == 'I':\n","        chunkEnd = True\n","    if prevTag == 'E' and tag == 'O':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'O':\n","        chunkEnd = True\n","\n","    if prevTag != 'O' and prevTag != '.' and prevTagType != tagType:\n","        chunkEnd = True\n","    return chunkEnd\n","\n","\n","def __splitTagType(tag):\n","    s = tag.split('-')\n","    if len(s) > 2 or len(s) == 0:\n","        raise ValueError('tag format wrong. it must be B-xxx.xxx')\n","    if len(s) == 1:\n","        tag = s[0]\n","        tagType = \"\"\n","    else:\n","        tag = s[0]\n","        tagType = s[1]\n","    return tag, tagType\n","\n","\n","def computeF1Score(correct_slots, pred_slots):\n","    correctChunk = {}\n","    correctChunkCnt = 0\n","    foundCorrect = {}\n","    foundCorrectCnt = 0\n","    foundPred = {}\n","    foundPredCnt = 0\n","    correctTags = 0\n","    tokenCount = 0\n","    for correct_slot, pred_slot in zip(correct_slots, pred_slots):\n","        inCorrect = False\n","        lastCorrectTag = 'O'\n","        lastCorrectType = ''\n","        lastPredTag = 'O'\n","        lastPredType = ''\n","        for c, p in zip(correct_slot, pred_slot):\n","            correctTag, correctType = __splitTagType(c)\n","            predTag, predType = __splitTagType(p)\n","\n","            if inCorrect == True:\n","                if __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n","                        __endOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n","                        (lastCorrectType == lastPredType):\n","                    inCorrect = False\n","                    correctChunkCnt += 1\n","                    if lastCorrectType in correctChunk:\n","                        correctChunk[lastCorrectType] += 1\n","                    else:\n","                        correctChunk[lastCorrectType] = 1\n","                elif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) != \\\n","                        __endOfChunk(lastPredTag, predTag, lastPredType, predType) or \\\n","                        (correctType != predType):\n","                    inCorrect = False\n","\n","            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n","                    __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n","                    (correctType == predType):\n","                inCorrect = True\n","\n","            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True:\n","                foundCorrectCnt += 1\n","                if correctType in foundCorrect:\n","                    foundCorrect[correctType] += 1\n","                else:\n","                    foundCorrect[correctType] = 1\n","\n","            if __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True:\n","                foundPredCnt += 1\n","                if predType in foundPred:\n","                    foundPred[predType] += 1\n","                else:\n","                    foundPred[predType] = 1\n","\n","            if correctTag == predTag and correctType == predType:\n","                correctTags += 1\n","\n","            tokenCount += 1\n","\n","            lastCorrectTag = correctTag\n","            lastCorrectType = correctType\n","            lastPredTag = predTag\n","            lastPredType = predType\n","\n","        if inCorrect == True:\n","            correctChunkCnt += 1\n","            if lastCorrectType in correctChunk:\n","                correctChunk[lastCorrectType] += 1\n","            else:\n","                correctChunk[lastCorrectType] = 1\n","\n","    if foundPredCnt > 0:\n","        precision = 100 * correctChunkCnt / foundPredCnt\n","    else:\n","        precision = 0\n","\n","    if foundCorrectCnt > 0:\n","        recall = 100 * correctChunkCnt / foundCorrectCnt\n","    else:\n","        recall = 0\n","\n","    if (precision + recall) > 0:\n","        f1 = (2 * precision * recall) / (precision + recall)\n","    else:\n","        f1 = 0\n","\n","    return f1, precision, recall\n","\n","\n","class DataProcessor(object):\n","    def __init__(self, in_path, slot_path, intent_path, in_vocab, slot_vocab, intent_vocab, shuffle=False):\n","        self.__fd_in = open(in_path, 'r').readlines()\n","        self.__fd_slot = open(slot_path, 'r').readlines()\n","        self.__fd_intent = open(intent_path, 'r').readlines()\n","        if shuffle:\n","            self.shuffle()\n","        self.__in_vocab = in_vocab\n","        self.__slot_vocab = slot_vocab\n","        self.__intent_vocab = intent_vocab\n","        self.end = 0\n","\n","    def close(self):\n","        self.__fd_in.close()\n","        self.__fd_slot.close()\n","        self.__fd_intent.close()\n","\n","    def shuffle(self):\n","        from sklearn.utils import shuffle\n","        self.__fd_in, self.__fd_slot, self.__fd_intent = shuffle(self.__fd_in, self.__fd_slot, self.__fd_intent)\n","\n","    def get_batch(self, batch_size):\n","        in_data = []\n","        slot_data = []\n","        slot_weight = []\n","        length = []\n","        intents = []\n","\n","        batch_in = []\n","        batch_slot = []\n","        max_len = 0\n","\n","        in_seq = []\n","        slot_seq = []\n","        intent_seq = []\n","        temp=''\n","        temp2=''\n","        for i in range(batch_size):\n","            try:\n","                inp = self.__fd_in.pop()\n","            except IndexError:\n","                self.end = 1\n","                break\n","            slot = self.__fd_slot.pop()\n","            intent = self.__fd_intent.pop()\n","            inp = inp.rstrip()\n","            slot = slot.rstrip()\n","            intent = intent.rstrip()\n","            if temp2=='':\n","              in_seq.append(inp)\n","              slot_seq.append(slot)\n","              intent_seq.append(intent)\n","            else:\n","              inp=inp+' '\n","              inp=inp+temp\n","              inp=inp+' '\n","              inp=inp+temp2\n","              in_seq.append(inp)\n","              slot=slot+' O O'\n","              slot_seq.append(slot)\n","              intent_seq.append(intent)\n","            temp2=temp\n","            temp=intent\n","            iii = inp\n","            sss = slot\n","            inp = sentenceToIds(inp, self.__in_vocab, unk=True)\n","            slot = sentenceToIds(slot, self.__slot_vocab, unk=True)\n","            intent = sentenceToIds(intent, self.__intent_vocab, unk=False)\n","            if None not in intent:\n","                batch_in.append(np.array(inp))\n","                batch_slot.append(np.array(slot))\n","                length.append(len(inp))\n","                intents.append(intent[0])\n","            if len(inp) != len(slot):\n","                print(iii, sss)\n","                print(inp, slot)\n","                exit(0)\n","            if len(inp) > max_len:\n","                max_len = len(inp)\n","\n","        length = np.array(length)\n","        intents = np.array(intents)\n","        for i, s in zip(batch_in, batch_slot):\n","            in_data.append(padSentence(list(i), max_len, self.__in_vocab))\n","            slot_data.append(padSentence(list(s), max_len, self.__slot_vocab))\n","\n","        in_data = np.array(in_data)\n","        slot_data = np.array(slot_data)\n","\n","        for s in slot_data:\n","            weight = np.not_equal(s, np.full(s.shape, self._DataProcessor__slot_vocab['vocab']['_PAD']))\n","            weight = weight.astype(np.float32)\n","            slot_weight.append(weight)\n","        slot_weight = np.array(slot_weight)\n","        return in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GZlOXACIVDQ9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595694131289,"user_tz":-330,"elapsed":15202,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\n","\"\"\"## Functions for working with arbitrarily nested sequences of elements.\n","\n","This module can perform operations on nested structures. A nested structure is a\n","Python sequence, tuple (including `namedtuple`), or dict that can contain\n","further sequences, tuples, and dicts.\n","\n","The utilities here assume (and do not check) that the nested structures form a\n","'tree', i.e., no references in the structure of the input of these functions\n","should be recursive.\n","\n","Example structures: `((3, 4), 5, (6, 7, (9, 10), 8))`, `(np.array(0),\n","  (np.array([3, 4]), tf.constant([3, 4])))`\n","\"\"\"\n","\n","import collections as _collections\n","\n","import six as _six\n","\n","\n","def _sorted(dict_):\n","    \"\"\"Returns a sorted list of the dict keys, with error if keys not sortable.\"\"\"\n","    try:\n","        return sorted(_six.iterkeys(dict_))\n","    except TypeError:\n","        raise TypeError(\"nest only supports dicts with sortable keys.\")\n","\n","\n","def _sequence_like(instance, args):\n","    \"\"\"Converts the sequence `args` to the same type as `instance`.\n","\n","    Args:\n","      instance: an instance of `tuple`, `list`, `namedtuple`, `dict`, or\n","          `collections.OrderedDict`.\n","      args: elements to be converted to the `instance` type.\n","\n","    Returns:\n","      `args` with the type of `instance`.\n","    \"\"\"\n","    if isinstance(instance, dict):\n","        # Pack dictionaries in a deterministic order by sorting the keys.\n","        # Notice this means that we ignore the original order of `OrderedDict`\n","        # instances. This is intentional, to avoid potential bugs caused by mixing\n","        # ordered and plain dicts (e.g., flattening a dict but using a\n","        # corresponding `OrderedDict` to pack it back).\n","        result = dict(zip(_sorted(instance), args))\n","        return type(instance)((key, result[key]) for key in _six.iterkeys(instance))\n","    elif (isinstance(instance, tuple) and\n","          hasattr(instance, \"_fields\") and\n","          isinstance(instance._fields, _collections.Sequence) and\n","          all(isinstance(f, _six.string_types) for f in instance._fields)):\n","        # This is a namedtuple\n","        return type(instance)(*args)\n","    else:\n","        # Not a namedtuple\n","        return type(instance)(args)\n","\n","\n","def _yield_value(iterable):\n","    if isinstance(iterable, dict):\n","        # Iterate through dictionaries in a deterministic order by sorting the\n","        # keys. Notice this means that we ignore the original order of `OrderedDict`\n","        # instances. This is intentional, to avoid potential bugs caused by mixing\n","        # ordered and plain dicts (e.g., flattening a dict but using a\n","        # corresponding `OrderedDict` to pack it back).\n","        for key in _sorted(iterable):\n","            yield iterable[key]\n","    else:\n","        for value in iterable:\n","            yield value\n","\n","\n","def _yield_flat_nest(nest):\n","    for n in _yield_value(nest):\n","        if is_sequence(n):\n","            for ni in _yield_flat_nest(n):\n","                yield ni\n","        else:\n","            yield n\n","\n","\n","# Used by `_warn_once` to remember which warning messages have been given.\n","_ALREADY_WARNED = {}\n","\n","\n","def _warn_once(message):\n","    \"\"\"Logs a warning message, once per unique string.\"\"\"\n","    if message not in _ALREADY_WARNED:\n","        _ALREADY_WARNED[message] = True\n","\n","\n","def is_sequence(seq):\n","    \"\"\"Returns a true if its input is a collections.Sequence (except strings).\n","\n","    Args:\n","      seq: an input sequence.\n","\n","    Returns:\n","      True if the sequence is a not a string and is a collections.Sequence or a\n","      dict.\n","    \"\"\"\n","    if isinstance(seq, dict):\n","        return True\n","    if isinstance(seq, set):\n","        _warn_once(\"Sets are not currently considered sequences, but this may \"\n","                   \"change in the future, so consider avoiding using them.\")\n","    return (isinstance(seq, _collections.Sequence)\n","            and not isinstance(seq, _six.string_types))\n","\n","\n","def flatten(nest):\n","    \"\"\"Returns a flat list from a given nested structure.\n","\n","    If `nest` is not a sequence, tuple, or dict, then returns a single-element\n","    list: `[nest]`.\n","\n","    In the case of dict instances, the sequence consists of the values, sorted by\n","    key to ensure deterministic behavior. This is true also for `OrderedDict`\n","    instances: their sequence order is ignored, the sorting order of keys is\n","    used instead. The same convention is followed in `pack_sequence_as`. This\n","    correctly repacks dicts and `OrderedDict`s after they have been flattened,\n","    and also allows flattening an `OrderedDict` and then repacking it back using\n","    a correponding plain dict, or vice-versa.\n","    Dictionaries with non-sortable keys cannot be flattened.\n","\n","    Args:\n","      nest: an arbitrarily nested structure or a scalar object. Note, numpy\n","          arrays are considered scalars.\n","\n","    Returns:\n","      A Python list, the flattened version of the input.\n","\n","    Raises:\n","      TypeError: The nest is or contains a dict with non-sortable keys.\n","    \"\"\"\n","    if is_sequence(nest):\n","        return list(_yield_flat_nest(nest))\n","    else:\n","        return [nest]\n","\n","\n","def _recursive_assert_same_structure(nest1, nest2, check_types):\n","    \"\"\"Helper function for `assert_same_structure`.\"\"\"\n","    is_sequence_nest1 = is_sequence(nest1)\n","    if is_sequence_nest1 != is_sequence(nest2):\n","        raise ValueError(\n","            \"The two structures don't have the same nested structure.\\n\\n\"\n","            \"First structure: %s\\n\\nSecond structure: %s.\" % (nest1, nest2))\n","\n","    if not is_sequence_nest1:\n","        return  # finished checking\n","\n","    if check_types:\n","        type_nest1 = type(nest1)\n","        type_nest2 = type(nest2)\n","        if type_nest1 != type_nest2:\n","            raise TypeError(\n","                \"The two structures don't have the same sequence type. First \"\n","                \"structure has type %s, while second structure has type %s.\"\n","                % (type_nest1, type_nest2))\n","\n","        if isinstance(nest1, dict):\n","            keys1 = set(_six.iterkeys(nest1))\n","            keys2 = set(_six.iterkeys(nest2))\n","            if keys1 != keys2:\n","                raise ValueError(\n","                    \"The two dictionaries don't have the same set of keys. First \"\n","                    \"structure has keys {}, while second structure has keys {}.\"\n","                        .format(keys1, keys2))\n","\n","    nest1_as_sequence = [n for n in _yield_value(nest1)]\n","    nest2_as_sequence = [n for n in _yield_value(nest2)]\n","    for n1, n2 in zip(nest1_as_sequence, nest2_as_sequence):\n","        _recursive_assert_same_structure(n1, n2, check_types)\n","\n","\n","def assert_same_structure(nest1, nest2, check_types=True):\n","    \"\"\"Asserts that two structures are nested in the same way.\n","\n","    Args:\n","      nest1: an arbitrarily nested structure.\n","      nest2: an arbitrarily nested structure.\n","      check_types: if `True` (default) types of sequences are checked as\n","          well, including the keys of dictionaries. If set to `False`, for example\n","          a list and a tuple of objects will look the same if they have the same\n","          size.\n","\n","    Raises:\n","      ValueError: If the two structures do not have the same number of elements or\n","        if the two structures are not nested in the same way.\n","      TypeError: If the two structures differ in the type of sequence in any of\n","        their substructures. Only possible if `check_types` is `True`.\n","    \"\"\"\n","    len_nest1 = len(flatten(nest1)) if is_sequence(nest1) else 1\n","    len_nest2 = len(flatten(nest2)) if is_sequence(nest2) else 1\n","    if len_nest1 != len_nest2:\n","        raise ValueError(\"The two structures don't have the same number of \"\n","                         \"elements.\\n\\nFirst structure (%i elements): %s\\n\\n\"\n","                         \"Second structure (%i elements): %s\"\n","                         % (len_nest1, nest1, len_nest2, nest2))\n","    _recursive_assert_same_structure(nest1, nest2, check_types)\n","\n","\n","def flatten_dict_items(dictionary):\n","    \"\"\"Returns a dictionary with flattened keys and values.\n","\n","    This function flattens the keys and values of a dictionary, which can be\n","    arbitrarily nested structures, and returns the flattened version of such\n","    structures:\n","\n","    ```python\n","    example_dictionary = {(4, 5, (6, 8)): (\"a\", \"b\", (\"c\", \"d\"))}\n","    result = {4: \"a\", 5: \"b\", 6: \"c\", 8: \"d\"}\n","    flatten_dict_items(example_dictionary) == result\n","    ```\n","\n","    The input dictionary must satisfy two properties:\n","\n","    1. Its keys and values should have the same exact nested structure.\n","    2. The set of all flattened keys of the dictionary must not contain repeated\n","       keys.\n","\n","    Args:\n","      dictionary: the dictionary to zip\n","\n","    Returns:\n","      The zipped dictionary.\n","\n","    Raises:\n","      TypeError: If the input is not a dictionary.\n","      ValueError: If any key and value have not the same structure, or if keys are\n","        not unique.\n","    \"\"\"\n","    if not isinstance(dictionary, dict):\n","        raise TypeError(\"input must be a dictionary\")\n","    flat_dictionary = {}\n","    for i, v in _six.iteritems(dictionary):\n","        if not is_sequence(i):\n","            if i in flat_dictionary:\n","                raise ValueError(\n","                    \"Could not flatten dictionary: key %s is not unique.\" % i)\n","            flat_dictionary[i] = v\n","        else:\n","            flat_i = flatten(i)\n","            flat_v = flatten(v)\n","            if len(flat_i) != len(flat_v):\n","                raise ValueError(\n","                    \"Could not flatten dictionary. Key had %d elements, but value had \"\n","                    \"%d elements. Key: %s, value: %s.\"\n","                    % (len(flat_i), len(flat_v), flat_i, flat_v))\n","            for new_i, new_v in zip(flat_i, flat_v):\n","                if new_i in flat_dictionary:\n","                    raise ValueError(\n","                        \"Could not flatten dictionary: key %s is not unique.\"\n","                        % (new_i))\n","                flat_dictionary[new_i] = new_v\n","    return flat_dictionary\n","\n","\n","def _packed_nest_with_indices(structure, flat, index):\n","    \"\"\"Helper function for pack_sequence_as.\n","\n","    Args:\n","      structure: Substructure (list / tuple / dict) to mimic.\n","      flat: Flattened values to output substructure for.\n","      index: Index at which to start reading from flat.\n","\n","    Returns:\n","      The tuple (new_index, child), where:\n","        * new_index - the updated index into `flat` having processed `structure`.\n","        * packed - the subset of `flat` corresponding to `structure`,\n","                   having started at `index`, and packed into the same nested\n","                   format.\n","\n","    Raises:\n","      ValueError: if `structure` contains more elements than `flat`\n","        (assuming indexing starts from `index`).\n","    \"\"\"\n","    packed = []\n","    for s in _yield_value(structure):\n","        if is_sequence(s):\n","            new_index, child = _packed_nest_with_indices(s, flat, index)\n","            packed.append(_sequence_like(s, child))\n","            index = new_index\n","        else:\n","            packed.append(flat[index])\n","            index += 1\n","    return index, packed\n","\n","\n","def pack_sequence_as(structure, flat_sequence):\n","    \"\"\"Returns a given flattened sequence packed into a given structure.\n","\n","    If `structure` is a scalar, `flat_sequence` must be a single-element list;\n","    in this case the return value is `flat_sequence[0]`.\n","\n","    If `structure` is or contains a dict instance, the keys will be sorted to\n","    pack the flat sequence in deterministic order. This is true also for\n","    `OrderedDict` instances: their sequence order is ignored, the sorting order of\n","    keys is used instead. The same convention is followed in `pack_sequence_as`.\n","    This correctly repacks dicts and `OrderedDict`s after they have been\n","    flattened, and also allows flattening an `OrderedDict` and then repacking it\n","    back using a correponding plain dict, or vice-versa.\n","    Dictionaries with non-sortable keys cannot be flattened.\n","\n","    Args:\n","      structure: Nested structure, whose structure is given by nested lists,\n","          tuples, and dicts. Note: numpy arrays and strings are considered\n","          scalars.\n","      flat_sequence: flat sequence to pack.\n","\n","    Returns:\n","      packed: `flat_sequence` converted to have the same recursive structure as\n","        `structure`.\n","\n","    Raises:\n","      ValueError: If `flat_sequence` and `structure` have different\n","        element counts.\n","      TypeError: `structure` is or contains a dict with non-sortable keys.\n","    \"\"\"\n","    if not is_sequence(flat_sequence):\n","        raise TypeError(\"flat_sequence must be a sequence\")\n","\n","    if not is_sequence(structure):\n","        if len(flat_sequence) != 1:\n","            raise ValueError(\"Structure is a scalar but len(flat_sequence) == %d > 1\"\n","                             % len(flat_sequence))\n","        return flat_sequence[0]\n","\n","    flat_structure = flatten(structure)\n","    if len(flat_structure) != len(flat_sequence):\n","        raise ValueError(\n","            \"Could not pack sequence. Structure had %d elements, but flat_sequence \"\n","            \"had %d elements.  Structure: %s, flat_sequence: %s.\"\n","            % (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n","\n","    _, packed = _packed_nest_with_indices(structure, flat_sequence, 0)\n","    return _sequence_like(structure, packed)\n","\n","\n","def map_structure(func, *structure, **check_types_dict):\n","    \"\"\"Applies `func` to each entry in `structure` and returns a new structure.\n","\n","    Applies `func(x[0], x[1], ...)` where x[i] is an entry in\n","    `structure[i]`.  All structures in `structure` must have the same arity,\n","    and the return value will contain the results in the same structure.\n","\n","    Args:\n","      func: A callable that accepts as many arguments as there are structures.\n","      *structure: scalar, or tuple or list of constructed scalars and/or other\n","        tuples/lists, or scalars.  Note: numpy arrays are considered as scalars.\n","      **check_types_dict: only valid keyword argument is `check_types`. If set to\n","        `True` (default) the types of iterables within the structures have to be\n","        same (e.g. `map_structure(func, [1], (1,))` raises a `TypeError`\n","        exception). To allow this set this argument to `False`.\n","\n","    Returns:\n","      A new structure with the same arity as `structure`, whose values correspond\n","      to `func(x[0], x[1], ...)` where `x[i]` is a value in the corresponding\n","      location in `structure[i]`. If there are different sequence types and\n","      `check_types` is `False` the sequence types of the first structure will be\n","      used.\n","\n","    Raises:\n","      TypeError: If `func` is not callable or if the structures do not match\n","        each other by depth tree.\n","      ValueError: If no structure is provided or if the structures do not match\n","        each other by type.\n","      ValueError: If wrong keyword arguments are provided.\n","    \"\"\"\n","    if not callable(func):\n","        raise TypeError(\"func must be callable, got: %s\" % func)\n","\n","    if not structure:\n","        raise ValueError(\"Must provide at least one structure\")\n","\n","    if check_types_dict:\n","        if \"check_types\" not in check_types_dict or len(check_types_dict) > 1:\n","            raise ValueError(\"Only valid keyword argument is check_types\")\n","        check_types = check_types_dict[\"check_types\"]\n","    else:\n","        check_types = True\n","\n","    for other in structure[1:]:\n","        assert_same_structure(structure[0], other, check_types=check_types)\n","\n","    flat_structure = [flatten(s) for s in structure]\n","    entries = zip(*flat_structure)\n","\n","    return pack_sequence_as(\n","        structure[0], [func(*x) for x in entries])\n","\n","\n","def _yield_flat_up_to(shallow_tree, input_tree):\n","    \"\"\"Yields elements `input_tree` partially flattened up to `shallow_tree`.\"\"\"\n","    if is_sequence(shallow_tree):\n","        for shallow_branch, input_branch in zip(_yield_value(shallow_tree),\n","                                                _yield_value(input_tree)):\n","            for input_leaf in _yield_flat_up_to(shallow_branch, input_branch):\n","                yield input_leaf\n","    else:\n","        yield input_tree\n","\n","\n","def assert_shallow_structure(shallow_tree, input_tree, check_types=True):\n","    \"\"\"Asserts that `shallow_tree` is a shallow structure of `input_tree`.\n","\n","    That is, this function tests if the `input_tree` structure can be created from\n","    the `shallow_tree` structure by replacing its leaf nodes with deeper\n","    tree structures.\n","\n","    Examples:\n","\n","    The following code will raise an exception:\n","    ```python\n","      shallow_tree = [\"a\", \"b\"]\n","      input_tree = [\"c\", [\"d\", \"e\"], \"f\"]\n","      assert_shallow_structure(shallow_tree, input_tree)\n","    ```\n","\n","    The following code will not raise an exception:\n","    ```python\n","      shallow_tree = [\"a\", \"b\"]\n","      input_tree = [\"c\", [\"d\", \"e\"]]\n","      assert_shallow_structure(shallow_tree, input_tree)\n","    ```\n","\n","    Args:\n","      shallow_tree: an arbitrarily nested structure.\n","      input_tree: an arbitrarily nested structure.\n","      check_types: if `True` (default) the sequence types of `shallow_tree` and\n","        `input_tree` have to be the same.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`. Only raised if `check_types` is `True`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","    \"\"\"\n","    if is_sequence(shallow_tree):\n","        if not is_sequence(input_tree):\n","            raise TypeError(\n","                \"If shallow structure is a sequence, input must also be a sequence. \"\n","                \"Input has type: %s.\" % type(input_tree))\n","\n","        if check_types and not isinstance(input_tree, type(shallow_tree)):\n","            raise TypeError(\n","                \"The two structures don't have the same sequence type. Input \"\n","                \"structure has type %s, while shallow structure has type %s.\"\n","                % (type(input_tree), type(shallow_tree)))\n","\n","        if len(input_tree) != len(shallow_tree):\n","            raise ValueError(\n","                \"The two structures don't have the same sequence length. Input \"\n","                \"structure has length %s, while shallow structure has length %s.\"\n","                % (len(input_tree), len(shallow_tree)))\n","\n","        for shallow_branch, input_branch in zip(shallow_tree, input_tree):\n","            assert_shallow_structure(shallow_branch, input_branch,\n","                                     check_types=check_types)\n","\n","\n","def flatten_up_to(shallow_tree, input_tree):\n","    \"\"\"Flattens `input_tree` up to `shallow_tree`.\n","\n","    Any further depth in structure in `input_tree` is retained as elements in the\n","    partially flatten output.\n","\n","    If `shallow_tree` and `input_tree` are not sequences, this returns a\n","    single-element list: `[input_tree]`.\n","\n","    Use Case:\n","\n","    Sometimes we may wish to partially flatten a nested sequence, retaining some\n","    of the nested structure. We achieve this by specifying a shallow structure,\n","    `shallow_tree`, we wish to flatten up to.\n","\n","    The input, `input_tree`, can be thought of as having the same structure as\n","    `shallow_tree`, but with leaf nodes that are themselves tree structures.\n","\n","    Examples:\n","\n","    ```python\n","    input_tree = [[[2, 2], [3, 3]], [[4, 9], [5, 5]]]\n","    shallow_tree = [[True, True], [False, True]]\n","\n","    flattened_input_tree = flatten_up_to(shallow_tree, input_tree)\n","    flattened_shallow_tree = flatten_up_to(shallow_tree, shallow_tree)\n","\n","    # Output is:\n","    # [[2, 2], [3, 3], [4, 9], [5, 5]]\n","    # [True, True, False, True]\n","    ```\n","\n","    ```python\n","    input_tree = [[('a', 1), [('b', 2), [('c', 3), [('d', 4)]]]]]\n","    shallow_tree = [['level_1', ['level_2', ['level_3', ['level_4']]]]]\n","\n","    input_tree_flattened_as_shallow_tree = flatten_up_to(shallow_tree, input_tree)\n","    input_tree_flattened = flatten(input_tree)\n","\n","    # Output is:\n","    # [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n","    # ['a', 1, 'b', 2, 'c', 3, 'd', 4]\n","    ```\n","\n","    Non-Sequence Edge Cases:\n","\n","    ```python\n","    flatten_up_to(0, 0)  # Output: [0]\n","    flatten_up_to(0, [0, 1, 2])  # Output: [[0, 1, 2]]\n","    flatten_up_to([0, 1, 2], 0)  # Output: TypeError\n","    flatten_up_to([0, 1, 2], [0, 1, 2])  # Output: [0, 1, 2]\n","    ```\n","\n","    Args:\n","      shallow_tree: a possibly pruned structure of input_tree.\n","      input_tree: an arbitrarily nested structure or a scalar object.\n","        Note, numpy arrays are considered scalars.\n","\n","    Returns:\n","      A Python list, the partially flattened version of `input_tree` according to\n","      the structure of `shallow_tree`.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","    \"\"\"\n","    assert_shallow_structure(shallow_tree, input_tree)\n","    return list(_yield_flat_up_to(shallow_tree, input_tree))\n","\n","\n","def map_structure_up_to(shallow_tree, func, *inputs):\n","    \"\"\"Applies a function or op to a number of partially flattened inputs.\n","\n","    The `inputs` are flattened up to `shallow_tree` before being mapped.\n","\n","    Use Case:\n","\n","    Sometimes we wish to apply a function to a partially flattened\n","    sequence (for example when the function itself takes sequence inputs). We\n","    achieve this by specifying a shallow structure, `shallow_tree` we wish to\n","    flatten up to.\n","\n","    The `inputs`, can be thought of as having the same structure as\n","    `shallow_tree`, but with leaf nodes that are themselves tree structures.\n","\n","    This function therefore will return something with the same base structure as\n","    `shallow_tree`.\n","\n","    Examples:\n","\n","    ```python\n","    ab_tuple = collections.namedtuple(\"ab_tuple\", \"a, b\")\n","    op_tuple = collections.namedtuple(\"op_tuple\", \"add, mul\")\n","    inp_val = ab_tuple(a=2, b=3)\n","    inp_ops = ab_tuple(a=op_tuple(add=1, mul=2), b=op_tuple(add=2, mul=3))\n","    out = map_structure_up_to(inp_val, lambda val, ops: (val + ops.add) * ops.mul,\n","                              inp_val, inp_ops)\n","\n","    # Output is: ab_tuple(a=6, b=15)\n","    ```\n","\n","    ```python\n","    data_list = [[2, 4, 6, 8], [[1, 3, 5, 7, 9], [3, 5, 7]]]\n","    name_list = ['evens', ['odds', 'primes']]\n","    out = map_structure_up_to(\n","        name_list,\n","        lambda name, sec: \"first_{}_{}\".format(len(sec), name),\n","        name_list, data_list)\n","\n","    # Output is: ['first_4_evens', ['first_5_odds', 'first_3_primes']]\n","    ```\n","\n","    Args:\n","      shallow_tree: a shallow tree, common to all the inputs.\n","      func: callable which will be applied to each input individually.\n","      *inputs: arbitrarily nested combination of objects that are compatible with\n","          shallow_tree. The function `func` is applied to corresponding\n","          partially flattened elements of each input, so the function must support\n","          arity of `len(inputs)`.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","\n","    Returns:\n","      result of repeatedly applying `func`, with same structure as\n","      `shallow_tree`.\n","    \"\"\"\n","    if not inputs:\n","        raise ValueError(\"Cannot map over no sequences\")\n","    for input_tree in inputs:\n","        assert_shallow_structure(shallow_tree, input_tree)\n","\n","    # Flatten each input separately, apply the function to corresponding elements,\n","    # then repack based on the structure of the first input.\n","    all_flattened_up_to = [flatten_up_to(shallow_tree, input_tree)\n","                           for input_tree in inputs]\n","    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]\n","    return pack_sequence_as(structure=shallow_tree, flat_sequence=results)\n","\n","\n","def get_traverse_shallow_structure(traverse_fn, structure):\n","    \"\"\"Generates a shallow structure from a `traverse_fn` and `structure`.\n","\n","    `traverse_fn` must accept any possible subtree of `structure` and return\n","    a depth=1 structure containing `True` or `False` values, describing which\n","    of the top-level subtrees may be traversed.  It may also\n","    return scalar `True` or `False` \"traversal is OK / not OK for all subtrees.\"\n","\n","    Examples are available in the unit tests (nest_test.py).\n","\n","    Args:\n","      traverse_fn: Function taking a substructure and returning either a scalar\n","        `bool` (whether to traverse that substructure or not) or a depth=1\n","        shallow structure of the same type, describing which parts of the\n","        substructure to traverse.\n","      structure: The structure to traverse.\n","\n","    Returns:\n","      A shallow structure containing python bools, which can be passed to\n","      `map_structure_up_to` and `flatten_up_to`.\n","\n","    Raises:\n","      TypeError: if `traverse_fn` returns a sequence for a non-sequence input,\n","        or a structure with depth higher than 1 for a sequence input,\n","        or if any leaf values in the returned structure or scalar are not type\n","        `bool`.\n","    \"\"\"\n","    to_traverse = traverse_fn(structure)\n","    if not is_sequence(structure):\n","        if not isinstance(to_traverse, bool):\n","            raise TypeError(\"traverse_fn returned structure: %s for non-structure: %s\"\n","                            % (to_traverse, structure))\n","        return to_traverse\n","    level_traverse = []\n","    if isinstance(to_traverse, bool):\n","        if not to_traverse:\n","            # Do not traverse this substructure at all.  Exit early.\n","            return False\n","        else:\n","            # Traverse the entire substructure.\n","            for branch in _yield_value(structure):\n","                level_traverse.append(\n","                    get_traverse_shallow_structure(traverse_fn, branch))\n","    elif not is_sequence(to_traverse):\n","        raise TypeError(\"traverse_fn returned a non-bool scalar: %s for input: %s\"\n","                        % (to_traverse, structure))\n","    else:\n","        # Traverse some subset of this substructure.\n","        assert_shallow_structure(to_traverse, structure)\n","        for t, branch in zip(_yield_value(to_traverse), _yield_value(structure)):\n","            if not isinstance(t, bool):\n","                raise TypeError(\n","                    \"traverse_fn didn't return a depth=1 structure of bools.  saw: %s \"\n","                    \" for structure: %s\" % (to_traverse, structure))\n","            if t:\n","                level_traverse.append(\n","                    get_traverse_shallow_structure(traverse_fn, branch))\n","            else:\n","                level_traverse.append(False)\n","    return _sequence_like(structure, level_traverse)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcCV7jESVKSC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595694132136,"user_tz":-330,"elapsed":16044,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","#import nest\n","\n","\n","def mkMask(input_tensor, maxLen):\n","    shape_of_input = tf.shape(input_tensor)\n","    shape_of_output = tf.concat(axis=0, values=[shape_of_input, [maxLen]])\n","\n","    oneDtensor = tf.reshape(input_tensor, shape=(-1,))\n","    flat_mask = tf.sequence_mask(oneDtensor, maxlen=maxLen)\n","    return tf.reshape(flat_mask, shape_of_output)\n","\n","\n","def reduce_avg(reduce_target, lengths, dim):\n","    \"\"\"\n","    Args:\n","        reduce_target : shape(d_0, d_1,..,d_dim, .., d_k)\n","        lengths : shape(d0, .., d_(dim-1))\n","        dim : which dimension to average, should be a python number\n","    \"\"\"\n","    shape_of_lengths = lengths.get_shape()\n","    shape_of_target = reduce_target.get_shape()\n","    if len(shape_of_lengths) != dim:\n","        raise ValueError(('Second input tensor should be rank %d, ' +\n","                          'while it got rank %d') % (dim, len(shape_of_lengths)))\n","    if len(shape_of_target) < dim + 1:\n","        raise ValueError(('First input tensor should be at least rank %d, ' +\n","                          'while it got rank %d') % (dim + 1, len(shape_of_target)))\n","\n","    rank_diff = len(shape_of_target) - len(shape_of_lengths) - 1\n","    mxlen = tf.shape(reduce_target)[dim]\n","    mask = mkMask(lengths, mxlen)\n","    if rank_diff != 0:\n","        len_shape = tf.concat(axis=0, values=[tf.shape(lengths), [1] * rank_diff])\n","        mask_shape = tf.concat(axis=0, values=[tf.shape(mask), [1] * rank_diff])\n","    else:\n","        len_shape = tf.shape(lengths)\n","        mask_shape = tf.shape(mask)\n","    lengths_reshape = tf.reshape(lengths, shape=len_shape)\n","    mask = tf.reshape(mask, shape=mask_shape)\n","\n","    mask_target = reduce_target * tf.cast(mask, dtype=reduce_target.dtype)\n","\n","    red_sum = tf.reduce_sum(mask_target, axis=[dim], keep_dims=False)\n","    red_avg = red_sum / (tf.to_float(lengths_reshape) + 1e-30)\n","    return red_avg\n","\n","\n","def reduce_sum(reduce_target, lengths, dim):\n","    \"\"\"\n","    Args:\n","        reduce_target : shape(d_0, d_1,..,d_dim, .., d_k)\n","        lengths : shape(d0, .., d_(dim-1))\n","        dim : which dimension to average, should be a python number\n","    \"\"\"\n","    shape_of_lengths = lengths.get_shape()\n","    shape_of_target = reduce_target.get_shape()\n","    if len(shape_of_lengths) != dim:\n","        raise ValueError(('Second input tensor should be rank %d, ' +\n","                          'while it got rank %d') % (dim, len(shape_of_lengths)))\n","    if len(shape_of_target) < dim + 1:\n","        raise ValueError(('First input tensor should be at least rank %d, ' +\n","                          'while it got rank %d') % (dim + 1, len(shape_of_target)))\n","\n","    rank_diff = len(shape_of_target) - len(shape_of_lengths) - 1\n","    mxlen = tf.shape(reduce_target)[dim]\n","    mask = mkMask(lengths, mxlen)\n","    if rank_diff != 0:\n","        len_shape = tf.concat(axis=0, values=[tf.shape(lengths), [1] * rank_diff])\n","        mask_shape = tf.concat(axis=0, values=[tf.shape(mask), [1] * rank_diff])\n","    else:\n","        len_shape = tf.shape(lengths)\n","        mask_shape = tf.shape(mask)\n","    lengths_reshape = tf.reshape(lengths, shape=len_shape)\n","    mask = tf.reshape(mask, shape=mask_shape)\n","\n","    mask_target = reduce_target * tf.cast(mask, dtype=reduce_target.dtype)\n","\n","    red_sum = tf.reduce_sum(mask_target, axis=[dim], keep_dims=False)\n","\n","    return red_sum\n","\n","\n","def embed_lookup_last_dim(embedding, ids):\n","    '''\n","        embedding: shape(b_sz, tstp, emb_sz)\n","        ids : shape(b_sz, tstp)\n","    '''\n","    input_shape = tf.shape(embedding)\n","    time_steps = input_shape[0]\n","\n","    def _create_ta(name, dtype):\n","        return tf.TensorArray(dtype=dtype,\n","                              size=time_steps,\n","                              tensor_array_name=name)\n","\n","    input_ta = _create_ta('input_ta', embedding.dtype)\n","    fetch_ta = _create_ta('fetch_ta', ids.dtype)\n","    output_ta = _create_ta('output_ta', embedding.dtype)\n","    input_ta = input_ta.unpack(embedding)\n","    fetch_ta = fetch_ta.unpack(ids)\n","\n","    def loop_body(time, output_ta):\n","        embed = input_ta.read(time)  # shape(tstp, emb_sz) type of float32\n","        fetch_id = fetch_ta.read(time)  # shape(tstp) type of int32\n","        out_emb = tf.nn.embedding_lookup(embed, fetch_id)\n","        output_ta = output_ta.write(time, out_emb)\n","\n","        next_time = time + 1\n","        return next_time, output_ta\n","\n","    time = tf.constant(0)\n","    _, output_ta = tf.while_loop(cond=lambda time, *_: time < time_steps,\n","                                 body=loop_body, loop_vars=(time, output_ta),\n","                                 swap_memory=True)\n","    ret_t = output_ta.pack()  # shape(b_sz, tstp, embd_sz)\n","    return ret_t\n","\n","\n","def entry_stop_gradients(target, mask):\n","    '''\n","    Args:\n","        target: a tensor\n","        mask: a boolean tensor that broadcast to the rank of that to target tensor\n","    Returns:\n","        ret: a tensor have the same value of target,\n","            but some entry will have no gradient during backprop\n","    '''\n","    mask_h = tf.logical_not(mask)\n","\n","    mask = tf.cast(mask, dtype=target.dtype)\n","    mask_h = tf.cast(mask_h, dtype=target.dtype)\n","    ret = tf.stop_gradient(mask_h * target) + mask * target\n","\n","    return ret\n","\n","\n","def last_dim_linear(inputs, output_size, bias, scope):\n","    '''\n","    Args:\n","        input: shape(b_sz, ..., rep_sz)\n","        output_size: a scalar, python number\n","    '''\n","    bias_start = 0.0\n","    input_shape = tf.shape(inputs)\n","    out_shape = tf.concat(axis=0, values=[input_shape[:-1], [output_size]])\n","    input_size = int(inputs.get_shape()[-1])\n","    unbatch_input = tf.reshape(inputs, shape=[-1, input_size])\n","\n","    unbatch_output = linear(unbatch_input, output_size, bias=bias,\n","                            bias_start=bias_start, scope=scope)\n","    batch_output = tf.reshape(unbatch_output, shape=out_shape)\n","\n","    return batch_output  # shape(b_sz, ..., output_size)\n","\n","\n","def linear(args, output_size, bias, bias_start=0.0, scope=None):\n","    \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n","\n","    Args:\n","      args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n","      output_size: int, second dimension of W[i].\n","      bias: boolean, whether to add a bias term or not.\n","      bias_start: starting value to initialize the bias; 0 by default.\n","      scope: (optional) Variable scope to create parameters in.\n","\n","    Returns:\n","      A 2D Tensor with shape [batch x output_size] equal to\n","      sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n","\n","    Raises:\n","      ValueError: if some of the arguments has unspecified or wrong shape.\n","    \"\"\"\n","    if args is None or (nest.is_sequence(args) and not args):\n","        raise ValueError(\"`args` must be specified\")\n","    if not nest.is_sequence(args):\n","        args = [args]\n","\n","    total_arg_size = 0\n","    shapes = [a.get_shape() for a in args]\n","    for shape in shapes:\n","        if shape.ndims != 2:\n","            raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n","        if shape[1].value is None:\n","            raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n","                             \"but saw %s\" % (shape, shape[1]))\n","        else:\n","            total_arg_size += shape[1].value\n","\n","    dtype = [a.dtype for a in args][0]\n","\n","    with tf.variable_scope(scope or 'Linear') as outer_scope:\n","        weights = tf.get_variable(\n","            \"weights\", [total_arg_size, output_size], dtype=dtype)\n","        if len(args) == 1:\n","            res = tf.matmul(args[0], weights)\n","        else:\n","            res = tf.matmul(tf.concat(args, 1), weights)\n","        if not bias:\n","            return res\n","        with tf.variable_scope(outer_scope) as inner_scope:\n","            inner_scope.set_partitioner(None)\n","            biases = tf.get_variable(\n","                \"biases\", [output_size],\n","                dtype=dtype,\n","                initializer=tf.constant_initializer(bias_start, dtype=dtype))\n","    return tf.nn.bias_add(res, biases)\n","\n","\n","def masked_softmax(inp, seqLen):\n","    seqLen = tf.where(tf.equal(seqLen, 0), tf.ones_like(seqLen), seqLen)\n","    if len(inp.get_shape()) != len(seqLen.get_shape()) + 1:\n","        raise ValueError('rank of seqLen should be %d, but have the rank %d.\\n'\n","                         % (len(inp.get_shape()) - 1, len(seqLen.get_shape())))\n","    mask = mkMask(seqLen, tf.shape(inp)[-1])\n","    masked_inp = tf.where(mask, inp, tf.ones_like(inp) * (-np.Inf))\n","    ret = tf.nn.softmax(masked_inp)\n","    return ret\n","\n","\n","from tensorflow.python.client import device_lib\n","\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import gen_math_ops\n","\n","\n","def batch_gather(params, indices, name=None):\n","    \"\"\"Gather slices from `params` according to `indices` with leading batch dims.\n","    This operation assumes that the leading dimensions of `indices` are dense,\n","    and the gathers on the axis corresponding to the last dimension of `indices`.\n","    More concretely it computes:\n","    result[i1, ..., in] = params[i1, ..., in-1, indices[i1, ..., in]]\n","    Therefore `params` should be a Tensor of shape [A1, ..., AN, B1, ..., BM],\n","    `indices` should be a Tensor of shape [A1, ..., AN-1, C] and `result` will be\n","    a Tensor of size `[A1, ..., AN-1, C, B1, ..., BM]`.\n","    In the case in which indices is a 1D tensor, this operation is equivalent to\n","    `tf.gather`.\n","    See also `tf.gather` and `tf.gather_nd`.\n","    Args:\n","      params: A Tensor. The tensor from which to gather values.\n","      indices: A Tensor. Must be one of the following types: int32, int64. Index\n","          tensor. Must be in range `[0, params.shape[axis]`, where `axis` is the\n","          last dimension of `indices` itself.\n","      name: A name for the operation (optional).\n","    Returns:\n","      A Tensor. Has the same type as `params`.\n","    Raises:\n","      ValueError: if `indices` has an unknown shape.\n","    \"\"\"\n","\n","    with ops.name_scope(name):\n","        indices = ops.convert_to_tensor(indices, name=\"indices\")\n","        params = ops.convert_to_tensor(params, name=\"params\")\n","        indices_shape = tf.shape(indices)\n","        params_shape = tf.shape(params)\n","        ndims = indices.shape.ndims\n","        if ndims is None:\n","            raise ValueError(\"batch_gather does not allow indices with unknown \"\n","                             \"shape.\")\n","        batch_indices = indices\n","        accum_dim_value = 1\n","        for dim in range(ndims - 1, 0, -1):\n","            dim_value = params_shape[dim - 1]\n","            accum_dim_value *= params_shape[dim]\n","            dim_indices = gen_math_ops._range(0, dim_value, 1)\n","            dim_indices *= accum_dim_value\n","            dim_shape = tf.stack([1] * (dim - 1) + [dim_value] + [1] * (ndims - dim),\n","                                 axis=0)\n","            batch_indices += tf.reshape(dim_indices, dim_shape)\n","\n","        flat_indices = tf.reshape(batch_indices, [-1])\n","        outer_shape = params_shape[ndims:]\n","        flat_inner_shape = gen_math_ops.prod(\n","            params_shape[:ndims], [0], False)\n","\n","        flat_params = tf.reshape(\n","            params, tf.concat([[flat_inner_shape], outer_shape], axis=0))\n","        flat_result = tf.gather(flat_params, flat_indices)\n","        result = tf.reshape(flat_result, tf.concat([indices_shape, outer_shape], axis=0))\n","        final_shape = indices.get_shape()[:ndims - 1].merge_with(\n","            params.get_shape()[:ndims - 1])\n","        final_shape = final_shape.concatenate(indices.get_shape()[ndims - 1])\n","        final_shape = final_shape.concatenate(params.get_shape()[ndims:])\n","        result.set_shape(final_shape)\n","        return result"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6agyaVbVb-U","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595694132138,"user_tz":-330,"elapsed":16039,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","def _softmax_with_mask(logits, lens, axis=-1):\n","    \"\"\"Helper function for softmax on variable-length sequences.\n","        Args:\n","            logits: The logits before softmax. Shape is [batch, type_num, class_num]\n","            lens: The length of the sequence. Shape is [batch, type_num].\n","            axis: The axis to apply softmax operator on.\n","        Returns:\n","             A tensor with softmax-ed values. Same shape as logits.\n","    \"\"\"\n","    exp_logits = tf.exp(logits)\n","    mask = tf.sequence_mask(lens, maxlen=tf.shape(logits)[axis], dtype=tf.float32)\n","    masked_exp_logits = tf.multiply(exp_logits, mask)\n","    masked_exp_logits_sum = tf.reduce_sum(masked_exp_logits, axis)\n","    return tf.clip_by_value(tf.div(masked_exp_logits, tf.expand_dims(masked_exp_logits_sum, axis)), 1e-37, 1e+37)\n","\n","\n","def _squash(input_tensor):\n","    \"\"\"Applies norm nonlinearity (squash) to a capsule layer.\n","        Args:\n","            input_tensor: Input tensor. Shape is [batch, num_channels, num_atoms] for a\n","              fully connected capsule layer or\n","              [batch, num_channels, num_atoms, height, width] for a convolutional\n","              capsule layer.\n","        Returns:\n","            A tensor with same shape as input (rank 3) for output of this layer.\n","    \"\"\"\n","    with tf.name_scope('norm_non_linearity'):\n","        norm = tf.norm(input_tensor, axis=2, keep_dims=True)\n","        norm_squared = norm * norm\n","        return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n","\n","\n","def _leaky_routing(logits, output_dim):\n","    \"\"\"Adds extra dimmension to routing logits.\n","    This enables active capsules to be routed to the extra dim if they are not a\n","    good fit for any of the capsules in layer above.\n","    Args:\n","      logits: The original logits. shape is\n","        [input_capsule_num, output_capsule_num] if fully connected. Otherwise, it\n","        has two more dimmensions.\n","      output_dim: The number of units in the second dimmension of logits.\n","    Returns:\n","      Routing probabilities for each pair of capsules. Same shape as logits.\n","    \"\"\"\n","    leak = tf.zeros_like(logits, optimize=True)\n","    leak = tf.reduce_sum(leak, axis=2, keep_dims=True)\n","    leaky_logits = tf.concat([leak, logits], axis=2)\n","    leaky_routing = tf.nn.softmax(leaky_logits, dim=2)\n","    return tf.split(leaky_routing, [1, output_dim], 2)[1]\n","\n","\n","def _update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,\n","                    num_routing=3, leaky=True):\n","    \"\"\"Sums over scaled votes and applies squash to compute the activations.\n","    Iteratively updates routing logits (scales) based on the similarity between\n","    the activation of this layer and the votes of the layer below.\n","    Args:\n","      votes: tensor, The transformed outputs of the layer below.\n","      biases: tensor, Bias variable.\n","      logit_shape: tensor, shape of the logit to be initialized.\n","      num_dims: scalar, number of dimmensions in votes. For fully connected\n","        capsule it is 4, for convolutional 6.\n","      input_dim: scalar, number of capsules in the input layer.\n","      output_dim: scalar, number of capsules in the output layer.\n","      num_routing: scalar, Number of routing iterations.\n","      leaky: boolean, if set use leaky routing.\n","    Returns:\n","      The activation tensor of the output layer after num_routing iterations.\n","    \"\"\"\n","    votes_t_shape = [3, 0, 1, 2]\n","    for i in range(num_dims - 4):\n","        votes_t_shape += [i + 4]\n","    r_t_shape = [1, 2, 3, 0]\n","    for i in range(num_dims - 4):\n","        r_t_shape += [i + 4]\n","    votes_trans = tf.transpose(votes, votes_t_shape)\n","\n","    def _body(i, logits, activations, routes):\n","        \"\"\"Routing while loop.\"\"\"\n","        if leaky:\n","            route = _leaky_routing(logits, output_dim)\n","        else:\n","            route = tf.nn.softmax(logits, dim=2)\n","        preactivate_unrolled = route * votes_trans\n","        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n","        preactivate = tf.reduce_sum(preact_trans, axis=1) + biases\n","        activation = _squash(preactivate)\n","        activations = activations.write(i, activation)\n","        routes = routes.write(i, route)\n","        # distances: [batch, input_dim, output_dim]\n","        act_3d = tf.expand_dims(activation, 1)\n","        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n","        tile_shape[1] = input_dim\n","        act_replicated = tf.tile(act_3d, tile_shape)\n","        distances = tf.reduce_sum(votes * act_replicated, axis=3)\n","        logits += distances\n","        return (i + 1, logits, activations, routes)\n","\n","    activations = tf.TensorArray(\n","        dtype=tf.float32, size=num_routing, clear_after_read=False)\n","    routes = tf.TensorArray(\n","        dtype=tf.float32, size=num_routing, clear_after_read=False)\n","    logits = tf.fill(logit_shape, 0.0)\n","    i = tf.constant(0, dtype=tf.int32)\n","    _, logits, activations, routes = tf.while_loop(\n","        lambda i, logits, activations, routes: i < num_routing,\n","        _body,\n","        loop_vars=[i, logits, activations, routes],\n","        swap_memory=True)\n","\n","    return activations.read(num_routing - 1), logits, routes.read(num_routing - 1)\n","\n","\n","class Capsule:\n","    def __init__(self, input_dim, input_atoms, output_dim, output_atoms, layer_name):\n","        self.input_dim = input_dim\n","        self.input_atoms = input_atoms\n","        self.output_dim = output_dim\n","        self.output_atoms = output_atoms\n","        with tf.variable_scope(layer_name):\n","            self.weights = tf.get_variable(name='w',\n","                                           shape=[1, input_dim, input_atoms, output_dim * output_atoms],\n","                                           dtype=tf.float32)\n","            self.biases = tf.get_variable(name='b', shape=[output_dim, output_atoms], dtype=tf.float32,\n","                                          initializer=tf.zeros_initializer())\n","\n","    def vote_and_route(self, input_tensor, leaky=False):\n","        with tf.name_scope('Wx_plus_b'):\n","            input_tiled = tf.tile(tf.expand_dims(input_tensor, -1),\n","                                  [1, 1, 1, self.output_dim * self.output_atoms])\n","            votes = tf.reduce_sum(input_tiled * self.weights, axis=2)\n","            votes_reshaped = tf.reshape(votes,\n","                                        [-1, self.input_dim, self.output_dim, self.output_atoms])\n","        with tf.name_scope('routing'):\n","            input_shape = tf.shape(input_tensor)\n","            logit_shape = tf.stack([input_shape[0], self.input_dim, self.output_dim])\n","            activations, weights_c, route = _update_routing(\n","                votes=votes_reshaped,\n","                biases=self.biases,\n","                logit_shape=logit_shape,\n","                num_dims=4,\n","                input_dim=self.input_dim,\n","                output_dim=self.output_dim,\n","                leaky=leaky,\n","                num_routing=3)\n","        return activations, weights_c, route"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"CzX7D2Wj3qym","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595694132140,"user_tz":-330,"elapsed":16036,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.python.layers import base as base_layer\n","\n","#from TfUtils import mkMask\n","\n","_EPSILON = 1e-9\n","_MIN_NUM = -np.Inf\n","\n","\n","class Capsule(base_layer.Layer):\n","    def __init__(self, out_caps_num, out_caps_dim, iter_num=3, wrr_dim=(1, 1), reuse=None):\n","        super(Capsule, self).__init__(_reuse=reuse)\n","        self.out_caps_num = out_caps_num\n","        self.out_caps_dim = out_caps_dim\n","        self.iter_num = iter_num\n","        self.reuse=reuse\n","        self.w_rr = tf.get_variable(name='w_rr', shape=(1, 1, wrr_dim[0], wrr_dim[1]))\n","\n","    def call(self, in_caps, seqLen, caps_ihat=None, re_routing=False):\n","        caps_uhat = shared_routing_uhat(in_caps, self.out_caps_num, self.out_caps_dim, scope='rnn_caps_uhat')\n","        if not re_routing:\n","            V, S, C, B = masked_routing_iter(caps_uhat, seqLen, self.iter_num, caps_ihat, w_rr=None)\n","        else:\n","            V, S, C, B = masked_routing_iter(caps_uhat, seqLen, self.iter_num, caps_ihat, w_rr=self.w_rr)\n","        return V, C, B\n","\n","\n","def shared_routing_uhat(caps, out_caps_num, out_caps_dim, scope=None):\n","    '''\n","\n","    Args:\n","        caps: # shape(b_sz, caps_num, caps_dim)\n","        out_caps_num: #number of output capsule\n","        out_caps_dim: #dimension of output capsule\n","    Returns:\n","        caps_uhat: shape(b_sz, caps_num, out_caps_num, out_caps_dim)\n","    '''\n","    b_sz = tf.shape(caps)[0]\n","    tstp = tf.shape(caps)[1]\n","\n","    with tf.variable_scope(scope or 'shared_routing_uhat'):\n","        '''shape(b_sz, caps_num, out_caps_num*out_caps_dim)'''\n","        caps_uhat = tf.layers.dense(caps, out_caps_num * out_caps_dim, activation=tf.tanh)\n","        caps_uhat = tf.reshape(caps_uhat, shape=[b_sz, tstp, out_caps_num, out_caps_dim])\n","    return caps_uhat\n","\n","\n","def masked_routing_iter(caps_uhat, seqLen, iter_num, caps_ihat=None, w_rr=None):\n","    '''\n","\n","    Args:\n","        caps_uhat:  shape(b_sz, tstp, out_caps_num, out_caps_dim)\n","        seqLen:     shape(b_sz)\n","        iter_num:   number of iteration\n","\n","    Returns:\n","        V_ret:      #shape(b_sz, out_caps_num, out_caps_dim)\n","    '''\n","    assert iter_num > 0\n","    b_sz = tf.shape(caps_uhat)[0]\n","    tstp = tf.shape(caps_uhat)[1]\n","    out_caps_num = int(caps_uhat.get_shape()[2])\n","    seqLen = tf.where(tf.equal(seqLen, 0), tf.ones_like(seqLen), seqLen)\n","    mask = mkMask(seqLen, tstp)  # shape(b_sz, tstp)\n","    floatmask = tf.cast(tf.expand_dims(mask, axis=-1), dtype=tf.float32)  # shape(b_sz, tstp, 1)\n","    B = tf.zeros([b_sz, tstp, out_caps_num], dtype=tf.float32)\n","    C_list = list()\n","    for i in range(iter_num):\n","        B_logits = B\n","        C = tf.nn.softmax(B, axis=2)  # shape(b_sz, tstp, out_caps_num)\n","        C = tf.expand_dims(C * floatmask, axis=-1)  # shape(b_sz, tstp, out_caps_num, 1)\n","        weighted_uhat = C * caps_uhat  # shape(b_sz, tstp, out_caps_num, out_caps_dim)\n","        C_list.append(C)\n","        S = tf.reduce_sum(weighted_uhat, axis=1)  # shape(b_sz, out_caps_num, out_caps_dim)\n","        V = _squash(S, axes=[2])  # shape(b_sz, out_caps_num, out_caps_dim)\n","        V = tf.expand_dims(V, axis=1)  # shape(b_sz, 1, out_caps_num, out_caps_dim)\n","        if caps_ihat == None:\n","            B = tf.reduce_sum(caps_uhat * V, axis=-1) + B  # shape(b_sz, tstp, out_caps_num)\n","        else:\n","            B = tf.reduce_sum(caps_uhat * V, axis=-1) + 0.1 * tf.squeeze(\n","                tf.matmul(tf.matmul(caps_uhat, tf.tile(w_rr, [tf.shape(caps_uhat)[0], tf.shape(caps_uhat)[1], 1, 1])),\n","                          tf.tile(caps_ihat, [1, tf.shape(caps_uhat)[1], 1, 1])),\n","                axis=-1) + B  # shape(b_sz, tstp, out_caps_num)\n","    V_ret = tf.squeeze(V, axis=[1])  # shape(b_sz, out_caps_num, out_caps_dim)\n","    S_ret = S\n","    C_ret = tf.squeeze(tf.stack(C_list), axis=[4])\n","    return V_ret, S_ret, C_ret, B_logits\n","\n","\n","def margin_loss1(y_true, y_pred):\n","    \"\"\"\n","    :param y_true: [None, n_classes]\n","    :param y_pred: [None, n_classes]\n","    :return: a scalar loss value.\n","    \"\"\"\n","    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n","        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n","\n","    assert_inf_L = tf.Assert(tf.logical_not(tf.reduce_any(tf.is_inf(L))),\n","                             ['assert_inf_L', L], summarize=100)\n","    assert_nan_L = tf.Assert(tf.logical_not(tf.reduce_any(tf.is_nan(L))),\n","                             ['assert_nan_L', L], summarize=100)\n","    with tf.control_dependencies([assert_inf_L, assert_nan_L]):\n","        ret = tf.reduce_mean(tf.reduce_sum(L, axis=1))\n","    return ret\n","\n","\n","def _squash(in_caps, axes):\n","    '''\n","    Squashing function corresponding to Eq. 1\n","    Args:\n","        in_caps:  a tensor\n","        axes:     dimensions along which to apply squash\n","\n","    Returns:\n","        vec_squashed:   squashed tensor\n","\n","    '''\n","    vec_squared_norm = tf.reduce_sum(tf.square(in_caps), axis=axes, keepdims=True)\n","    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + _EPSILON)\n","    vec_squashed = scalar_factor * in_caps  # element-wise\n","    return vec_squashed"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5c4_CixAVl_6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595694132141,"user_tz":-330,"elapsed":16032,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import tensorflow as tf\n","\n","\n","\n","\n","def build_model(input_data, input_size, sequence_length, slot_size, intent_size, intent_dim, layer_size, embed_dim,\n","                num_rnn=1, isTraining=True, iter_slot=2, iter_intent=2, re_routing=True):\n","    cell_fw_list = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(layer_size) for _ in range(num_rnn)])\n","    cell_bw_list = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(layer_size) for _ in range(num_rnn)])\n","\n","    if isTraining == True:\n","        cell_fw_list = tf.contrib.rnn.DropoutWrapper(cell_fw_list, input_keep_prob=0.8,\n","                                                     output_keep_prob=0.8)\n","        cell_bw_list = tf.contrib.rnn.DropoutWrapper(cell_bw_list, input_keep_prob=0.8,\n","                                                     output_keep_prob=0.8)\n","\n","    embedding = tf.get_variable('embedding', [input_size, embed_dim],\n","                                initializer=tf.contrib.layers.xavier_initializer())\n","    inputs = tf.nn.embedding_lookup(embedding, input_data)\n","\n","    with tf.variable_scope('slot_capsule'):\n","        H, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n","            [cell_fw_list],\n","            [cell_bw_list],\n","            inputs=inputs,\n","            sequence_length=sequence_length,\n","            dtype=tf.float32)\n","        sc = Capsule(slot_size, layer_size, reuse=tf.AUTO_REUSE, iter_num=iter_slot, wrr_dim=(layer_size, intent_dim))\n","        slot_capsule, routing_weight, routing_logits = sc(H, sequence_length, re_routing=False)\n","    with tf.variable_scope('slot_proj'):\n","        slot_p = tf.reshape(routing_logits, [-1, slot_size])\n","    with tf.variable_scope('intent_capsule'):\n","        intent_capsule, intent_routing_weight, _ = Capsule(intent_size, intent_dim, reuse=tf.AUTO_REUSE,\n","                                                           iter_num=iter_intent)(slot_capsule, slot_size)\n","    with tf.variable_scope('intent_proj'):\n","        intent = intent_capsule\n","    outputs = [slot_p, intent, routing_weight, intent_routing_weight]\n","    if re_routing:\n","        pred_intent_index_onehot = tf.one_hot(tf.argmax(tf.norm(intent_capsule, axis=-1), axis=-1), intent_size)\n","        pred_intent_index_onehot = tf.tile(tf.expand_dims(pred_intent_index_onehot, 2),\n","                                           [1, 1, tf.shape(intent_capsule)[2]])\n","        intent_capsule_max = tf.reduce_sum(tf.multiply(intent_capsule, tf.cast(pred_intent_index_onehot, tf.float32)),\n","                                           axis=1,\n","                                           keepdims=False)\n","        caps_ihat = tf.expand_dims(tf.expand_dims(intent_capsule_max, 1), 3)\n","        with tf.variable_scope('slot_capsule', reuse=True):\n","            slot_capsule_new, routing_weight_new, routing_logits_new = sc(H, sequence_length, caps_ihat=caps_ihat,\n","                                                                          re_routing=True)\n","        with tf.variable_scope('slot_proj', reuse=True):\n","            slot_p_new = tf.reshape(routing_logits_new, [-1, slot_size])\n","        outputs = [slot_p_new, intent, routing_weight_new, intent_routing_weight]\n","    return outputs"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8gDTVaeV9Wk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595696510079,"user_tz":-330,"elapsed":2393961,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"469bf5be-2e19-44be-e613-6f91f08a8f24"},"source":["# -*- coding: utf-8 -*-\n","import argparse\n","import logging\n","import os\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","\n","# Processing Units logs\n","log_device_placement = False\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n","\n","parser = argparse.ArgumentParser(allow_abbrev=False)\n","# Network\n","parser.add_argument(\"--num_units\", type=int, default=512, help=\"Network size.\", dest='layer_size',required=False)\n","parser.add_argument(\"--embed_dim\", type=int, default=1024, help=\"Embedding dim.\", dest='embed_dim',required=False)\n","parser.add_argument(\"--intent_dim\", type=int, default=128, help=\"Intent dim.\", dest='intent_dim',required=False)\n","parser.add_argument(\"--model_type\", type=str, default='full', help=\"\"\"full(default) | without_rerouting.\n","                                                                    full: full model with re-routing\n","                                                                    without_rerouting: model without re-routing\"\"\",required=False)\n","parser.add_argument(\"--num_rnn\", type=int, default=1, help=\"Num of layers for stacked RNNs.\",required=False)\n","parser.add_argument(\"--iter_slot\", type=int, default=2, help=\"Num of iteration for slots.\",required=False)\n","parser.add_argument(\"--iter_intent\", type=int, default=2, help=\"Num of iteration for intents.\",required=False)\n","\n","# Training Environment\n","parser.add_argument(\"--optimizer\", type=str, default='adam', help=\"Optimizer.\",required=False)\n","parser.add_argument(\"--batch_size\", type=int, default=8, help=\"Batch size.\",required=False)\n","parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"Batch size.\",required=False)\n","parser.add_argument(\"--margin\", type=float, default=0.4, help=\"Margin in the max-margin loss.\",required=False)\n","parser.add_argument(\"--downweight\", type=float, default=0.5, help=\"Downweight for the max-margin loss.\",required=False)\n","parser.add_argument(\"--max_epochs\", type=int, default=50, help=\"Max epochs to train.\",required=False)\n","parser.add_argument(\"--no_early_stop\", action='store_false', dest='early_stop',\n","                    help=\"Disable early stop, which is based on sentence level accuracy.\",required=False)\n","parser.add_argument(\"--patience\", type=int, default=10, help=\"Patience to wait before stop.\",required=False)\n","parser.add_argument(\"--run_name\", type=str, default='capsule_nlu', help=\"Run name.\",required=False)\n","\n","# Model and Data\n","parser.add_argument(\"--dataset\", type=str, default='snips', help=\"\"\"Type 'snips' to use dataset provided by us or enter what ever you named your own dataset.\n","                Note, if you don't want to use this part, enter --dataset=''. It can not be None\"\"\",required=False)\n","parser.add_argument(\"--model_path\", type=str, default='./model', help=\"Path to save model.\",required=False)\n","parser.add_argument(\"--vocab_path\", type=str, default='./vocab', help=\"Path to vocabulary files.\",required=False)\n","parser.add_argument(\"--train_data_path\", type=str, default='train', help=\"Path to training data files.\",required=False)\n","parser.add_argument(\"--test_data_path\", type=str, default='test', help=\"Path to testing data files.\",required=False)\n","parser.add_argument(\"--valid_data_path\", type=str, default='valid', help=\"Path to validation data files.\",required=False)\n","parser.add_argument(\"--input_file\", type=str, default='seq.in', help=\"Input file name.\",required=False)\n","parser.add_argument(\"--slot_file\", type=str, default='seq.out', help=\"Slot file name.\",required=False)\n","parser.add_argument(\"--intent_file\", type=str, default='label', help=\"Intent file name.\",required=False)\n","\n","arg = parser.parse_args(''.split())\n","logs_path = './log/' + arg.run_name\n","\n","# Print arguments\n","for k, v in sorted(vars(arg).items()):\n","    print(k, '=', v)\n","print()\n","\n","# Optimzers\n","if arg.optimizer == 'adam':\n","    opt = tf.train.AdamOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'rmsprop':\n","    opt = tf.train.RMSPropOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'adadelta':\n","    opt = tf.train.AdadeltaOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'adagrad':\n","    opt = tf.train.AdagradOptimizer(learning_rate=arg.learning_rate)\n","else:\n","    print('unknown optimizer!')\n","    exit(1)\n","\n","# Ablation\n","if arg.model_type == 'full':\n","    re_routing = True\n","elif arg.model_type == 'without_rerouting':\n","    re_routing = False\n","else:\n","    print('unknown model type!')\n","    exit(1)\n","\n","# Full path to data will be: ./data/ + dataset + train/test/valid\n","if arg.dataset == None:\n","    print('name of dataset can not be None')\n","    exit(1)\n","elif arg.dataset == 'snips':\n","    print('use snips dataset')\n","elif arg.dataset == 'atis':\n","    print('use atis dataset')\n","else:\n","    print('use own dataset: ', arg.dataset)\n","\n","full_train_path = os.path.join('./data', arg.dataset, arg.train_data_path)\n","full_test_path = os.path.join('./data', arg.dataset, arg.test_data_path)\n","full_valid_path = os.path.join('./data', arg.dataset, arg.valid_data_path)\n","\n","# Create vocabulary and save vocab files in ./vocab\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'in_vocab'))\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.slot_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'slot_vocab'))\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.intent_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'intent_vocab'),\n","                 pad=False, unk=False)\n","\n","# Load vocab\n","in_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'in_vocab'))\n","slot_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'slot_vocab'))\n","intent_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'intent_vocab'))\n","intent_dim = arg.intent_dim\n","\n","\n","# Create training model\n","tf.reset_default_graph()\n","input_data = tf.placeholder(tf.int32, [None, None], name='inputs')  # word ids\n","sequence_length = tf.placeholder(tf.int32, [None], name=\"sequence_length\")  # sequence length\n","global_step = tf.Variable(0, trainable=False, name='global_step')\n","slots = tf.placeholder(tf.int32, [None, None], name='slots')  # slot ids\n","slot_weights = tf.placeholder(tf.float32, [None, None], name='slot_weights')  # sequence mask\n","intent = tf.placeholder(tf.int32, [None], name='intent')  # intent label\n","\n","with tf.variable_scope('model'):\n","    training_outputs = build_model(input_data, len(in_vocab['vocab']), sequence_length, len(slot_vocab['vocab']) - 2,\n","                                   len(intent_vocab['vocab']), intent_dim,\n","                                   layer_size=arg.layer_size, embed_dim=arg.embed_dim, num_rnn=arg.num_rnn,\n","                                   isTraining=True, iter_slot=arg.iter_slot, iter_intent=arg.iter_intent,\n","                                   re_routing=re_routing)\n","\n","slots_shape = tf.shape(slots)\n","slots_reshape = tf.reshape(slots, [-1])\n","slot_outputs = training_outputs[0]\n","intent_outputs = training_outputs[1]\n","slot_routing_weight = training_outputs[2]\n","intent_routing_weight = training_outputs[3]\n","intent_outputs_norm = tf.norm(intent_outputs, axis=-1)\n","\n","# Define slot loss\n","with tf.variable_scope('slot_loss'):\n","    slots_reshape_onehot = tf.one_hot(slots_reshape, len(slot_vocab['vocab']) - 2)  # [16*18, 74]\n","    crossent = tf.nn.softmax_cross_entropy_with_logits_v2(labels=slots_reshape_onehot, logits=slot_outputs)\n","    crossent = tf.reshape(crossent, slots_shape)\n","    slot_loss = tf.reduce_sum(crossent * slot_weights, 1)\n","    total_size = tf.reduce_sum(slot_weights, 1)\n","    total_size += 1e-12\n","    slot_loss = slot_loss / total_size\n","\n","# Define intent loss\n","with tf.variable_scope('intent_loss'):\n","    intent_onehot = tf.one_hot(intent, len(intent_vocab['vocab']))\n","    marginloss =margin_loss(labels=intent_onehot, raw_logits=intent_outputs_norm, margin=arg.margin,\n","                             downweight=arg.downweight)\n","    intent_loss = tf.reduce_mean(marginloss, axis=-1)\n","\n","# Specify the learning environment\n","params = tf.trainable_variables()\n","slot_params = []\n","for p in params:\n","    if 'slot' in p.name or 'embedding' in p.name:\n","        slot_params.append(p)\n","intent_params = []\n","for p in params:\n","    if 'intent' in p.name:\n","        intent_params.append(p)\n","\n","gradients_slot = tf.gradients(slot_loss, slot_params)\n","gradients_intent = tf.gradients(intent_loss, intent_params)\n","\n","clipped_gradients_slot, norm_slot = tf.clip_by_global_norm(gradients_slot, 5.0)\n","clipped_gradients_intent, norm_intent = tf.clip_by_global_norm(gradients_intent, 5.0)\n","\n","gradient_norm_slot = norm_slot\n","gradient_norm_intent = norm_intent\n","\n","update_slot = opt.apply_gradients(zip(clipped_gradients_slot, slot_params))\n","update_intent = opt.apply_gradients(zip(clipped_gradients_intent, intent_params), global_step=global_step)\n","\n","training_outputs = [global_step, slot_loss, intent_loss, slot_routing_weight, intent_routing_weight, update_slot,\n","                    update_intent, gradient_norm_slot, gradient_norm_intent]\n","inputs = [input_data, sequence_length, slots, slot_weights, intent]\n","\n","# Create Inference Model\n","with tf.variable_scope('model', reuse=True):\n","    inference_outputs = build_model(input_data, len(in_vocab['vocab']), sequence_length, len(slot_vocab['vocab']) - 2,\n","                                    len(intent_vocab['vocab']), intent_dim,\n","                                    layer_size=arg.layer_size, embed_dim=arg.embed_dim, num_rnn=arg.num_rnn,\n","                                    isTraining=False, iter_slot=arg.iter_slot, iter_intent=arg.iter_intent,\n","                                    re_routing=re_routing)\n","\n","inference_intent_outputs_norm = tf.norm(inference_outputs[1], axis=-1)\n","inference_outputs = [inference_outputs[0], inference_outputs[1], inference_intent_outputs_norm, inference_outputs[2],\n","                     inference_outputs[3]]\n","inference_inputs = [input_data, sequence_length]\n","\n","saver = tf.train.Saver()\n","\n","# Start Training\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=False, log_device_placement=log_device_placement)) as sess:\n","    sess.run(tf.global_variables_initializer())\n","    logging.info('Training Start')\n","    epochs = 0\n","    eval_slot_loss = 0.0\n","    eval_intent_loss = 0.0\n","    eval_slot_p = 0.0\n","    data_processor = None\n","    line = 0\n","    num_loss = 0\n","    step = 0\n","    no_improve = 0\n","\n","    # variables to store highest values among epochs, only use 'valid_err' for now\n","    valid_slot = 0\n","    test_slot = 0\n","    valid_intent = 0\n","    test_intent = 0\n","    valid_err = 0\n","    test_err = 0\n","\n","    # Load from saved checkpoints\n","    # saver.restore(sess, './model/' + arg.run_name + \".ckpt\")\n","    # logging.info(\"Model restored.\")\n","\n","    while True:\n","        if data_processor == None:\n","            data_processor = DataProcessor(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.input_file),\n","                                           os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.slot_file),\n","                                           os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.intent_file), in_vocab, slot_vocab,\n","                                           intent_vocab, shuffle=True)\n","        in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq = data_processor.get_batch(\n","            arg.batch_size)\n","        feed_dict = {input_data.name: in_data, slots.name: slot_data, slot_weights.name: slot_weight,\n","                     sequence_length.name: length, intent.name: intents}\n","\n","        if len(in_data) != 0:\n","            ret = sess.run(training_outputs, feed_dict)\n","            eval_slot_loss += np.mean(ret[1])\n","            eval_intent_loss += np.mean(ret[2])\n","\n","            line += len(in_data)\n","            step = ret[0]\n","            num_loss += 1\n","\n","        if data_processor.end == 1:\n","            line = 0\n","            data_processor = None\n","            epochs += 1\n","            logging.info('Step: ' + str(step))\n","            logging.info('Epochs: ' + str(epochs))\n","            logging.info('Slot Loss: ' + str(eval_slot_loss / num_loss))\n","            logging.info('Intent Loss: ' + str(eval_intent_loss / num_loss))\n","            num_loss = 0\n","            eval_slot_loss = 0.0\n","            eval_slot_p = 0.0\n","            eval_intent_loss = 0.0\n","            save_path = os.path.join(arg.model_path, '_step_' + str(step) + '_epochs_' + str(epochs) + '.ckpt')\n","\n","\n","            def valid(in_path, slot_path, intent_path):\n","                data_processor_valid = DataProcessor(in_path, slot_path, intent_path, in_vocab, slot_vocab,\n","                                                     intent_vocab)\n","                pred_intents = []\n","                correct_intents = []\n","                slot_outputs = []\n","                correct_slots = []\n","                input_words = []\n","\n","                while True:\n","                    in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq = data_processor_valid.get_batch(\n","                        arg.batch_size)\n","                    feed_dict = {input_data.name: in_data, sequence_length.name: length}\n","                    if len(in_data) != 0:\n","                        ret = sess.run(inference_outputs, feed_dict)\n","                        for i in ret[2]:\n","                            pred_intents.append(np.argmax(i))\n","                        for i in intents:\n","                            correct_intents.append(i)\n","\n","                        pred_slots = ret[3][-1, :, :, :].reshape((slot_data.shape[0], slot_data.shape[1], -1))\n","                        for p, t, i, l, s in zip(pred_slots, slot_data, in_data, length, slot_seq):\n","                            p = np.argmax(p, 1)\n","                            tmp_pred = []\n","                            tmp_correct = []\n","                            tmp_input = []\n","                            for j in range(l):\n","                                tmp_pred.append(slot_vocab['rev'][p[j]])\n","                                tmp_correct.append(slot_vocab['rev'][t[j]])\n","                                tmp_input.append(in_vocab['rev'][i[j]])\n","\n","                            slot_outputs.append(tmp_pred)\n","                            correct_slots.append(tmp_correct)\n","                            input_words.append(tmp_input)\n","                    if data_processor_valid.end == 1:\n","                        break\n","                pred_intents = np.array(pred_intents)\n","                correct_intents = np.array(correct_intents)\n","                from sklearn.metrics import classification_report\n","                logging.info(classification_report(y_true=correct_intents, y_pred=pred_intents, digits=4))\n","                accuracy = (pred_intents == correct_intents)\n","                semantic_error = accuracy\n","                accuracy = accuracy.astype(float)\n","                accuracy = np.mean(accuracy) * 100.0\n","\n","                index = 0\n","                for t, p in zip(correct_slots, slot_outputs):\n","                    # Process Semantic Error\n","                    if len(t) != len(p):\n","                        raise ValueError('Error!!')\n","\n","                    for j in range(len(t)):\n","                        if p[j] != t[j]:\n","                            semantic_error[index] = False\n","                            break\n","                    index += 1\n","                semantic_error = semantic_error.astype(float)\n","                semantic_error = np.mean(semantic_error) * 100.0\n","\n","                f1, precision, recall = computeF1Score(correct_slots, slot_outputs)\n","                logging.info('slot f1: ' + str(f1))\n","                logging.info('intent accuracy: ' + str(accuracy))\n","                logging.info('semantic error(intent, slots are all correct): ' + str(semantic_error))\n","\n","                return f1, accuracy, semantic_error, pred_intents, correct_intents, slot_outputs, correct_slots, input_words\n","\n","\n","            logging.info('Valid:')\n","            epoch_valid_slot, epoch_valid_intent, epoch_valid_err, valid_pred_intent, valid_correct_intent, valid_pred_slot, valid_correct_slot, valid_words = valid(\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.slot_file),\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.intent_file))\n","\n","            logging.info('Test:')\n","            epoch_test_slot, epoch_test_intent, epoch_test_err, test_pred_intent, test_correct_intent, test_pred_slot, test_correct_slot, test_words = valid(\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.slot_file),\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.intent_file))\n","\n","            if epoch_valid_err <= valid_err:\n","                no_improve += 1\n","            else:\n","                valid_err = epoch_valid_err\n","                no_improve = 0\n","            if epochs == arg.max_epochs:\n","                break\n","            if arg.early_stop:\n","                if no_improve > arg.patience:\n","                    break\n","\n","            save_path = saver.save(sess, './model/' + arg.run_name + \"_\" + str(epochs) + \".ckpt\")\n","            # logging.info(\"Model saved in path: \" + str(save_path))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["batch_size = 8\n","dataset = snips\n","downweight = 0.5\n","early_stop = True\n","embed_dim = 1024\n","input_file = seq.in\n","intent_dim = 128\n","intent_file = label\n","iter_intent = 2\n","iter_slot = 2\n","layer_size = 512\n","learning_rate = 0.001\n","margin = 0.4\n","max_epochs = 50\n","model_path = ./model\n","model_type = full\n","num_rnn = 1\n","optimizer = adam\n","patience = 10\n","run_name = capsule_nlu\n","slot_file = seq.out\n","test_data_path = test\n","train_data_path = train\n","valid_data_path = valid\n","vocab_path = ./vocab\n","\n","use snips dataset\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:12,500 : INFO : NumExpr defaulting to 2 threads.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,198 : WARNING : \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-5a5a7f76549c>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,200 : WARNING : From <ipython-input-7-5a5a7f76549c>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-5a5a7f76549c>:9: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,204 : WARNING : From <ipython-input-7-5a5a7f76549c>:9: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,236 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,238 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,451 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a6d3f28>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,455 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,470 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,565 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a6d3dd8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,590 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,706 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba8a5e9908>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,815 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba8a600320>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,921 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From <ipython-input-6-04bbf396d210>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:13,935 : WARNING : From <ipython-input-6-04bbf396d210>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:14,022 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b36a400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:14,136 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fcf8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:14,224 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7b186940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:14,353 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba7bb5fd68>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:14,433 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7afa3518>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,374 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79cce8d0>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,472 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79de09e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,590 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fba79e141d0>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,686 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fba79e14470>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,763 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,844 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7993aa58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:16,955 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79c60860>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:17,040 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba797c0c18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:17,171 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fba79e143c8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:17,250 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fba7963b668>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:22:19,285 : INFO : Training Start\n","2020-07-25 16:23:54,506 : INFO : Step: 1636\n","2020-07-25 16:23:54,507 : INFO : Epochs: 1\n","2020-07-25 16:23:54,508 : INFO : Slot Loss: 0.45809419609294305\n","2020-07-25 16:23:54,512 : INFO : Intent Loss: 0.006798936320005417\n","2020-07-25 16:23:54,513 : INFO : Valid:\n","2020-07-25 16:23:56,363 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9794    0.9500    0.9645       100\n","           1     0.9898    0.9700    0.9798       100\n","           2     0.9802    0.9900    0.9851       100\n","           3     0.9899    0.9800    0.9849       100\n","           4     0.8547    1.0000    0.9217       100\n","           5     0.9765    0.8300    0.8973       100\n","           6     0.9612    0.9900    0.9754       100\n","\n","    accuracy                         0.9586       700\n","   macro avg     0.9617    0.9586    0.9584       700\n","weighted avg     0.9617    0.9586    0.9584       700\n","\n","2020-07-25 16:23:56,390 : INFO : slot f1: 75.69676700111482\n","2020-07-25 16:23:56,391 : INFO : intent accuracy: 95.85714285714285\n","2020-07-25 16:23:56,394 : INFO : semantic error(intent, slots are all correct): 45.0\n","2020-07-25 16:23:56,396 : INFO : Test:\n","2020-07-25 16:23:58,094 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8901    0.9419    0.9153        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9681    0.9891    0.9785        92\n","           3     0.9870    0.9500    0.9682        80\n","           4     0.8333    0.9813    0.9013       107\n","           5     0.9286    0.7290    0.8168       107\n","           6     0.9837    0.9758    0.9798       124\n","\n","    accuracy                         0.9357       700\n","   macro avg     0.9388    0.9368    0.9350       700\n","weighted avg     0.9387    0.9357    0.9343       700\n","\n","2020-07-25 16:23:58,127 : INFO : slot f1: 74.78211976384594\n","2020-07-25 16:23:58,128 : INFO : intent accuracy: 93.57142857142857\n","2020-07-25 16:23:58,132 : INFO : semantic error(intent, slots are all correct): 44.714285714285715\n","2020-07-25 16:25:36,120 : INFO : Step: 3272\n","2020-07-25 16:25:36,121 : INFO : Epochs: 2\n","2020-07-25 16:25:36,122 : INFO : Slot Loss: 0.0953918769110272\n","2020-07-25 16:25:36,123 : INFO : Intent Loss: 0.001735401441412188\n","2020-07-25 16:25:36,125 : INFO : Valid:\n","2020-07-25 16:25:37,784 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9604    0.9700    0.9652       100\n","           1     0.9706    0.9900    0.9802       100\n","           2     0.9900    0.9900    0.9900       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     1.0000    0.9100    0.9529       100\n","           5     0.9245    0.9800    0.9515       100\n","           6     0.9798    0.9700    0.9749       100\n","\n","    accuracy                         0.9729       700\n","   macro avg     0.9736    0.9729    0.9728       700\n","weighted avg     0.9736    0.9729    0.9728       700\n","\n","2020-07-25 16:25:37,809 : INFO : slot f1: 77.84898300362218\n","2020-07-25 16:25:37,810 : INFO : intent accuracy: 97.28571428571429\n","2020-07-25 16:25:37,815 : INFO : semantic error(intent, slots are all correct): 49.28571428571429\n","2020-07-25 16:25:37,818 : INFO : Test:\n","2020-07-25 16:25:39,584 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8646    0.9651    0.9121        86\n","           1     0.9533    0.9808    0.9668       104\n","           2     0.9780    0.9674    0.9727        92\n","           3     0.9750    0.9750    0.9750        80\n","           4     0.9891    0.8505    0.9146       107\n","           5     0.8707    0.9439    0.9058       107\n","           6     0.9915    0.9435    0.9669       124\n","\n","    accuracy                         0.9443       700\n","   macro avg     0.9460    0.9466    0.9448       700\n","weighted avg     0.9477    0.9443    0.9445       700\n","\n","2020-07-25 16:25:39,611 : INFO : slot f1: 76.95290858725761\n","2020-07-25 16:25:39,612 : INFO : intent accuracy: 94.42857142857143\n","2020-07-25 16:25:39,616 : INFO : semantic error(intent, slots are all correct): 48.714285714285715\n","2020-07-25 16:27:17,974 : INFO : Step: 4908\n","2020-07-25 16:27:17,975 : INFO : Epochs: 3\n","2020-07-25 16:27:17,976 : INFO : Slot Loss: 0.044228655240342786\n","2020-07-25 16:27:17,981 : INFO : Intent Loss: 0.00125247790226753\n","2020-07-25 16:27:17,982 : INFO : Valid:\n","2020-07-25 16:27:19,668 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9515    0.9800    0.9655       100\n","           1     0.9709    1.0000    0.9852       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    0.9900    0.9950       100\n","           4     1.0000    0.9100    0.9529       100\n","           5     0.9608    0.9800    0.9703       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9805    0.9800    0.9799       700\n","weighted avg     0.9805    0.9800    0.9799       700\n","\n","2020-07-25 16:27:19,695 : INFO : slot f1: 80.27019420208276\n","2020-07-25 16:27:19,696 : INFO : intent accuracy: 98.0\n","2020-07-25 16:27:19,699 : INFO : semantic error(intent, slots are all correct): 51.142857142857146\n","2020-07-25 16:27:19,700 : INFO : Test:\n","2020-07-25 16:27:21,462 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8469    0.9651    0.9022        86\n","           1     0.9444    0.9808    0.9623       104\n","           2     0.9785    0.9891    0.9838        92\n","           3     0.9750    0.9750    0.9750        80\n","           4     0.9792    0.8785    0.9261       107\n","           5     0.9314    0.8879    0.9091       107\n","           6     0.9919    0.9839    0.9879       124\n","\n","    accuracy                         0.9500       700\n","   macro avg     0.9496    0.9515    0.9495       700\n","weighted avg     0.9521    0.9500    0.9500       700\n","\n","2020-07-25 16:27:21,489 : INFO : slot f1: 79.02411665731913\n","2020-07-25 16:27:21,490 : INFO : intent accuracy: 95.0\n","2020-07-25 16:27:21,491 : INFO : semantic error(intent, slots are all correct): 50.857142857142854\n","2020-07-25 16:28:59,934 : INFO : Step: 6544\n","2020-07-25 16:28:59,935 : INFO : Epochs: 4\n","2020-07-25 16:28:59,937 : INFO : Slot Loss: 0.024990431073021464\n","2020-07-25 16:28:59,937 : INFO : Intent Loss: 0.0011274764493487389\n","2020-07-25 16:28:59,938 : INFO : Valid:\n","2020-07-25 16:29:01,646 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9000    0.9900    0.9429       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    0.9900    0.9950       100\n","           4     0.9709    1.0000    0.9852       100\n","           5     1.0000    0.9000    0.9474       100\n","           6     0.9899    0.9800    0.9849       100\n","\n","    accuracy                         0.9771       700\n","   macro avg     0.9787    0.9771    0.9772       700\n","weighted avg     0.9787    0.9771    0.9772       700\n","\n","2020-07-25 16:29:01,680 : INFO : slot f1: 80.78762306610409\n","2020-07-25 16:29:01,681 : INFO : intent accuracy: 97.71428571428571\n","2020-07-25 16:29:01,682 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 16:29:01,685 : INFO : Test:\n","2020-07-25 16:29:03,418 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8173    0.9884    0.8947        86\n","           1     0.9714    0.9808    0.9761       104\n","           2     0.9783    0.9783    0.9783        92\n","           3     1.0000    0.9625    0.9809        80\n","           4     0.9444    0.9533    0.9488       107\n","           5     0.9457    0.8131    0.8744       107\n","           6     1.0000    0.9839    0.9919       124\n","\n","    accuracy                         0.9500       700\n","   macro avg     0.9510    0.9514    0.9493       700\n","weighted avg     0.9537    0.9500    0.9500       700\n","\n","2020-07-25 16:29:03,452 : INFO : slot f1: 79.0671536948581\n","2020-07-25 16:29:03,453 : INFO : intent accuracy: 95.0\n","2020-07-25 16:29:03,457 : INFO : semantic error(intent, slots are all correct): 51.28571428571429\n","2020-07-25 16:30:42,175 : INFO : Step: 8180\n","2020-07-25 16:30:42,176 : INFO : Epochs: 5\n","2020-07-25 16:30:42,180 : INFO : Slot Loss: 0.018242871740987588\n","2020-07-25 16:30:42,181 : INFO : Intent Loss: 0.000995063947950509\n","2020-07-25 16:30:42,182 : INFO : Valid:\n","2020-07-25 16:30:43,831 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9608    0.9800    0.9703       100\n","           1     1.0000    0.9900    0.9950       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9800    0.9800    0.9800       100\n","           5     0.9794    0.9500    0.9645       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9857       700\n","   macro avg     0.9858    0.9857    0.9857       700\n","weighted avg     0.9858    0.9857    0.9857       700\n","\n","2020-07-25 16:30:43,856 : INFO : slot f1: 79.55119214586256\n","2020-07-25 16:30:43,857 : INFO : intent accuracy: 98.57142857142858\n","2020-07-25 16:30:43,859 : INFO : semantic error(intent, slots are all correct): 51.0\n","2020-07-25 16:30:43,860 : INFO : Test:\n","2020-07-25 16:30:45,637 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9011    0.9535    0.9266        86\n","           1     0.9714    0.9808    0.9761       104\n","           2     0.9785    0.9891    0.9838        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9712    0.9439    0.9573       107\n","           5     0.9333    0.9159    0.9245       107\n","           6     1.0000    1.0000    1.0000       124\n","\n","    accuracy                         0.9657       700\n","   macro avg     0.9651    0.9655    0.9651       700\n","weighted avg     0.9662    0.9657    0.9658       700\n","\n","2020-07-25 16:30:45,665 : INFO : slot f1: 79.20291888857703\n","2020-07-25 16:30:45,665 : INFO : intent accuracy: 96.57142857142857\n","2020-07-25 16:30:45,668 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 16:32:24,720 : INFO : Step: 9816\n","2020-07-25 16:32:24,721 : INFO : Epochs: 6\n","2020-07-25 16:32:24,722 : INFO : Slot Loss: 0.01496508120378271\n","2020-07-25 16:32:24,724 : INFO : Intent Loss: 0.0010440879098430626\n","2020-07-25 16:32:24,725 : INFO : Valid:\n","2020-07-25 16:32:26,423 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8750    0.9800    0.9245       100\n","           1     1.0000    0.9900    0.9950       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     1.0000    0.9200    0.9583       100\n","           5     0.9065    0.9700    0.9372       100\n","           6     0.9778    0.8800    0.9263       100\n","\n","    accuracy                         0.9629       700\n","   macro avg     0.9656    0.9629    0.9631       700\n","weighted avg     0.9656    0.9629    0.9631       700\n","\n","2020-07-25 16:32:26,459 : INFO : slot f1: 80.33613445378151\n","2020-07-25 16:32:26,460 : INFO : intent accuracy: 96.28571428571429\n","2020-07-25 16:32:26,463 : INFO : semantic error(intent, slots are all correct): 52.0\n","2020-07-25 16:32:26,466 : INFO : Test:\n","2020-07-25 16:32:28,232 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.7727    0.9884    0.8673        86\n","           1     0.9714    0.9808    0.9761       104\n","           2     0.9780    0.9674    0.9727        92\n","           3     0.9873    0.9750    0.9811        80\n","           4     0.9798    0.9065    0.9417       107\n","           5     0.9135    0.8879    0.9005       107\n","           6     1.0000    0.9032    0.9492       124\n","\n","    accuracy                         0.9400       700\n","   macro avg     0.9433    0.9442    0.9412       700\n","weighted avg     0.9472    0.9400    0.9413       700\n","\n","2020-07-25 16:32:28,259 : INFO : slot f1: 79.35177423861414\n","2020-07-25 16:32:28,263 : INFO : intent accuracy: 94.0\n","2020-07-25 16:32:28,266 : INFO : semantic error(intent, slots are all correct): 51.42857142857142\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:32:30,213 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","2020-07-25 16:34:07,206 : INFO : Step: 11452\n","2020-07-25 16:34:07,207 : INFO : Epochs: 7\n","2020-07-25 16:34:07,210 : INFO : Slot Loss: 0.011579431970335853\n","2020-07-25 16:34:07,212 : INFO : Intent Loss: 0.0009605638803851192\n","2020-07-25 16:34:07,214 : INFO : Valid:\n","2020-07-25 16:34:08,894 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9800    0.9800    0.9800       100\n","           1     1.0000    0.9600    0.9796       100\n","           2     0.9901    1.0000    0.9950       100\n","           3     0.9804    1.0000    0.9901       100\n","           4     0.9794    0.9500    0.9645       100\n","           5     0.9608    0.9800    0.9703       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9814       700\n","   macro avg     0.9816    0.9814    0.9814       700\n","weighted avg     0.9816    0.9814    0.9814       700\n","\n","2020-07-25 16:34:08,920 : INFO : slot f1: 79.75528364849833\n","2020-07-25 16:34:08,921 : INFO : intent accuracy: 98.14285714285714\n","2020-07-25 16:34:08,924 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 16:34:08,927 : INFO : Test:\n","2020-07-25 16:34:10,720 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9239    0.9884    0.9551        86\n","           1     0.9808    0.9808    0.9808       104\n","           2     0.9783    0.9783    0.9783        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9899    0.9159    0.9515       107\n","           5     0.9259    0.9346    0.9302       107\n","           6     1.0000    1.0000    1.0000       124\n","\n","    accuracy                         0.9700       700\n","   macro avg     0.9695    0.9711    0.9699       700\n","weighted avg     0.9707    0.9700    0.9700       700\n","\n","2020-07-25 16:34:10,745 : INFO : slot f1: 79.68662562954673\n","2020-07-25 16:34:10,746 : INFO : intent accuracy: 97.0\n","2020-07-25 16:34:10,746 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 16:35:49,257 : INFO : Step: 13088\n","2020-07-25 16:35:49,258 : INFO : Epochs: 8\n","2020-07-25 16:35:49,259 : INFO : Slot Loss: 0.00902707284053232\n","2020-07-25 16:35:49,260 : INFO : Intent Loss: 0.0008642537522428918\n","2020-07-25 16:35:49,261 : INFO : Valid:\n","2020-07-25 16:35:50,993 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9804    1.0000    0.9901       100\n","           1     1.0000    1.0000    1.0000       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    0.9700    0.9848       100\n","           4     0.9800    0.9800    0.9800       100\n","           5     0.9519    0.9900    0.9706       100\n","           6     1.0000    0.9800    0.9899       100\n","\n","    accuracy                         0.9871       700\n","   macro avg     0.9875    0.9871    0.9872       700\n","weighted avg     0.9875    0.9871    0.9872       700\n","\n","2020-07-25 16:35:51,018 : INFO : slot f1: 80.73446327683615\n","2020-07-25 16:35:51,020 : INFO : intent accuracy: 98.71428571428571\n","2020-07-25 16:35:51,022 : INFO : semantic error(intent, slots are all correct): 52.0\n","2020-07-25 16:35:51,024 : INFO : Test:\n","2020-07-25 16:35:52,808 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9032    0.9767    0.9385        86\n","           1     0.9720    1.0000    0.9858       104\n","           2     0.9785    0.9891    0.9838        92\n","           3     1.0000    0.9625    0.9809        80\n","           4     0.9510    0.9065    0.9282       107\n","           5     0.8991    0.9159    0.9074       107\n","           6     1.0000    0.9597    0.9794       124\n","\n","    accuracy                         0.9571       700\n","   macro avg     0.9577    0.9586    0.9577       700\n","weighted avg     0.9582    0.9571    0.9573       700\n","\n","2020-07-25 16:35:52,836 : INFO : slot f1: 80.11299435028248\n","2020-07-25 16:35:52,837 : INFO : intent accuracy: 95.71428571428572\n","2020-07-25 16:35:52,838 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 16:37:32,151 : INFO : Step: 14724\n","2020-07-25 16:37:32,152 : INFO : Epochs: 9\n","2020-07-25 16:37:32,155 : INFO : Slot Loss: 0.008223322614672783\n","2020-07-25 16:37:32,156 : INFO : Intent Loss: 0.0009415389430806946\n","2020-07-25 16:37:32,159 : INFO : Valid:\n","2020-07-25 16:37:33,984 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9515    0.9800    0.9655       100\n","           1     0.9709    1.0000    0.9852       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     1.0000    0.9400    0.9691       100\n","           5     0.9524    1.0000    0.9756       100\n","           6     1.0000    0.9400    0.9691       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9807    0.9800    0.9799       700\n","weighted avg     0.9807    0.9800    0.9799       700\n","\n","2020-07-25 16:37:34,013 : INFO : slot f1: 80.95909732016925\n","2020-07-25 16:37:34,014 : INFO : intent accuracy: 98.0\n","2020-07-25 16:37:34,016 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 16:37:34,017 : INFO : Test:\n","2020-07-25 16:37:35,812 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8252    0.9884    0.8995        86\n","           1     0.9720    1.0000    0.9858       104\n","           2     0.9891    0.9891    0.9891        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9798    0.9065    0.9417       107\n","           5     0.9074    0.9159    0.9116       107\n","           6     1.0000    0.8871    0.9402       124\n","\n","    accuracy                         0.9500       700\n","   macro avg     0.9516    0.9553    0.9517       700\n","weighted avg     0.9543    0.9500    0.9504       700\n","\n","2020-07-25 16:37:35,841 : INFO : slot f1: 79.56019171130532\n","2020-07-25 16:37:35,842 : INFO : intent accuracy: 95.0\n","2020-07-25 16:37:35,843 : INFO : semantic error(intent, slots are all correct): 51.28571428571429\n","2020-07-25 16:39:14,653 : INFO : Step: 16360\n","2020-07-25 16:39:14,654 : INFO : Epochs: 10\n","2020-07-25 16:39:14,655 : INFO : Slot Loss: 0.006802921178281671\n","2020-07-25 16:39:14,656 : INFO : Intent Loss: 0.0005886413944476685\n","2020-07-25 16:39:14,657 : INFO : Valid:\n","2020-07-25 16:39:16,356 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8750    0.9800    0.9245       100\n","           1     1.0000    0.9900    0.9950       100\n","           2     0.9900    0.9900    0.9900       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     1.0000    0.9700    0.9848       100\n","           5     0.9697    0.9600    0.9648       100\n","           6     0.9891    0.9100    0.9479       100\n","\n","    accuracy                         0.9714       700\n","   macro avg     0.9734    0.9714    0.9717       700\n","weighted avg     0.9734    0.9714    0.9717       700\n","\n","2020-07-25 16:39:16,387 : INFO : slot f1: 80.5735170087152\n","2020-07-25 16:39:16,388 : INFO : intent accuracy: 97.14285714285714\n","2020-07-25 16:39:16,390 : INFO : semantic error(intent, slots are all correct): 53.42857142857142\n","2020-07-25 16:39:16,392 : INFO : Test:\n","2020-07-25 16:39:18,176 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8485    0.9767    0.9081        86\n","           1     0.9904    0.9904    0.9904       104\n","           2     0.9890    0.9783    0.9836        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     0.9802    0.9252    0.9519       107\n","           5     0.9018    0.9439    0.9224       107\n","           6     1.0000    0.9113    0.9536       124\n","\n","    accuracy                         0.9571       700\n","   macro avg     0.9586    0.9608    0.9586       700\n","weighted avg     0.9605    0.9571    0.9577       700\n","\n","2020-07-25 16:39:18,203 : INFO : slot f1: 79.79626485568761\n","2020-07-25 16:39:18,204 : INFO : intent accuracy: 95.71428571428572\n","2020-07-25 16:39:18,207 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 16:40:58,447 : INFO : Step: 17996\n","2020-07-25 16:40:58,448 : INFO : Epochs: 11\n","2020-07-25 16:40:58,451 : INFO : Slot Loss: 0.005516019725196635\n","2020-07-25 16:40:58,452 : INFO : Intent Loss: 0.0005103122506259991\n","2020-07-25 16:40:58,453 : INFO : Valid:\n","2020-07-25 16:41:00,168 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9074    0.9800    0.9423       100\n","           1     1.0000    0.9900    0.9950       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     1.0000    0.9500    0.9744       100\n","           5     0.9700    0.9700    0.9700       100\n","           6     0.9898    0.9700    0.9798       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9796    0.9786    0.9788       700\n","weighted avg     0.9796    0.9786    0.9788       700\n","\n","2020-07-25 16:41:00,196 : INFO : slot f1: 80.98194130925508\n","2020-07-25 16:41:00,197 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 16:41:00,202 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 16:41:00,203 : INFO : Test:\n","2020-07-25 16:41:01,984 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8776    1.0000    0.9348        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9890    0.9783    0.9836        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9612    0.9252    0.9429       107\n","           5     0.9412    0.8972    0.9187       107\n","           6     1.0000    0.9919    0.9960       124\n","\n","    accuracy                         0.9643       700\n","   macro avg     0.9643    0.9654    0.9641       700\n","weighted avg     0.9658    0.9643    0.9644       700\n","\n","2020-07-25 16:41:02,014 : INFO : slot f1: 80.49745618993782\n","2020-07-25 16:41:02,015 : INFO : intent accuracy: 96.42857142857143\n","2020-07-25 16:41:02,018 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 16:42:42,905 : INFO : Step: 19632\n","2020-07-25 16:42:42,906 : INFO : Epochs: 12\n","2020-07-25 16:42:42,907 : INFO : Slot Loss: 0.005856139463638864\n","2020-07-25 16:42:42,911 : INFO : Intent Loss: 0.0006377317350260379\n","2020-07-25 16:42:42,912 : INFO : Valid:\n","2020-07-25 16:42:44,593 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9800    0.9800    0.9800       100\n","           1     1.0000    0.9700    0.9848       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9798    0.9700    0.9749       100\n","           5     0.9434    1.0000    0.9709       100\n","           6     0.9899    0.9800    0.9849       100\n","\n","    accuracy                         0.9843       700\n","   macro avg     0.9847    0.9843    0.9843       700\n","weighted avg     0.9847    0.9843    0.9843       700\n","\n","2020-07-25 16:42:44,621 : INFO : slot f1: 80.97780275358248\n","2020-07-25 16:42:44,622 : INFO : intent accuracy: 98.42857142857143\n","2020-07-25 16:42:44,622 : INFO : semantic error(intent, slots are all correct): 53.85714285714286\n","2020-07-25 16:42:44,625 : INFO : Test:\n","2020-07-25 16:42:46,440 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8660    0.9767    0.9180        86\n","           1     0.9905    1.0000    0.9952       104\n","           2     1.0000    0.9674    0.9834        92\n","           3     0.9873    0.9750    0.9811        80\n","           4     0.9798    0.9065    0.9417       107\n","           5     0.8475    0.9346    0.8889       107\n","           6     1.0000    0.9113    0.9536       124\n","\n","    accuracy                         0.9500       700\n","   macro avg     0.9530    0.9531    0.9517       700\n","weighted avg     0.9543    0.9500    0.9508       700\n","\n","2020-07-25 16:42:46,464 : INFO : slot f1: 78.56943280245878\n","2020-07-25 16:42:46,467 : INFO : intent accuracy: 95.0\n","2020-07-25 16:42:46,468 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 16:44:26,473 : INFO : Step: 21268\n","2020-07-25 16:44:26,475 : INFO : Epochs: 13\n","2020-07-25 16:44:26,476 : INFO : Slot Loss: 0.005449581433828018\n","2020-07-25 16:44:26,478 : INFO : Intent Loss: 0.0005811842071830754\n","2020-07-25 16:44:26,478 : INFO : Valid:\n","2020-07-25 16:44:28,215 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8673    0.9800    0.9202       100\n","           1     0.9804    1.0000    0.9901       100\n","           2     0.9899    0.9800    0.9849       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     1.0000    0.9500    0.9744       100\n","           5     0.9897    0.9600    0.9746       100\n","           6     0.9787    0.9200    0.9485       100\n","\n","    accuracy                         0.9700       700\n","   macro avg     0.9723    0.9700    0.9704       700\n","weighted avg     0.9723    0.9700    0.9704       700\n","\n","2020-07-25 16:44:28,238 : INFO : slot f1: 80.47138047138048\n","2020-07-25 16:44:28,240 : INFO : intent accuracy: 97.0\n","2020-07-25 16:44:28,241 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n","2020-07-25 16:44:28,243 : INFO : Test:\n","2020-07-25 16:44:30,050 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.7818    1.0000    0.8776        86\n","           1     0.9720    1.0000    0.9858       104\n","           2     0.9889    0.9674    0.9780        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     0.9796    0.8972    0.9366       107\n","           5     0.9231    0.8972    0.9100       107\n","           6     1.0000    0.8952    0.9447       124\n","\n","    accuracy                         0.9457       700\n","   macro avg     0.9493    0.9510    0.9475       700\n","weighted avg     0.9527    0.9457    0.9467       700\n","\n","2020-07-25 16:44:30,078 : INFO : slot f1: 79.60618846694796\n","2020-07-25 16:44:30,081 : INFO : intent accuracy: 94.57142857142857\n","2020-07-25 16:44:30,081 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 16:46:09,807 : INFO : Step: 22904\n","2020-07-25 16:46:09,808 : INFO : Epochs: 14\n","2020-07-25 16:46:09,809 : INFO : Slot Loss: 0.0032394928385541867\n","2020-07-25 16:46:09,812 : INFO : Intent Loss: 0.0003936981485913327\n","2020-07-25 16:46:09,815 : INFO : Valid:\n","2020-07-25 16:46:11,505 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9238    0.9700    0.9463       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     1.0000    0.9500    0.9744       100\n","           5     0.9900    0.9900    0.9900       100\n","           6     0.9608    0.9800    0.9703       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9806    0.9800    0.9801       700\n","weighted avg     0.9806    0.9800    0.9801       700\n","\n","2020-07-25 16:46:11,534 : INFO : slot f1: 80.32602585722316\n","2020-07-25 16:46:11,535 : INFO : intent accuracy: 98.0\n","2020-07-25 16:46:11,536 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n","2020-07-25 16:46:11,538 : INFO : Test:\n","2020-07-25 16:46:13,365 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9140    0.9884    0.9497        86\n","           1     0.9903    0.9808    0.9855       104\n","           2     0.9787    1.0000    0.9892        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9794    0.8879    0.9314       107\n","           5     0.8919    0.9252    0.9083       107\n","           6     0.9919    0.9919    0.9919       124\n","\n","    accuracy                         0.9629       700\n","   macro avg     0.9637    0.9642    0.9633       700\n","weighted avg     0.9641    0.9629    0.9629       700\n","\n","2020-07-25 16:46:13,391 : INFO : slot f1: 80.29238122012933\n","2020-07-25 16:46:13,392 : INFO : intent accuracy: 96.28571428571429\n","2020-07-25 16:46:13,394 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 16:47:53,755 : INFO : Step: 24540\n","2020-07-25 16:47:53,757 : INFO : Epochs: 15\n","2020-07-25 16:47:53,757 : INFO : Slot Loss: 0.004031144569993978\n","2020-07-25 16:47:53,761 : INFO : Intent Loss: 0.000573757886820979\n","2020-07-25 16:47:53,764 : INFO : Valid:\n","2020-07-25 16:47:55,444 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9889    0.8900    0.9368       100\n","           1     1.0000    0.9700    0.9848       100\n","           2     0.9899    0.9800    0.9849       100\n","           3     1.0000    0.9500    0.9744       100\n","           4     0.9780    0.8900    0.9319       100\n","           5     0.7937    1.0000    0.8850       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9543       700\n","   macro avg     0.9616    0.9543    0.9554       700\n","weighted avg     0.9616    0.9543    0.9554       700\n","\n","2020-07-25 16:47:55,471 : INFO : slot f1: 79.9326410328375\n","2020-07-25 16:47:55,472 : INFO : intent accuracy: 95.42857142857143\n","2020-07-25 16:47:55,473 : INFO : semantic error(intent, slots are all correct): 50.28571428571429\n","2020-07-25 16:47:55,474 : INFO : Test:\n","2020-07-25 16:47:57,282 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9861    0.8256    0.8987        86\n","           1     1.0000    0.9904    0.9952       104\n","           2     0.9884    0.9239    0.9551        92\n","           3     1.0000    0.8875    0.9404        80\n","           4     0.9892    0.8598    0.9200       107\n","           5     0.6883    0.9907    0.8123       107\n","           6     1.0000    0.9758    0.9878       124\n","\n","    accuracy                         0.9271       700\n","   macro avg     0.9503    0.9220    0.9299       700\n","weighted avg     0.9475    0.9271    0.9310       700\n","\n","2020-07-25 16:47:57,309 : INFO : slot f1: 79.4158944116821\n","2020-07-25 16:47:57,310 : INFO : intent accuracy: 92.71428571428572\n","2020-07-25 16:47:57,311 : INFO : semantic error(intent, slots are all correct): 52.0\n","2020-07-25 16:49:36,922 : INFO : Step: 26176\n","2020-07-25 16:49:36,923 : INFO : Epochs: 16\n","2020-07-25 16:49:36,924 : INFO : Slot Loss: 0.0033457800157027317\n","2020-07-25 16:49:36,927 : INFO : Intent Loss: 0.0005174574260162925\n","2020-07-25 16:49:36,929 : INFO : Valid:\n","2020-07-25 16:49:38,644 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9896    0.9500    0.9694       100\n","           1     1.0000    0.9900    0.9950       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9896    0.9500    0.9694       100\n","           5     0.9346    1.0000    0.9662       100\n","           6     0.9709    1.0000    0.9852       100\n","\n","    accuracy                         0.9829       700\n","   macro avg     0.9835    0.9829    0.9829       700\n","weighted avg     0.9835    0.9829    0.9829       700\n","\n","2020-07-25 16:49:38,670 : INFO : slot f1: 80.9001406469761\n","2020-07-25 16:49:38,671 : INFO : intent accuracy: 98.28571428571429\n","2020-07-25 16:49:38,672 : INFO : semantic error(intent, slots are all correct): 53.0\n","2020-07-25 16:49:38,676 : INFO : Test:\n","2020-07-25 16:49:40,471 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9659    0.9884    0.9770        86\n","           1     0.9904    0.9904    0.9904       104\n","           2     0.9889    0.9674    0.9780        92\n","           3     0.9875    0.9875    0.9875        80\n","           4     0.9897    0.8972    0.9412       107\n","           5     0.9043    0.9720    0.9369       107\n","           6     0.9841    1.0000    0.9920       124\n","\n","    accuracy                         0.9714       700\n","   macro avg     0.9730    0.9718    0.9719       700\n","weighted avg     0.9725    0.9714    0.9714       700\n","\n","2020-07-25 16:49:40,498 : INFO : slot f1: 81.33107727016356\n","2020-07-25 16:49:40,498 : INFO : intent accuracy: 97.14285714285714\n","2020-07-25 16:49:40,501 : INFO : semantic error(intent, slots are all correct): 54.0\n","2020-07-25 16:51:20,506 : INFO : Step: 27812\n","2020-07-25 16:51:20,507 : INFO : Epochs: 17\n","2020-07-25 16:51:20,510 : INFO : Slot Loss: 0.003098270725474543\n","2020-07-25 16:51:20,511 : INFO : Intent Loss: 0.00040006789669326135\n","2020-07-25 16:51:20,514 : INFO : Valid:\n","2020-07-25 16:51:22,196 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9600    0.9796       100\n","           1     0.9900    0.9900    0.9900       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9892    0.9200    0.9534       100\n","           5     0.9174    1.0000    0.9569       100\n","           6     0.9709    1.0000    0.9852       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9811    0.9800    0.9800       700\n","weighted avg     0.9811    0.9800    0.9800       700\n","\n","2020-07-25 16:51:22,222 : INFO : slot f1: 80.58361391694726\n","2020-07-25 16:51:22,223 : INFO : intent accuracy: 98.0\n","2020-07-25 16:51:22,225 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 16:51:22,226 : INFO : Test:\n","2020-07-25 16:51:24,037 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9438    0.9767    0.9600        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9783    0.9783    0.9783        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     0.9897    0.8972    0.9412       107\n","           5     0.8870    0.9533    0.9189       107\n","           6     1.0000    0.9839    0.9919       124\n","\n","    accuracy                         0.9671       700\n","   macro avg     0.9685    0.9685    0.9680       700\n","weighted avg     0.9686    0.9671    0.9673       700\n","\n","2020-07-25 16:51:24,068 : INFO : slot f1: 81.26232741617356\n","2020-07-25 16:51:24,069 : INFO : intent accuracy: 96.71428571428572\n","2020-07-25 16:51:24,070 : INFO : semantic error(intent, slots are all correct): 53.714285714285715\n","2020-07-25 16:53:04,883 : INFO : Step: 29448\n","2020-07-25 16:53:04,884 : INFO : Epochs: 18\n","2020-07-25 16:53:04,886 : INFO : Slot Loss: 0.0024333030283590074\n","2020-07-25 16:53:04,887 : INFO : Intent Loss: 0.0003847132173978924\n","2020-07-25 16:53:04,888 : INFO : Valid:\n","2020-07-25 16:53:06,568 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9510    0.9700    0.9604       100\n","           1     0.9706    0.9900    0.9802       100\n","           2     1.0000    0.9700    0.9848       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9796    0.9600    0.9697       100\n","           5     0.9612    0.9900    0.9754       100\n","           6     0.9898    0.9700    0.9798       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9789    0.9786    0.9786       700\n","weighted avg     0.9789    0.9786    0.9786       700\n","\n","2020-07-25 16:53:06,594 : INFO : slot f1: 80.65241844769403\n","2020-07-25 16:53:06,595 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 16:53:06,597 : INFO : semantic error(intent, slots are all correct): 51.857142857142854\n","2020-07-25 16:53:06,599 : INFO : Test:\n","2020-07-25 16:53:08,433 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9043    0.9884    0.9444        86\n","           1     0.9811    1.0000    0.9905       104\n","           2     0.9783    0.9783    0.9783        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9608    0.9159    0.9378       107\n","           5     0.9065    0.9065    0.9065       107\n","           6     1.0000    0.9516    0.9752       124\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9598    0.9630    0.9609       700\n","weighted avg     0.9609    0.9600    0.9600       700\n","\n","2020-07-25 16:53:08,459 : INFO : slot f1: 80.50847457627118\n","2020-07-25 16:53:08,460 : INFO : intent accuracy: 96.0\n","2020-07-25 16:53:08,462 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 16:54:48,669 : INFO : Step: 31084\n","2020-07-25 16:54:48,670 : INFO : Epochs: 19\n","2020-07-25 16:54:48,670 : INFO : Slot Loss: 0.0035752960306869343\n","2020-07-25 16:54:48,673 : INFO : Intent Loss: 0.00040143891740970154\n","2020-07-25 16:54:48,674 : INFO : Valid:\n","2020-07-25 16:54:50,434 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9604    0.9700    0.9652       100\n","           1     0.9900    0.9900    0.9900       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9895    0.9400    0.9641       100\n","           5     0.9429    0.9900    0.9659       100\n","           6     0.9800    0.9800    0.9800       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9804    0.9800    0.9800       700\n","weighted avg     0.9804    0.9800    0.9800       700\n","\n","2020-07-25 16:54:50,466 : INFO : slot f1: 80.53691275167785\n","2020-07-25 16:54:50,468 : INFO : intent accuracy: 98.0\n","2020-07-25 16:54:50,469 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 16:54:50,471 : INFO : Test:\n","2020-07-25 16:54:52,305 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8586    0.9884    0.9189        86\n","           1     0.9905    1.0000    0.9952       104\n","           2     1.0000    0.9891    0.9945        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9898    0.9065    0.9463       107\n","           5     0.8947    0.9533    0.9231       107\n","           6     1.0000    0.9194    0.9580       124\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9619    0.9635    0.9614       700\n","weighted avg     0.9636    0.9600    0.9605       700\n","\n","2020-07-25 16:54:52,334 : INFO : slot f1: 80.14582164890633\n","2020-07-25 16:54:52,335 : INFO : intent accuracy: 96.0\n","2020-07-25 16:54:52,335 : INFO : semantic error(intent, slots are all correct): 54.0\n","2020-07-25 16:56:32,763 : INFO : Step: 32720\n","2020-07-25 16:56:32,764 : INFO : Epochs: 20\n","2020-07-25 16:56:32,765 : INFO : Slot Loss: 0.0037629874606947846\n","2020-07-25 16:56:32,766 : INFO : Intent Loss: 0.00037834615229367393\n","2020-07-25 16:56:32,769 : INFO : Valid:\n","2020-07-25 16:56:34,483 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9798    0.9700    0.9749       100\n","           1     1.0000    0.9800    0.9899       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9697    0.9600    0.9648       100\n","           5     0.9608    0.9800    0.9703       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9843       700\n","   macro avg     0.9844    0.9843    0.9843       700\n","weighted avg     0.9844    0.9843    0.9843       700\n","\n","2020-07-25 16:56:34,507 : INFO : slot f1: 80.526758195573\n","2020-07-25 16:56:34,510 : INFO : intent accuracy: 98.42857142857143\n","2020-07-25 16:56:34,513 : INFO : semantic error(intent, slots are all correct): 52.57142857142857\n","2020-07-25 16:56:34,518 : INFO : Test:\n","2020-07-25 16:56:36,290 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9121    0.9651    0.9379        86\n","           1     1.0000    1.0000    1.0000       104\n","           2     1.0000    1.0000    1.0000        92\n","           3     1.0000    0.9625    0.9809        80\n","           4     0.9806    0.9439    0.9619       107\n","           5     0.9091    0.9346    0.9217       107\n","           6     1.0000    0.9919    0.9960       124\n","\n","    accuracy                         0.9714       700\n","   macro avg     0.9717    0.9712    0.9712       700\n","weighted avg     0.9723    0.9714    0.9717       700\n","\n","2020-07-25 16:56:36,317 : INFO : slot f1: 80.40597688187201\n","2020-07-25 16:56:36,318 : INFO : intent accuracy: 97.14285714285714\n","2020-07-25 16:56:36,318 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 16:58:16,802 : INFO : Step: 34356\n","2020-07-25 16:58:16,803 : INFO : Epochs: 21\n","2020-07-25 16:58:16,804 : INFO : Slot Loss: 0.002967287643345698\n","2020-07-25 16:58:16,807 : INFO : Intent Loss: 0.0003167794300697594\n","2020-07-25 16:58:16,807 : INFO : Valid:\n","2020-07-25 16:58:18,536 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9515    0.9800    0.9655       100\n","           1     0.9800    0.9800    0.9800       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9796    0.9600    0.9697       100\n","           5     0.9515    0.9800    0.9655       100\n","           6     0.9896    0.9500    0.9694       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9789    0.9786    0.9786       700\n","weighted avg     0.9789    0.9786    0.9786       700\n","\n","2020-07-25 16:58:18,572 : INFO : slot f1: 80.77462812236881\n","2020-07-25 16:58:18,573 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 16:58:18,577 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 16:58:18,578 : INFO : Test:\n","2020-07-25 16:58:20,350 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8763    0.9884    0.9290        86\n","           1     0.9905    1.0000    0.9952       104\n","           2     1.0000    1.0000    1.0000        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9802    0.9252    0.9519       107\n","           5     0.9159    0.9159    0.9159       107\n","           6     1.0000    0.9597    0.9794       124\n","\n","    accuracy                         0.9657       700\n","   macro avg     0.9661    0.9681    0.9664       700\n","weighted avg     0.9675    0.9657    0.9660       700\n","\n","2020-07-25 16:58:20,376 : INFO : slot f1: 80.99127006477049\n","2020-07-25 16:58:20,377 : INFO : intent accuracy: 96.57142857142857\n","2020-07-25 16:58:20,379 : INFO : semantic error(intent, slots are all correct): 55.00000000000001\n","2020-07-25 17:00:00,762 : INFO : Step: 35992\n","2020-07-25 17:00:00,763 : INFO : Epochs: 22\n","2020-07-25 17:00:00,764 : INFO : Slot Loss: 0.0029456853849232816\n","2020-07-25 17:00:00,766 : INFO : Intent Loss: 0.0004852756957807083\n","2020-07-25 17:00:00,769 : INFO : Valid:\n","2020-07-25 17:00:02,508 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9333    0.9800    0.9561       100\n","           1     0.9252    0.9900    0.9565       100\n","           2     1.0000    0.9600    0.9796       100\n","           3     0.9804    1.0000    0.9901       100\n","           4     0.9783    0.9000    0.9375       100\n","           5     0.9505    0.9600    0.9552       100\n","           6     0.9897    0.9600    0.9746       100\n","\n","    accuracy                         0.9643       700\n","   macro avg     0.9653    0.9643    0.9642       700\n","weighted avg     0.9653    0.9643    0.9642       700\n","\n","2020-07-25 17:00:02,536 : INFO : slot f1: 80.4946599213041\n","2020-07-25 17:00:02,537 : INFO : intent accuracy: 96.42857142857143\n","2020-07-25 17:00:02,540 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 17:00:02,541 : INFO : Test:\n","2020-07-25 17:00:04,322 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8936    0.9767    0.9333        86\n","           1     0.9541    1.0000    0.9765       104\n","           2     1.0000    0.9457    0.9721        92\n","           3     0.9753    0.9875    0.9814        80\n","           4     1.0000    0.9065    0.9510       107\n","           5     0.8571    0.9533    0.9027       107\n","           6     1.0000    0.9113    0.9536       124\n","\n","    accuracy                         0.9514       700\n","   macro avg     0.9543    0.9544    0.9529       700\n","weighted avg     0.9555    0.9514    0.9519       700\n","\n","2020-07-25 17:00:04,351 : INFO : slot f1: 79.80823463056966\n","2020-07-25 17:00:04,351 : INFO : intent accuracy: 95.14285714285714\n","2020-07-25 17:00:04,353 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 17:01:44,851 : INFO : Step: 37628\n","2020-07-25 17:01:44,852 : INFO : Epochs: 23\n","2020-07-25 17:01:44,855 : INFO : Slot Loss: 0.003292040083247933\n","2020-07-25 17:01:44,856 : INFO : Intent Loss: 0.0004356923193301383\n","2020-07-25 17:01:44,858 : INFO : Valid:\n","2020-07-25 17:01:46,588 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8448    0.9800    0.9074       100\n","           1     0.9800    0.9800    0.9800       100\n","           2     1.0000    0.9800    0.9899       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9592    0.9400    0.9495       100\n","           5     0.9655    0.8400    0.8984       100\n","           6     0.9901    1.0000    0.9950       100\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9628    0.9600    0.9600       700\n","weighted avg     0.9628    0.9600    0.9600       700\n","\n","2020-07-25 17:01:46,616 : INFO : slot f1: 80.8546527973011\n","2020-07-25 17:01:46,620 : INFO : intent accuracy: 96.0\n","2020-07-25 17:01:46,620 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 17:01:46,624 : INFO : Test:\n","2020-07-25 17:01:48,393 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8019    0.9884    0.8854        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9890    0.9783    0.9836        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9346    0.9346    0.9346       107\n","           5     0.9149    0.8037    0.8557       107\n","           6     1.0000    0.9355    0.9667       124\n","\n","    accuracy                         0.9429       700\n","   macro avg     0.9441    0.9473    0.9436       700\n","weighted avg     0.9470    0.9429    0.9430       700\n","\n","2020-07-25 17:01:48,432 : INFO : slot f1: 80.33755274261604\n","2020-07-25 17:01:48,433 : INFO : intent accuracy: 94.28571428571428\n","2020-07-25 17:01:48,437 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NiT9DJaWPYFB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696510083,"user_tz":-330,"elapsed":2393932,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":[""],"execution_count":8,"outputs":[]}]}