{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Capsule_NLU_for_atis_dataset_privious_intent.ipynb","provenance":[{"file_id":"1DCEektoZZ5NyAtlAcYtFQqYpCtwsIO31","timestamp":1593056674185}],"collapsed_sections":[],"mount_file_id":"1Qyh7QBvhqpe_I6aMdEWpMeSsKxRYSXYb","authorship_tag":"ABX9TyPEgaPACA3pmkdWfGUo8X40"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I5-V0A4GEWyG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"executionInfo":{"status":"ok","timestamp":1595696165405,"user_tz":-330,"elapsed":12991,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"c603aaf7-21c6-48e7-83c2-54c5e6e09378"},"source":["!pip install tensorflow==1.14\n","!pip install tensorflow-gpu==1.14"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.30.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.18.5)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (49.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.0)\n","Requirement already satisfied: tensorflow-gpu==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.0)\n","Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.30.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.12.2)\n","Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.14.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.3.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.18.5)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (49.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oCX3UennU_GG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"ok","timestamp":1595696169252,"user_tz":-330,"elapsed":16825,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"3ae1296e-c1a0-4ff6-f4c8-67541df52e21"},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","def margin_loss(labels, raw_logits, margin=0.4, downweight=0.5):\n","    \"\"\"Penalizes deviations from margin for each logit.\n","    Each wrong logit costs its distance to margin. For negative logits margin is\n","    0.1 and for positives it is 0.9. First subtract 0.5 from all logits. Now\n","    margin is 0.4 from each side.\n","    Args:\n","    labels: tensor, one hot encoding of ground truth.\n","    raw_logits: tensor, model predictions in range [0, 1]\n","    margin: scalar, the margin after subtracting 0.5 from raw_logits.\n","    downweight: scalar, the factor for negative cost.\n","    Returns:\n","    A tensor with cost for each data point of shape [batch_size].\n","    \"\"\"\n","    logits = raw_logits - 0.5\n","    positive_cost = labels * tf.cast(tf.less(logits, margin),\n","                                     tf.float32) * tf.pow(logits - margin, 2)\n","    negative_cost = (1 - labels) * tf.cast(\n","        tf.greater(logits, -margin), tf.float32) * tf.pow(logits + margin, 2)\n","    return 0.5 * positive_cost + downweight * 0.5 * negative_cost\n","\n","\n","def createVocabulary(input_path, output_path, pad=True, unk=True):\n","    if not isinstance(input_path, str):\n","        raise TypeError('input_path should be string')\n","\n","    if not isinstance(output_path, str):\n","        raise TypeError('output_path should be string')\n","\n","    vocab = {}\n","    with open(input_path, 'r') as fd, \\\n","            open(output_path, 'w+') as out:\n","        for line in fd:\n","            line = line.rstrip('\\r\\n')\n","            words = line.split()\n","\n","            for w in words:\n","                if w == '_UNK':\n","                    break\n","                if str.isdigit(w) == True:\n","                    w = '0'\n","                if w in vocab:\n","                    vocab[w] += 1\n","                else:\n","                    vocab[w] = 1\n","        init_vocab = []\n","        if pad:\n","            init_vocab.append('_PAD')\n","        if unk:\n","            init_vocab.append('_UNK')\n","        vocab = sorted(vocab, key=vocab.get, reverse=True) + init_vocab\n","\n","        for v in vocab:\n","            out.write(v + '\\n')\n","\n","\n","def loadVocabulary(path):\n","    if not isinstance(path, str):\n","        raise TypeError('path should be a string')\n","\n","    vocab = []\n","    rev = []\n","    with open(path) as fd:\n","        for line in fd:\n","            line = line.rstrip('\\r\\n')\n","            rev.append(line)\n","        vocab = dict([(x, y) for (y, x) in enumerate(rev)])\n","\n","    return {'vocab': vocab, 'rev': rev}\n","\n","\n","def sentenceToIds(data, vocab, unk):\n","    if not isinstance(vocab, dict):\n","        raise TypeError('vocab should be a dict that contains vocab and rev')\n","    vocab = vocab['vocab']\n","    if isinstance(data, str):\n","        words = data.split()\n","    elif isinstance(data, list):\n","        words = data\n","    else:\n","        raise TypeError('data should be a string or a list contains words')\n","\n","    ids = []\n","    if unk:\n","        for w in words:\n","            if str.isdigit(w) == True:\n","                w = '0'\n","            ids.append(vocab.get(w, vocab['_UNK']))\n","    else:\n","        for w in words:\n","            if str.isdigit(w) == True:\n","                w = '0'\n","            ids.append(vocab.get(w))\n","\n","    return ids\n","\n","\n","def padSentence(s, max_length, vocab):\n","    return s + [vocab['vocab']['_PAD']] * (max_length - len(s))\n","\n","\n","# compute f1 score is modified from conlleval.pl\n","def __startOfChunk(prevTag, tag, prevTagType, tagType, chunkStart=False):\n","    if prevTag == 'B' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'I' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'B':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'I':\n","        chunkStart = True\n","\n","    if prevTag == 'E' and tag == 'E':\n","        chunkStart = True\n","    if prevTag == 'E' and tag == 'I':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'E':\n","        chunkStart = True\n","    if prevTag == 'O' and tag == 'I':\n","        chunkStart = True\n","\n","    if tag != 'O' and tag != '.' and prevTagType != tagType:\n","        chunkStart = True\n","    return chunkStart\n","\n","\n","def __endOfChunk(prevTag, tag, prevTagType, tagType, chunkEnd=False):\n","    if prevTag == 'B' and tag == 'B':\n","        chunkEnd = True\n","    if prevTag == 'B' and tag == 'O':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'B':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'O':\n","        chunkEnd = True\n","\n","    if prevTag == 'E' and tag == 'E':\n","        chunkEnd = True\n","    if prevTag == 'E' and tag == 'I':\n","        chunkEnd = True\n","    if prevTag == 'E' and tag == 'O':\n","        chunkEnd = True\n","    if prevTag == 'I' and tag == 'O':\n","        chunkEnd = True\n","\n","    if prevTag != 'O' and prevTag != '.' and prevTagType != tagType:\n","        chunkEnd = True\n","    return chunkEnd\n","\n","\n","def __splitTagType(tag):\n","    s = tag.split('-')\n","    if len(s) > 2 or len(s) == 0:\n","        raise ValueError('tag format wrong. it must be B-xxx.xxx')\n","    if len(s) == 1:\n","        tag = s[0]\n","        tagType = \"\"\n","    else:\n","        tag = s[0]\n","        tagType = s[1]\n","    return tag, tagType\n","\n","\n","def computeF1Score(correct_slots, pred_slots):\n","    correctChunk = {}\n","    correctChunkCnt = 0\n","    foundCorrect = {}\n","    foundCorrectCnt = 0\n","    foundPred = {}\n","    foundPredCnt = 0\n","    correctTags = 0\n","    tokenCount = 0\n","    for correct_slot, pred_slot in zip(correct_slots, pred_slots):\n","        inCorrect = False\n","        lastCorrectTag = 'O'\n","        lastCorrectType = ''\n","        lastPredTag = 'O'\n","        lastPredType = ''\n","        for c, p in zip(correct_slot, pred_slot):\n","            correctTag, correctType = __splitTagType(c)\n","            predTag, predType = __splitTagType(p)\n","\n","            if inCorrect == True:\n","                if __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n","                        __endOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n","                        (lastCorrectType == lastPredType):\n","                    inCorrect = False\n","                    correctChunkCnt += 1\n","                    if lastCorrectType in correctChunk:\n","                        correctChunk[lastCorrectType] += 1\n","                    else:\n","                        correctChunk[lastCorrectType] = 1\n","                elif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) != \\\n","                        __endOfChunk(lastPredTag, predTag, lastPredType, predType) or \\\n","                        (correctType != predType):\n","                    inCorrect = False\n","\n","            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n","                    __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n","                    (correctType == predType):\n","                inCorrect = True\n","\n","            if __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True:\n","                foundCorrectCnt += 1\n","                if correctType in foundCorrect:\n","                    foundCorrect[correctType] += 1\n","                else:\n","                    foundCorrect[correctType] = 1\n","\n","            if __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True:\n","                foundPredCnt += 1\n","                if predType in foundPred:\n","                    foundPred[predType] += 1\n","                else:\n","                    foundPred[predType] = 1\n","\n","            if correctTag == predTag and correctType == predType:\n","                correctTags += 1\n","\n","            tokenCount += 1\n","\n","            lastCorrectTag = correctTag\n","            lastCorrectType = correctType\n","            lastPredTag = predTag\n","            lastPredType = predType\n","\n","        if inCorrect == True:\n","            correctChunkCnt += 1\n","            if lastCorrectType in correctChunk:\n","                correctChunk[lastCorrectType] += 1\n","            else:\n","                correctChunk[lastCorrectType] = 1\n","\n","    if foundPredCnt > 0:\n","        precision = 100 * correctChunkCnt / foundPredCnt\n","    else:\n","        precision = 0\n","\n","    if foundCorrectCnt > 0:\n","        recall = 100 * correctChunkCnt / foundCorrectCnt\n","    else:\n","        recall = 0\n","\n","    if (precision + recall) > 0:\n","        f1 = (2 * precision * recall) / (precision + recall)\n","    else:\n","        f1 = 0\n","\n","    return f1, precision, recall\n","\n","\n","class DataProcessor(object):\n","    def __init__(self, in_path, slot_path, intent_path, in_vocab, slot_vocab, intent_vocab, shuffle=False):\n","        self.__fd_in = open(in_path, 'r').readlines()\n","        self.__fd_slot = open(slot_path, 'r').readlines()\n","        self.__fd_intent = open(intent_path, 'r').readlines()\n","        if shuffle:\n","            self.shuffle()\n","        self.__in_vocab = in_vocab\n","        self.__slot_vocab = slot_vocab\n","        self.__intent_vocab = intent_vocab\n","        self.end = 0\n","\n","    def close(self):\n","        self.__fd_in.close()\n","        self.__fd_slot.close()\n","        self.__fd_intent.close()\n","\n","    def shuffle(self):\n","        from sklearn.utils import shuffle\n","        self.__fd_in, self.__fd_slot, self.__fd_intent = shuffle(self.__fd_in, self.__fd_slot, self.__fd_intent)\n","\n","    def get_batch(self, batch_size):\n","        in_data = []\n","        slot_data = []\n","        slot_weight = []\n","        length = []\n","        intents = []\n","\n","        batch_in = []\n","        batch_slot = []\n","        max_len = 0\n","\n","        in_seq = []\n","        slot_seq = []\n","        intent_seq = []\n","        temp=''\n","        for i in range(batch_size):\n","            try:\n","                inp = self.__fd_in.pop()\n","            except IndexError:\n","                self.end = 1\n","                break\n","            slot = self.__fd_slot.pop()\n","            intent = self.__fd_intent.pop()\n","            inp = inp.rstrip()\n","            slot = slot.rstrip()\n","            intent = intent.rstrip()\n","            if temp=='':\n","              in_seq.append(inp)\n","              slot_seq.append(slot)\n","              intent_seq.append(intent)\n","            else:\n","              inp=inp+' '\n","              inp=inp+temp\n","              in_seq.append(inp)\n","              slot=slot+' O'\n","              slot_seq.append(slot)\n","              intent_seq.append(intent)\n","            temp=intent\n","            iii = inp\n","            sss = slot\n","            inp = sentenceToIds(inp, self.__in_vocab, unk=True)\n","            slot = sentenceToIds(slot, self.__slot_vocab, unk=True)\n","            intent = sentenceToIds(intent, self.__intent_vocab, unk=False)\n","            if None not in intent:\n","                batch_in.append(np.array(inp))\n","                batch_slot.append(np.array(slot))\n","                length.append(len(inp))\n","                intents.append(intent[0])\n","            if len(inp) != len(slot):\n","                print(iii, sss)\n","                print(inp, slot)\n","                exit(0)\n","            if len(inp) > max_len:\n","                max_len = len(inp)\n","\n","        length = np.array(length)\n","        intents = np.array(intents)\n","        for i, s in zip(batch_in, batch_slot):\n","            in_data.append(padSentence(list(i), max_len, self.__in_vocab))\n","            slot_data.append(padSentence(list(s), max_len, self.__slot_vocab))\n","\n","        in_data = np.array(in_data)\n","        slot_data = np.array(slot_data)\n","\n","        for s in slot_data:\n","            weight = np.not_equal(s, np.full(s.shape, self._DataProcessor__slot_vocab['vocab']['_PAD']))\n","            weight = weight.astype(np.float32)\n","            slot_weight.append(weight)\n","        slot_weight = np.array(slot_weight)\n","        return in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GZlOXACIVDQ9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696170489,"user_tz":-330,"elapsed":18031,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\n","\"\"\"## Functions for working with arbitrarily nested sequences of elements.\n","\n","This module can perform operations on nested structures. A nested structure is a\n","Python sequence, tuple (including `namedtuple`), or dict that can contain\n","further sequences, tuples, and dicts.\n","\n","The utilities here assume (and do not check) that the nested structures form a\n","'tree', i.e., no references in the structure of the input of these functions\n","should be recursive.\n","\n","Example structures: `((3, 4), 5, (6, 7, (9, 10), 8))`, `(np.array(0),\n","  (np.array([3, 4]), tf.constant([3, 4])))`\n","\"\"\"\n","\n","import collections as _collections\n","\n","import six as _six\n","\n","\n","def _sorted(dict_):\n","    \"\"\"Returns a sorted list of the dict keys, with error if keys not sortable.\"\"\"\n","    try:\n","        return sorted(_six.iterkeys(dict_))\n","    except TypeError:\n","        raise TypeError(\"nest only supports dicts with sortable keys.\")\n","\n","\n","def _sequence_like(instance, args):\n","    \"\"\"Converts the sequence `args` to the same type as `instance`.\n","\n","    Args:\n","      instance: an instance of `tuple`, `list`, `namedtuple`, `dict`, or\n","          `collections.OrderedDict`.\n","      args: elements to be converted to the `instance` type.\n","\n","    Returns:\n","      `args` with the type of `instance`.\n","    \"\"\"\n","    if isinstance(instance, dict):\n","        # Pack dictionaries in a deterministic order by sorting the keys.\n","        # Notice this means that we ignore the original order of `OrderedDict`\n","        # instances. This is intentional, to avoid potential bugs caused by mixing\n","        # ordered and plain dicts (e.g., flattening a dict but using a\n","        # corresponding `OrderedDict` to pack it back).\n","        result = dict(zip(_sorted(instance), args))\n","        return type(instance)((key, result[key]) for key in _six.iterkeys(instance))\n","    elif (isinstance(instance, tuple) and\n","          hasattr(instance, \"_fields\") and\n","          isinstance(instance._fields, _collections.Sequence) and\n","          all(isinstance(f, _six.string_types) for f in instance._fields)):\n","        # This is a namedtuple\n","        return type(instance)(*args)\n","    else:\n","        # Not a namedtuple\n","        return type(instance)(args)\n","\n","\n","def _yield_value(iterable):\n","    if isinstance(iterable, dict):\n","        # Iterate through dictionaries in a deterministic order by sorting the\n","        # keys. Notice this means that we ignore the original order of `OrderedDict`\n","        # instances. This is intentional, to avoid potential bugs caused by mixing\n","        # ordered and plain dicts (e.g., flattening a dict but using a\n","        # corresponding `OrderedDict` to pack it back).\n","        for key in _sorted(iterable):\n","            yield iterable[key]\n","    else:\n","        for value in iterable:\n","            yield value\n","\n","\n","def _yield_flat_nest(nest):\n","    for n in _yield_value(nest):\n","        if is_sequence(n):\n","            for ni in _yield_flat_nest(n):\n","                yield ni\n","        else:\n","            yield n\n","\n","\n","# Used by `_warn_once` to remember which warning messages have been given.\n","_ALREADY_WARNED = {}\n","\n","\n","def _warn_once(message):\n","    \"\"\"Logs a warning message, once per unique string.\"\"\"\n","    if message not in _ALREADY_WARNED:\n","        _ALREADY_WARNED[message] = True\n","\n","\n","def is_sequence(seq):\n","    \"\"\"Returns a true if its input is a collections.Sequence (except strings).\n","\n","    Args:\n","      seq: an input sequence.\n","\n","    Returns:\n","      True if the sequence is a not a string and is a collections.Sequence or a\n","      dict.\n","    \"\"\"\n","    if isinstance(seq, dict):\n","        return True\n","    if isinstance(seq, set):\n","        _warn_once(\"Sets are not currently considered sequences, but this may \"\n","                   \"change in the future, so consider avoiding using them.\")\n","    return (isinstance(seq, _collections.Sequence)\n","            and not isinstance(seq, _six.string_types))\n","\n","\n","def flatten(nest):\n","    \"\"\"Returns a flat list from a given nested structure.\n","\n","    If `nest` is not a sequence, tuple, or dict, then returns a single-element\n","    list: `[nest]`.\n","\n","    In the case of dict instances, the sequence consists of the values, sorted by\n","    key to ensure deterministic behavior. This is true also for `OrderedDict`\n","    instances: their sequence order is ignored, the sorting order of keys is\n","    used instead. The same convention is followed in `pack_sequence_as`. This\n","    correctly repacks dicts and `OrderedDict`s after they have been flattened,\n","    and also allows flattening an `OrderedDict` and then repacking it back using\n","    a correponding plain dict, or vice-versa.\n","    Dictionaries with non-sortable keys cannot be flattened.\n","\n","    Args:\n","      nest: an arbitrarily nested structure or a scalar object. Note, numpy\n","          arrays are considered scalars.\n","\n","    Returns:\n","      A Python list, the flattened version of the input.\n","\n","    Raises:\n","      TypeError: The nest is or contains a dict with non-sortable keys.\n","    \"\"\"\n","    if is_sequence(nest):\n","        return list(_yield_flat_nest(nest))\n","    else:\n","        return [nest]\n","\n","\n","def _recursive_assert_same_structure(nest1, nest2, check_types):\n","    \"\"\"Helper function for `assert_same_structure`.\"\"\"\n","    is_sequence_nest1 = is_sequence(nest1)\n","    if is_sequence_nest1 != is_sequence(nest2):\n","        raise ValueError(\n","            \"The two structures don't have the same nested structure.\\n\\n\"\n","            \"First structure: %s\\n\\nSecond structure: %s.\" % (nest1, nest2))\n","\n","    if not is_sequence_nest1:\n","        return  # finished checking\n","\n","    if check_types:\n","        type_nest1 = type(nest1)\n","        type_nest2 = type(nest2)\n","        if type_nest1 != type_nest2:\n","            raise TypeError(\n","                \"The two structures don't have the same sequence type. First \"\n","                \"structure has type %s, while second structure has type %s.\"\n","                % (type_nest1, type_nest2))\n","\n","        if isinstance(nest1, dict):\n","            keys1 = set(_six.iterkeys(nest1))\n","            keys2 = set(_six.iterkeys(nest2))\n","            if keys1 != keys2:\n","                raise ValueError(\n","                    \"The two dictionaries don't have the same set of keys. First \"\n","                    \"structure has keys {}, while second structure has keys {}.\"\n","                        .format(keys1, keys2))\n","\n","    nest1_as_sequence = [n for n in _yield_value(nest1)]\n","    nest2_as_sequence = [n for n in _yield_value(nest2)]\n","    for n1, n2 in zip(nest1_as_sequence, nest2_as_sequence):\n","        _recursive_assert_same_structure(n1, n2, check_types)\n","\n","\n","def assert_same_structure(nest1, nest2, check_types=True):\n","    \"\"\"Asserts that two structures are nested in the same way.\n","\n","    Args:\n","      nest1: an arbitrarily nested structure.\n","      nest2: an arbitrarily nested structure.\n","      check_types: if `True` (default) types of sequences are checked as\n","          well, including the keys of dictionaries. If set to `False`, for example\n","          a list and a tuple of objects will look the same if they have the same\n","          size.\n","\n","    Raises:\n","      ValueError: If the two structures do not have the same number of elements or\n","        if the two structures are not nested in the same way.\n","      TypeError: If the two structures differ in the type of sequence in any of\n","        their substructures. Only possible if `check_types` is `True`.\n","    \"\"\"\n","    len_nest1 = len(flatten(nest1)) if is_sequence(nest1) else 1\n","    len_nest2 = len(flatten(nest2)) if is_sequence(nest2) else 1\n","    if len_nest1 != len_nest2:\n","        raise ValueError(\"The two structures don't have the same number of \"\n","                         \"elements.\\n\\nFirst structure (%i elements): %s\\n\\n\"\n","                         \"Second structure (%i elements): %s\"\n","                         % (len_nest1, nest1, len_nest2, nest2))\n","    _recursive_assert_same_structure(nest1, nest2, check_types)\n","\n","\n","def flatten_dict_items(dictionary):\n","    \"\"\"Returns a dictionary with flattened keys and values.\n","\n","    This function flattens the keys and values of a dictionary, which can be\n","    arbitrarily nested structures, and returns the flattened version of such\n","    structures:\n","\n","    ```python\n","    example_dictionary = {(4, 5, (6, 8)): (\"a\", \"b\", (\"c\", \"d\"))}\n","    result = {4: \"a\", 5: \"b\", 6: \"c\", 8: \"d\"}\n","    flatten_dict_items(example_dictionary) == result\n","    ```\n","\n","    The input dictionary must satisfy two properties:\n","\n","    1. Its keys and values should have the same exact nested structure.\n","    2. The set of all flattened keys of the dictionary must not contain repeated\n","       keys.\n","\n","    Args:\n","      dictionary: the dictionary to zip\n","\n","    Returns:\n","      The zipped dictionary.\n","\n","    Raises:\n","      TypeError: If the input is not a dictionary.\n","      ValueError: If any key and value have not the same structure, or if keys are\n","        not unique.\n","    \"\"\"\n","    if not isinstance(dictionary, dict):\n","        raise TypeError(\"input must be a dictionary\")\n","    flat_dictionary = {}\n","    for i, v in _six.iteritems(dictionary):\n","        if not is_sequence(i):\n","            if i in flat_dictionary:\n","                raise ValueError(\n","                    \"Could not flatten dictionary: key %s is not unique.\" % i)\n","            flat_dictionary[i] = v\n","        else:\n","            flat_i = flatten(i)\n","            flat_v = flatten(v)\n","            if len(flat_i) != len(flat_v):\n","                raise ValueError(\n","                    \"Could not flatten dictionary. Key had %d elements, but value had \"\n","                    \"%d elements. Key: %s, value: %s.\"\n","                    % (len(flat_i), len(flat_v), flat_i, flat_v))\n","            for new_i, new_v in zip(flat_i, flat_v):\n","                if new_i in flat_dictionary:\n","                    raise ValueError(\n","                        \"Could not flatten dictionary: key %s is not unique.\"\n","                        % (new_i))\n","                flat_dictionary[new_i] = new_v\n","    return flat_dictionary\n","\n","\n","def _packed_nest_with_indices(structure, flat, index):\n","    \"\"\"Helper function for pack_sequence_as.\n","\n","    Args:\n","      structure: Substructure (list / tuple / dict) to mimic.\n","      flat: Flattened values to output substructure for.\n","      index: Index at which to start reading from flat.\n","\n","    Returns:\n","      The tuple (new_index, child), where:\n","        * new_index - the updated index into `flat` having processed `structure`.\n","        * packed - the subset of `flat` corresponding to `structure`,\n","                   having started at `index`, and packed into the same nested\n","                   format.\n","\n","    Raises:\n","      ValueError: if `structure` contains more elements than `flat`\n","        (assuming indexing starts from `index`).\n","    \"\"\"\n","    packed = []\n","    for s in _yield_value(structure):\n","        if is_sequence(s):\n","            new_index, child = _packed_nest_with_indices(s, flat, index)\n","            packed.append(_sequence_like(s, child))\n","            index = new_index\n","        else:\n","            packed.append(flat[index])\n","            index += 1\n","    return index, packed\n","\n","\n","def pack_sequence_as(structure, flat_sequence):\n","    \"\"\"Returns a given flattened sequence packed into a given structure.\n","\n","    If `structure` is a scalar, `flat_sequence` must be a single-element list;\n","    in this case the return value is `flat_sequence[0]`.\n","\n","    If `structure` is or contains a dict instance, the keys will be sorted to\n","    pack the flat sequence in deterministic order. This is true also for\n","    `OrderedDict` instances: their sequence order is ignored, the sorting order of\n","    keys is used instead. The same convention is followed in `pack_sequence_as`.\n","    This correctly repacks dicts and `OrderedDict`s after they have been\n","    flattened, and also allows flattening an `OrderedDict` and then repacking it\n","    back using a correponding plain dict, or vice-versa.\n","    Dictionaries with non-sortable keys cannot be flattened.\n","\n","    Args:\n","      structure: Nested structure, whose structure is given by nested lists,\n","          tuples, and dicts. Note: numpy arrays and strings are considered\n","          scalars.\n","      flat_sequence: flat sequence to pack.\n","\n","    Returns:\n","      packed: `flat_sequence` converted to have the same recursive structure as\n","        `structure`.\n","\n","    Raises:\n","      ValueError: If `flat_sequence` and `structure` have different\n","        element counts.\n","      TypeError: `structure` is or contains a dict with non-sortable keys.\n","    \"\"\"\n","    if not is_sequence(flat_sequence):\n","        raise TypeError(\"flat_sequence must be a sequence\")\n","\n","    if not is_sequence(structure):\n","        if len(flat_sequence) != 1:\n","            raise ValueError(\"Structure is a scalar but len(flat_sequence) == %d > 1\"\n","                             % len(flat_sequence))\n","        return flat_sequence[0]\n","\n","    flat_structure = flatten(structure)\n","    if len(flat_structure) != len(flat_sequence):\n","        raise ValueError(\n","            \"Could not pack sequence. Structure had %d elements, but flat_sequence \"\n","            \"had %d elements.  Structure: %s, flat_sequence: %s.\"\n","            % (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n","\n","    _, packed = _packed_nest_with_indices(structure, flat_sequence, 0)\n","    return _sequence_like(structure, packed)\n","\n","\n","def map_structure(func, *structure, **check_types_dict):\n","    \"\"\"Applies `func` to each entry in `structure` and returns a new structure.\n","\n","    Applies `func(x[0], x[1], ...)` where x[i] is an entry in\n","    `structure[i]`.  All structures in `structure` must have the same arity,\n","    and the return value will contain the results in the same structure.\n","\n","    Args:\n","      func: A callable that accepts as many arguments as there are structures.\n","      *structure: scalar, or tuple or list of constructed scalars and/or other\n","        tuples/lists, or scalars.  Note: numpy arrays are considered as scalars.\n","      **check_types_dict: only valid keyword argument is `check_types`. If set to\n","        `True` (default) the types of iterables within the structures have to be\n","        same (e.g. `map_structure(func, [1], (1,))` raises a `TypeError`\n","        exception). To allow this set this argument to `False`.\n","\n","    Returns:\n","      A new structure with the same arity as `structure`, whose values correspond\n","      to `func(x[0], x[1], ...)` where `x[i]` is a value in the corresponding\n","      location in `structure[i]`. If there are different sequence types and\n","      `check_types` is `False` the sequence types of the first structure will be\n","      used.\n","\n","    Raises:\n","      TypeError: If `func` is not callable or if the structures do not match\n","        each other by depth tree.\n","      ValueError: If no structure is provided or if the structures do not match\n","        each other by type.\n","      ValueError: If wrong keyword arguments are provided.\n","    \"\"\"\n","    if not callable(func):\n","        raise TypeError(\"func must be callable, got: %s\" % func)\n","\n","    if not structure:\n","        raise ValueError(\"Must provide at least one structure\")\n","\n","    if check_types_dict:\n","        if \"check_types\" not in check_types_dict or len(check_types_dict) > 1:\n","            raise ValueError(\"Only valid keyword argument is check_types\")\n","        check_types = check_types_dict[\"check_types\"]\n","    else:\n","        check_types = True\n","\n","    for other in structure[1:]:\n","        assert_same_structure(structure[0], other, check_types=check_types)\n","\n","    flat_structure = [flatten(s) for s in structure]\n","    entries = zip(*flat_structure)\n","\n","    return pack_sequence_as(\n","        structure[0], [func(*x) for x in entries])\n","\n","\n","def _yield_flat_up_to(shallow_tree, input_tree):\n","    \"\"\"Yields elements `input_tree` partially flattened up to `shallow_tree`.\"\"\"\n","    if is_sequence(shallow_tree):\n","        for shallow_branch, input_branch in zip(_yield_value(shallow_tree),\n","                                                _yield_value(input_tree)):\n","            for input_leaf in _yield_flat_up_to(shallow_branch, input_branch):\n","                yield input_leaf\n","    else:\n","        yield input_tree\n","\n","\n","def assert_shallow_structure(shallow_tree, input_tree, check_types=True):\n","    \"\"\"Asserts that `shallow_tree` is a shallow structure of `input_tree`.\n","\n","    That is, this function tests if the `input_tree` structure can be created from\n","    the `shallow_tree` structure by replacing its leaf nodes with deeper\n","    tree structures.\n","\n","    Examples:\n","\n","    The following code will raise an exception:\n","    ```python\n","      shallow_tree = [\"a\", \"b\"]\n","      input_tree = [\"c\", [\"d\", \"e\"], \"f\"]\n","      assert_shallow_structure(shallow_tree, input_tree)\n","    ```\n","\n","    The following code will not raise an exception:\n","    ```python\n","      shallow_tree = [\"a\", \"b\"]\n","      input_tree = [\"c\", [\"d\", \"e\"]]\n","      assert_shallow_structure(shallow_tree, input_tree)\n","    ```\n","\n","    Args:\n","      shallow_tree: an arbitrarily nested structure.\n","      input_tree: an arbitrarily nested structure.\n","      check_types: if `True` (default) the sequence types of `shallow_tree` and\n","        `input_tree` have to be the same.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`. Only raised if `check_types` is `True`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","    \"\"\"\n","    if is_sequence(shallow_tree):\n","        if not is_sequence(input_tree):\n","            raise TypeError(\n","                \"If shallow structure is a sequence, input must also be a sequence. \"\n","                \"Input has type: %s.\" % type(input_tree))\n","\n","        if check_types and not isinstance(input_tree, type(shallow_tree)):\n","            raise TypeError(\n","                \"The two structures don't have the same sequence type. Input \"\n","                \"structure has type %s, while shallow structure has type %s.\"\n","                % (type(input_tree), type(shallow_tree)))\n","\n","        if len(input_tree) != len(shallow_tree):\n","            raise ValueError(\n","                \"The two structures don't have the same sequence length. Input \"\n","                \"structure has length %s, while shallow structure has length %s.\"\n","                % (len(input_tree), len(shallow_tree)))\n","\n","        for shallow_branch, input_branch in zip(shallow_tree, input_tree):\n","            assert_shallow_structure(shallow_branch, input_branch,\n","                                     check_types=check_types)\n","\n","\n","def flatten_up_to(shallow_tree, input_tree):\n","    \"\"\"Flattens `input_tree` up to `shallow_tree`.\n","\n","    Any further depth in structure in `input_tree` is retained as elements in the\n","    partially flatten output.\n","\n","    If `shallow_tree` and `input_tree` are not sequences, this returns a\n","    single-element list: `[input_tree]`.\n","\n","    Use Case:\n","\n","    Sometimes we may wish to partially flatten a nested sequence, retaining some\n","    of the nested structure. We achieve this by specifying a shallow structure,\n","    `shallow_tree`, we wish to flatten up to.\n","\n","    The input, `input_tree`, can be thought of as having the same structure as\n","    `shallow_tree`, but with leaf nodes that are themselves tree structures.\n","\n","    Examples:\n","\n","    ```python\n","    input_tree = [[[2, 2], [3, 3]], [[4, 9], [5, 5]]]\n","    shallow_tree = [[True, True], [False, True]]\n","\n","    flattened_input_tree = flatten_up_to(shallow_tree, input_tree)\n","    flattened_shallow_tree = flatten_up_to(shallow_tree, shallow_tree)\n","\n","    # Output is:\n","    # [[2, 2], [3, 3], [4, 9], [5, 5]]\n","    # [True, True, False, True]\n","    ```\n","\n","    ```python\n","    input_tree = [[('a', 1), [('b', 2), [('c', 3), [('d', 4)]]]]]\n","    shallow_tree = [['level_1', ['level_2', ['level_3', ['level_4']]]]]\n","\n","    input_tree_flattened_as_shallow_tree = flatten_up_to(shallow_tree, input_tree)\n","    input_tree_flattened = flatten(input_tree)\n","\n","    # Output is:\n","    # [('a', 1), ('b', 2), ('c', 3), ('d', 4)]\n","    # ['a', 1, 'b', 2, 'c', 3, 'd', 4]\n","    ```\n","\n","    Non-Sequence Edge Cases:\n","\n","    ```python\n","    flatten_up_to(0, 0)  # Output: [0]\n","    flatten_up_to(0, [0, 1, 2])  # Output: [[0, 1, 2]]\n","    flatten_up_to([0, 1, 2], 0)  # Output: TypeError\n","    flatten_up_to([0, 1, 2], [0, 1, 2])  # Output: [0, 1, 2]\n","    ```\n","\n","    Args:\n","      shallow_tree: a possibly pruned structure of input_tree.\n","      input_tree: an arbitrarily nested structure or a scalar object.\n","        Note, numpy arrays are considered scalars.\n","\n","    Returns:\n","      A Python list, the partially flattened version of `input_tree` according to\n","      the structure of `shallow_tree`.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","    \"\"\"\n","    assert_shallow_structure(shallow_tree, input_tree)\n","    return list(_yield_flat_up_to(shallow_tree, input_tree))\n","\n","\n","def map_structure_up_to(shallow_tree, func, *inputs):\n","    \"\"\"Applies a function or op to a number of partially flattened inputs.\n","\n","    The `inputs` are flattened up to `shallow_tree` before being mapped.\n","\n","    Use Case:\n","\n","    Sometimes we wish to apply a function to a partially flattened\n","    sequence (for example when the function itself takes sequence inputs). We\n","    achieve this by specifying a shallow structure, `shallow_tree` we wish to\n","    flatten up to.\n","\n","    The `inputs`, can be thought of as having the same structure as\n","    `shallow_tree`, but with leaf nodes that are themselves tree structures.\n","\n","    This function therefore will return something with the same base structure as\n","    `shallow_tree`.\n","\n","    Examples:\n","\n","    ```python\n","    ab_tuple = collections.namedtuple(\"ab_tuple\", \"a, b\")\n","    op_tuple = collections.namedtuple(\"op_tuple\", \"add, mul\")\n","    inp_val = ab_tuple(a=2, b=3)\n","    inp_ops = ab_tuple(a=op_tuple(add=1, mul=2), b=op_tuple(add=2, mul=3))\n","    out = map_structure_up_to(inp_val, lambda val, ops: (val + ops.add) * ops.mul,\n","                              inp_val, inp_ops)\n","\n","    # Output is: ab_tuple(a=6, b=15)\n","    ```\n","\n","    ```python\n","    data_list = [[2, 4, 6, 8], [[1, 3, 5, 7, 9], [3, 5, 7]]]\n","    name_list = ['evens', ['odds', 'primes']]\n","    out = map_structure_up_to(\n","        name_list,\n","        lambda name, sec: \"first_{}_{}\".format(len(sec), name),\n","        name_list, data_list)\n","\n","    # Output is: ['first_4_evens', ['first_5_odds', 'first_3_primes']]\n","    ```\n","\n","    Args:\n","      shallow_tree: a shallow tree, common to all the inputs.\n","      func: callable which will be applied to each input individually.\n","      *inputs: arbitrarily nested combination of objects that are compatible with\n","          shallow_tree. The function `func` is applied to corresponding\n","          partially flattened elements of each input, so the function must support\n","          arity of `len(inputs)`.\n","\n","    Raises:\n","      TypeError: If `shallow_tree` is a sequence but `input_tree` is not.\n","      TypeError: If the sequence types of `shallow_tree` are different from\n","        `input_tree`.\n","      ValueError: If the sequence lengths of `shallow_tree` are different from\n","        `input_tree`.\n","\n","    Returns:\n","      result of repeatedly applying `func`, with same structure as\n","      `shallow_tree`.\n","    \"\"\"\n","    if not inputs:\n","        raise ValueError(\"Cannot map over no sequences\")\n","    for input_tree in inputs:\n","        assert_shallow_structure(shallow_tree, input_tree)\n","\n","    # Flatten each input separately, apply the function to corresponding elements,\n","    # then repack based on the structure of the first input.\n","    all_flattened_up_to = [flatten_up_to(shallow_tree, input_tree)\n","                           for input_tree in inputs]\n","    results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]\n","    return pack_sequence_as(structure=shallow_tree, flat_sequence=results)\n","\n","\n","def get_traverse_shallow_structure(traverse_fn, structure):\n","    \"\"\"Generates a shallow structure from a `traverse_fn` and `structure`.\n","\n","    `traverse_fn` must accept any possible subtree of `structure` and return\n","    a depth=1 structure containing `True` or `False` values, describing which\n","    of the top-level subtrees may be traversed.  It may also\n","    return scalar `True` or `False` \"traversal is OK / not OK for all subtrees.\"\n","\n","    Examples are available in the unit tests (nest_test.py).\n","\n","    Args:\n","      traverse_fn: Function taking a substructure and returning either a scalar\n","        `bool` (whether to traverse that substructure or not) or a depth=1\n","        shallow structure of the same type, describing which parts of the\n","        substructure to traverse.\n","      structure: The structure to traverse.\n","\n","    Returns:\n","      A shallow structure containing python bools, which can be passed to\n","      `map_structure_up_to` and `flatten_up_to`.\n","\n","    Raises:\n","      TypeError: if `traverse_fn` returns a sequence for a non-sequence input,\n","        or a structure with depth higher than 1 for a sequence input,\n","        or if any leaf values in the returned structure or scalar are not type\n","        `bool`.\n","    \"\"\"\n","    to_traverse = traverse_fn(structure)\n","    if not is_sequence(structure):\n","        if not isinstance(to_traverse, bool):\n","            raise TypeError(\"traverse_fn returned structure: %s for non-structure: %s\"\n","                            % (to_traverse, structure))\n","        return to_traverse\n","    level_traverse = []\n","    if isinstance(to_traverse, bool):\n","        if not to_traverse:\n","            # Do not traverse this substructure at all.  Exit early.\n","            return False\n","        else:\n","            # Traverse the entire substructure.\n","            for branch in _yield_value(structure):\n","                level_traverse.append(\n","                    get_traverse_shallow_structure(traverse_fn, branch))\n","    elif not is_sequence(to_traverse):\n","        raise TypeError(\"traverse_fn returned a non-bool scalar: %s for input: %s\"\n","                        % (to_traverse, structure))\n","    else:\n","        # Traverse some subset of this substructure.\n","        assert_shallow_structure(to_traverse, structure)\n","        for t, branch in zip(_yield_value(to_traverse), _yield_value(structure)):\n","            if not isinstance(t, bool):\n","                raise TypeError(\n","                    \"traverse_fn didn't return a depth=1 structure of bools.  saw: %s \"\n","                    \" for structure: %s\" % (to_traverse, structure))\n","            if t:\n","                level_traverse.append(\n","                    get_traverse_shallow_structure(traverse_fn, branch))\n","            else:\n","                level_traverse.append(False)\n","    return _sequence_like(structure, level_traverse)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcCV7jESVKSC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696170491,"user_tz":-330,"elapsed":18027,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","#import nest\n","\n","\n","def mkMask(input_tensor, maxLen):\n","    shape_of_input = tf.shape(input_tensor)\n","    shape_of_output = tf.concat(axis=0, values=[shape_of_input, [maxLen]])\n","\n","    oneDtensor = tf.reshape(input_tensor, shape=(-1,))\n","    flat_mask = tf.sequence_mask(oneDtensor, maxlen=maxLen)\n","    return tf.reshape(flat_mask, shape_of_output)\n","\n","\n","def reduce_avg(reduce_target, lengths, dim):\n","    \"\"\"\n","    Args:\n","        reduce_target : shape(d_0, d_1,..,d_dim, .., d_k)\n","        lengths : shape(d0, .., d_(dim-1))\n","        dim : which dimension to average, should be a python number\n","    \"\"\"\n","    shape_of_lengths = lengths.get_shape()\n","    shape_of_target = reduce_target.get_shape()\n","    if len(shape_of_lengths) != dim:\n","        raise ValueError(('Second input tensor should be rank %d, ' +\n","                          'while it got rank %d') % (dim, len(shape_of_lengths)))\n","    if len(shape_of_target) < dim + 1:\n","        raise ValueError(('First input tensor should be at least rank %d, ' +\n","                          'while it got rank %d') % (dim + 1, len(shape_of_target)))\n","\n","    rank_diff = len(shape_of_target) - len(shape_of_lengths) - 1\n","    mxlen = tf.shape(reduce_target)[dim]\n","    mask = mkMask(lengths, mxlen)\n","    if rank_diff != 0:\n","        len_shape = tf.concat(axis=0, values=[tf.shape(lengths), [1] * rank_diff])\n","        mask_shape = tf.concat(axis=0, values=[tf.shape(mask), [1] * rank_diff])\n","    else:\n","        len_shape = tf.shape(lengths)\n","        mask_shape = tf.shape(mask)\n","    lengths_reshape = tf.reshape(lengths, shape=len_shape)\n","    mask = tf.reshape(mask, shape=mask_shape)\n","\n","    mask_target = reduce_target * tf.cast(mask, dtype=reduce_target.dtype)\n","\n","    red_sum = tf.reduce_sum(mask_target, axis=[dim], keep_dims=False)\n","    red_avg = red_sum / (tf.to_float(lengths_reshape) + 1e-30)\n","    return red_avg\n","\n","\n","def reduce_sum(reduce_target, lengths, dim):\n","    \"\"\"\n","    Args:\n","        reduce_target : shape(d_0, d_1,..,d_dim, .., d_k)\n","        lengths : shape(d0, .., d_(dim-1))\n","        dim : which dimension to average, should be a python number\n","    \"\"\"\n","    shape_of_lengths = lengths.get_shape()\n","    shape_of_target = reduce_target.get_shape()\n","    if len(shape_of_lengths) != dim:\n","        raise ValueError(('Second input tensor should be rank %d, ' +\n","                          'while it got rank %d') % (dim, len(shape_of_lengths)))\n","    if len(shape_of_target) < dim + 1:\n","        raise ValueError(('First input tensor should be at least rank %d, ' +\n","                          'while it got rank %d') % (dim + 1, len(shape_of_target)))\n","\n","    rank_diff = len(shape_of_target) - len(shape_of_lengths) - 1\n","    mxlen = tf.shape(reduce_target)[dim]\n","    mask = mkMask(lengths, mxlen)\n","    if rank_diff != 0:\n","        len_shape = tf.concat(axis=0, values=[tf.shape(lengths), [1] * rank_diff])\n","        mask_shape = tf.concat(axis=0, values=[tf.shape(mask), [1] * rank_diff])\n","    else:\n","        len_shape = tf.shape(lengths)\n","        mask_shape = tf.shape(mask)\n","    lengths_reshape = tf.reshape(lengths, shape=len_shape)\n","    mask = tf.reshape(mask, shape=mask_shape)\n","\n","    mask_target = reduce_target * tf.cast(mask, dtype=reduce_target.dtype)\n","\n","    red_sum = tf.reduce_sum(mask_target, axis=[dim], keep_dims=False)\n","\n","    return red_sum\n","\n","\n","def embed_lookup_last_dim(embedding, ids):\n","    '''\n","        embedding: shape(b_sz, tstp, emb_sz)\n","        ids : shape(b_sz, tstp)\n","    '''\n","    input_shape = tf.shape(embedding)\n","    time_steps = input_shape[0]\n","\n","    def _create_ta(name, dtype):\n","        return tf.TensorArray(dtype=dtype,\n","                              size=time_steps,\n","                              tensor_array_name=name)\n","\n","    input_ta = _create_ta('input_ta', embedding.dtype)\n","    fetch_ta = _create_ta('fetch_ta', ids.dtype)\n","    output_ta = _create_ta('output_ta', embedding.dtype)\n","    input_ta = input_ta.unpack(embedding)\n","    fetch_ta = fetch_ta.unpack(ids)\n","\n","    def loop_body(time, output_ta):\n","        embed = input_ta.read(time)  # shape(tstp, emb_sz) type of float32\n","        fetch_id = fetch_ta.read(time)  # shape(tstp) type of int32\n","        out_emb = tf.nn.embedding_lookup(embed, fetch_id)\n","        output_ta = output_ta.write(time, out_emb)\n","\n","        next_time = time + 1\n","        return next_time, output_ta\n","\n","    time = tf.constant(0)\n","    _, output_ta = tf.while_loop(cond=lambda time, *_: time < time_steps,\n","                                 body=loop_body, loop_vars=(time, output_ta),\n","                                 swap_memory=True)\n","    ret_t = output_ta.pack()  # shape(b_sz, tstp, embd_sz)\n","    return ret_t\n","\n","\n","def entry_stop_gradients(target, mask):\n","    '''\n","    Args:\n","        target: a tensor\n","        mask: a boolean tensor that broadcast to the rank of that to target tensor\n","    Returns:\n","        ret: a tensor have the same value of target,\n","            but some entry will have no gradient during backprop\n","    '''\n","    mask_h = tf.logical_not(mask)\n","\n","    mask = tf.cast(mask, dtype=target.dtype)\n","    mask_h = tf.cast(mask_h, dtype=target.dtype)\n","    ret = tf.stop_gradient(mask_h * target) + mask * target\n","\n","    return ret\n","\n","\n","def last_dim_linear(inputs, output_size, bias, scope):\n","    '''\n","    Args:\n","        input: shape(b_sz, ..., rep_sz)\n","        output_size: a scalar, python number\n","    '''\n","    bias_start = 0.0\n","    input_shape = tf.shape(inputs)\n","    out_shape = tf.concat(axis=0, values=[input_shape[:-1], [output_size]])\n","    input_size = int(inputs.get_shape()[-1])\n","    unbatch_input = tf.reshape(inputs, shape=[-1, input_size])\n","\n","    unbatch_output = linear(unbatch_input, output_size, bias=bias,\n","                            bias_start=bias_start, scope=scope)\n","    batch_output = tf.reshape(unbatch_output, shape=out_shape)\n","\n","    return batch_output  # shape(b_sz, ..., output_size)\n","\n","\n","def linear(args, output_size, bias, bias_start=0.0, scope=None):\n","    \"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n","\n","    Args:\n","      args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n","      output_size: int, second dimension of W[i].\n","      bias: boolean, whether to add a bias term or not.\n","      bias_start: starting value to initialize the bias; 0 by default.\n","      scope: (optional) Variable scope to create parameters in.\n","\n","    Returns:\n","      A 2D Tensor with shape [batch x output_size] equal to\n","      sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n","\n","    Raises:\n","      ValueError: if some of the arguments has unspecified or wrong shape.\n","    \"\"\"\n","    if args is None or (nest.is_sequence(args) and not args):\n","        raise ValueError(\"`args` must be specified\")\n","    if not nest.is_sequence(args):\n","        args = [args]\n","\n","    total_arg_size = 0\n","    shapes = [a.get_shape() for a in args]\n","    for shape in shapes:\n","        if shape.ndims != 2:\n","            raise ValueError(\"linear is expecting 2D arguments: %s\" % shapes)\n","        if shape[1].value is None:\n","            raise ValueError(\"linear expects shape[1] to be provided for shape %s, \"\n","                             \"but saw %s\" % (shape, shape[1]))\n","        else:\n","            total_arg_size += shape[1].value\n","\n","    dtype = [a.dtype for a in args][0]\n","\n","    with tf.variable_scope(scope or 'Linear') as outer_scope:\n","        weights = tf.get_variable(\n","            \"weights\", [total_arg_size, output_size], dtype=dtype)\n","        if len(args) == 1:\n","            res = tf.matmul(args[0], weights)\n","        else:\n","            res = tf.matmul(tf.concat(args, 1), weights)\n","        if not bias:\n","            return res\n","        with tf.variable_scope(outer_scope) as inner_scope:\n","            inner_scope.set_partitioner(None)\n","            biases = tf.get_variable(\n","                \"biases\", [output_size],\n","                dtype=dtype,\n","                initializer=tf.constant_initializer(bias_start, dtype=dtype))\n","    return tf.nn.bias_add(res, biases)\n","\n","\n","def masked_softmax(inp, seqLen):\n","    seqLen = tf.where(tf.equal(seqLen, 0), tf.ones_like(seqLen), seqLen)\n","    if len(inp.get_shape()) != len(seqLen.get_shape()) + 1:\n","        raise ValueError('rank of seqLen should be %d, but have the rank %d.\\n'\n","                         % (len(inp.get_shape()) - 1, len(seqLen.get_shape())))\n","    mask = mkMask(seqLen, tf.shape(inp)[-1])\n","    masked_inp = tf.where(mask, inp, tf.ones_like(inp) * (-np.Inf))\n","    ret = tf.nn.softmax(masked_inp)\n","    return ret\n","\n","\n","from tensorflow.python.client import device_lib\n","\n","\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import gen_math_ops\n","\n","\n","def batch_gather(params, indices, name=None):\n","    \"\"\"Gather slices from `params` according to `indices` with leading batch dims.\n","    This operation assumes that the leading dimensions of `indices` are dense,\n","    and the gathers on the axis corresponding to the last dimension of `indices`.\n","    More concretely it computes:\n","    result[i1, ..., in] = params[i1, ..., in-1, indices[i1, ..., in]]\n","    Therefore `params` should be a Tensor of shape [A1, ..., AN, B1, ..., BM],\n","    `indices` should be a Tensor of shape [A1, ..., AN-1, C] and `result` will be\n","    a Tensor of size `[A1, ..., AN-1, C, B1, ..., BM]`.\n","    In the case in which indices is a 1D tensor, this operation is equivalent to\n","    `tf.gather`.\n","    See also `tf.gather` and `tf.gather_nd`.\n","    Args:\n","      params: A Tensor. The tensor from which to gather values.\n","      indices: A Tensor. Must be one of the following types: int32, int64. Index\n","          tensor. Must be in range `[0, params.shape[axis]`, where `axis` is the\n","          last dimension of `indices` itself.\n","      name: A name for the operation (optional).\n","    Returns:\n","      A Tensor. Has the same type as `params`.\n","    Raises:\n","      ValueError: if `indices` has an unknown shape.\n","    \"\"\"\n","\n","    with ops.name_scope(name):\n","        indices = ops.convert_to_tensor(indices, name=\"indices\")\n","        params = ops.convert_to_tensor(params, name=\"params\")\n","        indices_shape = tf.shape(indices)\n","        params_shape = tf.shape(params)\n","        ndims = indices.shape.ndims\n","        if ndims is None:\n","            raise ValueError(\"batch_gather does not allow indices with unknown \"\n","                             \"shape.\")\n","        batch_indices = indices\n","        accum_dim_value = 1\n","        for dim in range(ndims - 1, 0, -1):\n","            dim_value = params_shape[dim - 1]\n","            accum_dim_value *= params_shape[dim]\n","            dim_indices = gen_math_ops._range(0, dim_value, 1)\n","            dim_indices *= accum_dim_value\n","            dim_shape = tf.stack([1] * (dim - 1) + [dim_value] + [1] * (ndims - dim),\n","                                 axis=0)\n","            batch_indices += tf.reshape(dim_indices, dim_shape)\n","\n","        flat_indices = tf.reshape(batch_indices, [-1])\n","        outer_shape = params_shape[ndims:]\n","        flat_inner_shape = gen_math_ops.prod(\n","            params_shape[:ndims], [0], False)\n","\n","        flat_params = tf.reshape(\n","            params, tf.concat([[flat_inner_shape], outer_shape], axis=0))\n","        flat_result = tf.gather(flat_params, flat_indices)\n","        result = tf.reshape(flat_result, tf.concat([indices_shape, outer_shape], axis=0))\n","        final_shape = indices.get_shape()[:ndims - 1].merge_with(\n","            params.get_shape()[:ndims - 1])\n","        final_shape = final_shape.concatenate(indices.get_shape()[ndims - 1])\n","        final_shape = final_shape.concatenate(params.get_shape()[ndims:])\n","        result.set_shape(final_shape)\n","        return result"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"n6agyaVbVb-U","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696171685,"user_tz":-330,"elapsed":19215,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","def _softmax_with_mask(logits, lens, axis=-1):\n","    \"\"\"Helper function for softmax on variable-length sequences.\n","        Args:\n","            logits: The logits before softmax. Shape is [batch, type_num, class_num]\n","            lens: The length of the sequence. Shape is [batch, type_num].\n","            axis: The axis to apply softmax operator on.\n","        Returns:\n","             A tensor with softmax-ed values. Same shape as logits.\n","    \"\"\"\n","    exp_logits = tf.exp(logits)\n","    mask = tf.sequence_mask(lens, maxlen=tf.shape(logits)[axis], dtype=tf.float32)\n","    masked_exp_logits = tf.multiply(exp_logits, mask)\n","    masked_exp_logits_sum = tf.reduce_sum(masked_exp_logits, axis)\n","    return tf.clip_by_value(tf.div(masked_exp_logits, tf.expand_dims(masked_exp_logits_sum, axis)), 1e-37, 1e+37)\n","\n","\n","def _squash(input_tensor):\n","    \"\"\"Applies norm nonlinearity (squash) to a capsule layer.\n","        Args:\n","            input_tensor: Input tensor. Shape is [batch, num_channels, num_atoms] for a\n","              fully connected capsule layer or\n","              [batch, num_channels, num_atoms, height, width] for a convolutional\n","              capsule layer.\n","        Returns:\n","            A tensor with same shape as input (rank 3) for output of this layer.\n","    \"\"\"\n","    with tf.name_scope('norm_non_linearity'):\n","        norm = tf.norm(input_tensor, axis=2, keep_dims=True)\n","        norm_squared = norm * norm\n","        return (input_tensor / norm) * (norm_squared / (1 + norm_squared))\n","\n","\n","def _leaky_routing(logits, output_dim):\n","    \"\"\"Adds extra dimmension to routing logits.\n","    This enables active capsules to be routed to the extra dim if they are not a\n","    good fit for any of the capsules in layer above.\n","    Args:\n","      logits: The original logits. shape is\n","        [input_capsule_num, output_capsule_num] if fully connected. Otherwise, it\n","        has two more dimmensions.\n","      output_dim: The number of units in the second dimmension of logits.\n","    Returns:\n","      Routing probabilities for each pair of capsules. Same shape as logits.\n","    \"\"\"\n","    leak = tf.zeros_like(logits, optimize=True)\n","    leak = tf.reduce_sum(leak, axis=2, keep_dims=True)\n","    leaky_logits = tf.concat([leak, logits], axis=2)\n","    leaky_routing = tf.nn.softmax(leaky_logits, dim=2)\n","    return tf.split(leaky_routing, [1, output_dim], 2)[1]\n","\n","\n","def _update_routing(votes, biases, logit_shape, num_dims, input_dim, output_dim,\n","                    num_routing=3, leaky=True):\n","    \"\"\"Sums over scaled votes and applies squash to compute the activations.\n","    Iteratively updates routing logits (scales) based on the similarity between\n","    the activation of this layer and the votes of the layer below.\n","    Args:\n","      votes: tensor, The transformed outputs of the layer below.\n","      biases: tensor, Bias variable.\n","      logit_shape: tensor, shape of the logit to be initialized.\n","      num_dims: scalar, number of dimmensions in votes. For fully connected\n","        capsule it is 4, for convolutional 6.\n","      input_dim: scalar, number of capsules in the input layer.\n","      output_dim: scalar, number of capsules in the output layer.\n","      num_routing: scalar, Number of routing iterations.\n","      leaky: boolean, if set use leaky routing.\n","    Returns:\n","      The activation tensor of the output layer after num_routing iterations.\n","    \"\"\"\n","    votes_t_shape = [3, 0, 1, 2]\n","    for i in range(num_dims - 4):\n","        votes_t_shape += [i + 4]\n","    r_t_shape = [1, 2, 3, 0]\n","    for i in range(num_dims - 4):\n","        r_t_shape += [i + 4]\n","    votes_trans = tf.transpose(votes, votes_t_shape)\n","\n","    def _body(i, logits, activations, routes):\n","        \"\"\"Routing while loop.\"\"\"\n","        if leaky:\n","            route = _leaky_routing(logits, output_dim)\n","        else:\n","            route = tf.nn.softmax(logits, dim=2)\n","        preactivate_unrolled = route * votes_trans\n","        preact_trans = tf.transpose(preactivate_unrolled, r_t_shape)\n","        preactivate = tf.reduce_sum(preact_trans, axis=1) + biases\n","        activation = _squash(preactivate)\n","        activations = activations.write(i, activation)\n","        routes = routes.write(i, route)\n","        # distances: [batch, input_dim, output_dim]\n","        act_3d = tf.expand_dims(activation, 1)\n","        tile_shape = np.ones(num_dims, dtype=np.int32).tolist()\n","        tile_shape[1] = input_dim\n","        act_replicated = tf.tile(act_3d, tile_shape)\n","        distances = tf.reduce_sum(votes * act_replicated, axis=3)\n","        logits += distances\n","        return (i + 1, logits, activations, routes)\n","\n","    activations = tf.TensorArray(\n","        dtype=tf.float32, size=num_routing, clear_after_read=False)\n","    routes = tf.TensorArray(\n","        dtype=tf.float32, size=num_routing, clear_after_read=False)\n","    logits = tf.fill(logit_shape, 0.0)\n","    i = tf.constant(0, dtype=tf.int32)\n","    _, logits, activations, routes = tf.while_loop(\n","        lambda i, logits, activations, routes: i < num_routing,\n","        _body,\n","        loop_vars=[i, logits, activations, routes],\n","        swap_memory=True)\n","\n","    return activations.read(num_routing - 1), logits, routes.read(num_routing - 1)\n","\n","\n","class Capsule:\n","    def __init__(self, input_dim, input_atoms, output_dim, output_atoms, layer_name):\n","        self.input_dim = input_dim\n","        self.input_atoms = input_atoms\n","        self.output_dim = output_dim\n","        self.output_atoms = output_atoms\n","        with tf.variable_scope(layer_name):\n","            self.weights = tf.get_variable(name='w',\n","                                           shape=[1, input_dim, input_atoms, output_dim * output_atoms],\n","                                           dtype=tf.float32)\n","            self.biases = tf.get_variable(name='b', shape=[output_dim, output_atoms], dtype=tf.float32,\n","                                          initializer=tf.zeros_initializer())\n","\n","    def vote_and_route(self, input_tensor, leaky=False):\n","        with tf.name_scope('Wx_plus_b'):\n","            input_tiled = tf.tile(tf.expand_dims(input_tensor, -1),\n","                                  [1, 1, 1, self.output_dim * self.output_atoms])\n","            votes = tf.reduce_sum(input_tiled * self.weights, axis=2)\n","            votes_reshaped = tf.reshape(votes,\n","                                        [-1, self.input_dim, self.output_dim, self.output_atoms])\n","        with tf.name_scope('routing'):\n","            input_shape = tf.shape(input_tensor)\n","            logit_shape = tf.stack([input_shape[0], self.input_dim, self.output_dim])\n","            activations, weights_c, route = _update_routing(\n","                votes=votes_reshaped,\n","                biases=self.biases,\n","                logit_shape=logit_shape,\n","                num_dims=4,\n","                input_dim=self.input_dim,\n","                output_dim=self.output_dim,\n","                leaky=leaky,\n","                num_routing=3)\n","        return activations, weights_c, route"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPzE0qPHD7i-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696171687,"user_tz":-330,"elapsed":19212,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.python.layers import base as base_layer\n","\n","#from TfUtils import mkMask\n","\n","_EPSILON = 1e-9\n","_MIN_NUM = -np.Inf\n","\n","\n","class Capsule(base_layer.Layer):\n","    def __init__(self, out_caps_num, out_caps_dim, iter_num=3, wrr_dim=(1, 1), reuse=None):\n","        super(Capsule, self).__init__(_reuse=reuse)\n","        self.out_caps_num = out_caps_num\n","        self.out_caps_dim = out_caps_dim\n","        self.iter_num = iter_num\n","        self.reuse=reuse\n","        self.w_rr = tf.get_variable(name='w_rr', shape=(1, 1, wrr_dim[0], wrr_dim[1]))\n","\n","    def call(self, in_caps, seqLen, caps_ihat=None, re_routing=False):\n","        caps_uhat = shared_routing_uhat(in_caps, self.out_caps_num, self.out_caps_dim, scope='rnn_caps_uhat')\n","        if not re_routing:\n","            V, S, C, B = masked_routing_iter(caps_uhat, seqLen, self.iter_num, caps_ihat, w_rr=None)\n","        else:\n","            V, S, C, B = masked_routing_iter(caps_uhat, seqLen, self.iter_num, caps_ihat, w_rr=self.w_rr)\n","        return V, C, B\n","\n","\n","def shared_routing_uhat(caps, out_caps_num, out_caps_dim, scope=None):\n","    '''\n","\n","    Args:\n","        caps: # shape(b_sz, caps_num, caps_dim)\n","        out_caps_num: #number of output capsule\n","        out_caps_dim: #dimension of output capsule\n","    Returns:\n","        caps_uhat: shape(b_sz, caps_num, out_caps_num, out_caps_dim)\n","    '''\n","    b_sz = tf.shape(caps)[0]\n","    tstp = tf.shape(caps)[1]\n","\n","    with tf.variable_scope(scope or 'shared_routing_uhat'):\n","        '''shape(b_sz, caps_num, out_caps_num*out_caps_dim)'''\n","        caps_uhat = tf.layers.dense(caps, out_caps_num * out_caps_dim, activation=tf.tanh)\n","        caps_uhat = tf.reshape(caps_uhat, shape=[b_sz, tstp, out_caps_num, out_caps_dim])\n","    return caps_uhat\n","\n","\n","def masked_routing_iter(caps_uhat, seqLen, iter_num, caps_ihat=None, w_rr=None):\n","    '''\n","\n","    Args:\n","        caps_uhat:  shape(b_sz, tstp, out_caps_num, out_caps_dim)\n","        seqLen:     shape(b_sz)\n","        iter_num:   number of iteration\n","\n","    Returns:\n","        V_ret:      #shape(b_sz, out_caps_num, out_caps_dim)\n","    '''\n","    assert iter_num > 0\n","    b_sz = tf.shape(caps_uhat)[0]\n","    tstp = tf.shape(caps_uhat)[1]\n","    out_caps_num = int(caps_uhat.get_shape()[2])\n","    seqLen = tf.where(tf.equal(seqLen, 0), tf.ones_like(seqLen), seqLen)\n","    mask = mkMask(seqLen, tstp)  # shape(b_sz, tstp)\n","    floatmask = tf.cast(tf.expand_dims(mask, axis=-1), dtype=tf.float32)  # shape(b_sz, tstp, 1)\n","    B = tf.zeros([b_sz, tstp, out_caps_num], dtype=tf.float32)\n","    C_list = list()\n","    for i in range(iter_num):\n","        B_logits = B\n","        C = tf.nn.softmax(B, axis=2)  # shape(b_sz, tstp, out_caps_num)\n","        C = tf.expand_dims(C * floatmask, axis=-1)  # shape(b_sz, tstp, out_caps_num, 1)\n","        weighted_uhat = C * caps_uhat  # shape(b_sz, tstp, out_caps_num, out_caps_dim)\n","        C_list.append(C)\n","        S = tf.reduce_sum(weighted_uhat, axis=1)  # shape(b_sz, out_caps_num, out_caps_dim)\n","        V = _squash(S, axes=[2])  # shape(b_sz, out_caps_num, out_caps_dim)\n","        V = tf.expand_dims(V, axis=1)  # shape(b_sz, 1, out_caps_num, out_caps_dim)\n","        if caps_ihat == None:\n","            B = tf.reduce_sum(caps_uhat * V, axis=-1) + B  # shape(b_sz, tstp, out_caps_num)\n","        else:\n","            B = tf.reduce_sum(caps_uhat * V, axis=-1) + 0.1 * tf.squeeze(\n","                tf.matmul(tf.matmul(caps_uhat, tf.tile(w_rr, [tf.shape(caps_uhat)[0], tf.shape(caps_uhat)[1], 1, 1])),\n","                          tf.tile(caps_ihat, [1, tf.shape(caps_uhat)[1], 1, 1])),\n","                axis=-1) + B  # shape(b_sz, tstp, out_caps_num)\n","    V_ret = tf.squeeze(V, axis=[1])  # shape(b_sz, out_caps_num, out_caps_dim)\n","    S_ret = S\n","    C_ret = tf.squeeze(tf.stack(C_list), axis=[4])\n","    return V_ret, S_ret, C_ret, B_logits\n","\n","\n","def margin_loss1(y_true, y_pred):\n","    \"\"\"\n","    :param y_true: [None, n_classes]\n","    :param y_pred: [None, n_classes]\n","    :return: a scalar loss value.\n","    \"\"\"\n","    L = y_true * tf.square(tf.maximum(0., 0.9 - y_pred)) + \\\n","        0.5 * (1 - y_true) * tf.square(tf.maximum(0., y_pred - 0.1))\n","\n","    assert_inf_L = tf.Assert(tf.logical_not(tf.reduce_any(tf.is_inf(L))),\n","                             ['assert_inf_L', L], summarize=100)\n","    assert_nan_L = tf.Assert(tf.logical_not(tf.reduce_any(tf.is_nan(L))),\n","                             ['assert_nan_L', L], summarize=100)\n","    with tf.control_dependencies([assert_inf_L, assert_nan_L]):\n","        ret = tf.reduce_mean(tf.reduce_sum(L, axis=1))\n","    return ret\n","\n","\n","def _squash(in_caps, axes):\n","    '''\n","    Squashing function corresponding to Eq. 1\n","    Args:\n","        in_caps:  a tensor\n","        axes:     dimensions along which to apply squash\n","\n","    Returns:\n","        vec_squashed:   squashed tensor\n","\n","    '''\n","    vec_squared_norm = tf.reduce_sum(tf.square(in_caps), axis=axes, keepdims=True)\n","    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + _EPSILON)\n","    vec_squashed = scalar_factor * in_caps  # element-wise\n","    return vec_squashed"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5c4_CixAVl_6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595696171689,"user_tz":-330,"elapsed":19209,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":["# -*- coding: utf-8 -*-\n","import tensorflow as tf\n","\n","\n","\n","\n","def build_model(input_data, input_size, sequence_length, slot_size, intent_size, intent_dim, layer_size, embed_dim,\n","                num_rnn=1, isTraining=True, iter_slot=2, iter_intent=2, re_routing=True):\n","    cell_fw_list = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(layer_size) for _ in range(num_rnn)])\n","    cell_bw_list = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(layer_size) for _ in range(num_rnn)])\n","\n","    if isTraining == True:\n","        cell_fw_list = tf.contrib.rnn.DropoutWrapper(cell_fw_list, input_keep_prob=0.8,\n","                                                     output_keep_prob=0.8)\n","        cell_bw_list = tf.contrib.rnn.DropoutWrapper(cell_bw_list, input_keep_prob=0.8,\n","                                                     output_keep_prob=0.8)\n","\n","    embedding = tf.get_variable('embedding', [input_size, embed_dim],\n","                                initializer=tf.contrib.layers.xavier_initializer())\n","    inputs = tf.nn.embedding_lookup(embedding, input_data)\n","\n","    with tf.variable_scope('slot_capsule'):\n","        H, _, _ = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n","            [cell_fw_list],\n","            [cell_bw_list],\n","            inputs=inputs,\n","            sequence_length=sequence_length,\n","            dtype=tf.float32)\n","        sc = Capsule(slot_size, layer_size, reuse=tf.AUTO_REUSE, iter_num=iter_slot, wrr_dim=(layer_size, intent_dim))\n","        slot_capsule, routing_weight, routing_logits = sc(H, sequence_length, re_routing=False)\n","    with tf.variable_scope('slot_proj'):\n","        slot_p = tf.reshape(routing_logits, [-1, slot_size])\n","    with tf.variable_scope('intent_capsule'):\n","        intent_capsule, intent_routing_weight, _ = Capsule(intent_size, intent_dim, reuse=tf.AUTO_REUSE,\n","                                                           iter_num=iter_intent)(slot_capsule, slot_size)\n","    with tf.variable_scope('intent_proj'):\n","        intent = intent_capsule\n","    outputs = [slot_p, intent, routing_weight, intent_routing_weight]\n","    if re_routing:\n","        pred_intent_index_onehot = tf.one_hot(tf.argmax(tf.norm(intent_capsule, axis=-1), axis=-1), intent_size)\n","        pred_intent_index_onehot = tf.tile(tf.expand_dims(pred_intent_index_onehot, 2),\n","                                           [1, 1, tf.shape(intent_capsule)[2]])\n","        intent_capsule_max = tf.reduce_sum(tf.multiply(intent_capsule, tf.cast(pred_intent_index_onehot, tf.float32)),\n","                                           axis=1,\n","                                           keepdims=False)\n","        caps_ihat = tf.expand_dims(tf.expand_dims(intent_capsule_max, 1), 3)\n","        with tf.variable_scope('slot_capsule', reuse=True):\n","            slot_capsule_new, routing_weight_new, routing_logits_new = sc(H, sequence_length, caps_ihat=caps_ihat,\n","                                                                          re_routing=True)\n","        with tf.variable_scope('slot_proj', reuse=True):\n","            slot_p_new = tf.reshape(routing_logits_new, [-1, slot_size])\n","        outputs = [slot_p_new, intent, routing_weight_new, intent_routing_weight]\n","    return outputs"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8gDTVaeV9Wk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595701000445,"user_tz":-330,"elapsed":50754,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}},"outputId":"a83c1157-906b-4953-871a-fd3d6e4c8ccd"},"source":["# -*- coding: utf-8 -*-\n","import argparse\n","import logging\n","import os\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","\n","# Processing Units logs\n","log_device_placement = False\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n","\n","parser = argparse.ArgumentParser(allow_abbrev=False)\n","# Network\n","parser.add_argument(\"--num_units\", type=int, default=512, help=\"Network size.\", dest='layer_size',required=False)\n","parser.add_argument(\"--embed_dim\", type=int, default=1024, help=\"Embedding dim.\", dest='embed_dim',required=False)\n","parser.add_argument(\"--intent_dim\", type=int, default=128, help=\"Intent dim.\", dest='intent_dim',required=False)\n","parser.add_argument(\"--model_type\", type=str, default='full', help=\"\"\"full(default) | without_rerouting.\n","                                                                    full: full model with re-routing\n","                                                                    without_rerouting: model without re-routing\"\"\",required=False)\n","parser.add_argument(\"--num_rnn\", type=int, default=1, help=\"Num of layers for stacked RNNs.\",required=False)\n","parser.add_argument(\"--iter_slot\", type=int, default=2, help=\"Num of iteration for slots.\",required=False)\n","parser.add_argument(\"--iter_intent\", type=int, default=2, help=\"Num of iteration for intents.\",required=False)\n","\n","# Training Environment\n","parser.add_argument(\"--optimizer\", type=str, default='adam', help=\"Optimizer.\",required=False)\n","parser.add_argument(\"--batch_size\", type=int, default=8, help=\"Batch size.\",required=False)\n","parser.add_argument(\"--learning_rate\", type=float, default=0.001, help=\"Batch size.\",required=False)\n","parser.add_argument(\"--margin\", type=float, default=0.4, help=\"Margin in the max-margin loss.\",required=False)\n","parser.add_argument(\"--downweight\", type=float, default=0.5, help=\"Downweight for the max-margin loss.\",required=False)\n","parser.add_argument(\"--max_epochs\", type=int, default=20, help=\"Max epochs to train.\",required=False)\n","parser.add_argument(\"--no_early_stop\", action='store_false', dest='early_stop',\n","                    help=\"Disable early stop, which is based on sentence level accuracy.\",required=False)\n","parser.add_argument(\"--patience\", type=int, default=10, help=\"Patience to wait before stop.\",required=False)\n","parser.add_argument(\"--run_name\", type=str, default='capsule_nlu', help=\"Run name.\",required=False)\n","\n","# Model and Data\n","parser.add_argument(\"--dataset\", type=str, default='snips', help=\"\"\"Type 'snips' to use dataset provided by us or enter what ever you named your own dataset.\n","                Note, if you don't want to use this part, enter --dataset=''. It can not be None\"\"\",required=False)\n","parser.add_argument(\"--model_path\", type=str, default='./model', help=\"Path to save model.\",required=False)\n","parser.add_argument(\"--vocab_path\", type=str, default='./vocab', help=\"Path to vocabulary files.\",required=False)\n","parser.add_argument(\"--train_data_path\", type=str, default='train', help=\"Path to training data files.\",required=False)\n","parser.add_argument(\"--test_data_path\", type=str, default='test', help=\"Path to testing data files.\",required=False)\n","parser.add_argument(\"--valid_data_path\", type=str, default='valid', help=\"Path to validation data files.\",required=False)\n","parser.add_argument(\"--input_file\", type=str, default='seq.in', help=\"Input file name.\",required=False)\n","parser.add_argument(\"--slot_file\", type=str, default='seq.out', help=\"Slot file name.\",required=False)\n","parser.add_argument(\"--intent_file\", type=str, default='label', help=\"Intent file name.\",required=False)\n","\n","arg = parser.parse_args(''.split())\n","logs_path = './log/' + arg.run_name\n","\n","# Print arguments\n","for k, v in sorted(vars(arg).items()):\n","    print(k, '=', v)\n","print()\n","\n","# Optimzers\n","if arg.optimizer == 'adam':\n","    opt = tf.train.AdamOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'rmsprop':\n","    opt = tf.train.RMSPropOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'adadelta':\n","    opt = tf.train.AdadeltaOptimizer(learning_rate=arg.learning_rate)\n","elif arg.optimizer == 'adagrad':\n","    opt = tf.train.AdagradOptimizer(learning_rate=arg.learning_rate)\n","else:\n","    print('unknown optimizer!')\n","    exit(1)\n","\n","# Ablation\n","if arg.model_type == 'full':\n","    re_routing = True\n","elif arg.model_type == 'without_rerouting':\n","    re_routing = False\n","else:\n","    print('unknown model type!')\n","    exit(1)\n","\n","# Full path to data will be: ./data/ + dataset + train/test/valid\n","if arg.dataset == None:\n","    print('name of dataset can not be None')\n","    exit(1)\n","elif arg.dataset == 'snips':\n","    print('use snips dataset')\n","elif arg.dataset == 'atis':\n","    print('use atis dataset')\n","else:\n","    print('use own dataset: ', arg.dataset)\n","\n","full_train_path = os.path.join('./data', arg.dataset, arg.train_data_path)\n","full_test_path = os.path.join('./data', arg.dataset, arg.test_data_path)\n","full_valid_path = os.path.join('./data', arg.dataset, arg.valid_data_path)\n","\n","# Create vocabulary and save vocab files in ./vocab\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'in_vocab'))\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.slot_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'slot_vocab'))\n","createVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.intent_file), os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'intent_vocab'),\n","                 pad=False, unk=False)\n","\n","# Load vocab\n","in_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'in_vocab'))\n","slot_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'slot_vocab'))\n","intent_vocab = loadVocabulary(os.path.join('/content/drive/My Drive/Capsule-NLU/vocab', 'intent_vocab'))\n","intent_dim = arg.intent_dim\n","\n","\n","# Create training model\n","tf.reset_default_graph()\n","input_data = tf.placeholder(tf.int32, [None, None], name='inputs')  # word ids\n","sequence_length = tf.placeholder(tf.int32, [None], name=\"sequence_length\")  # sequence length\n","global_step = tf.Variable(0, trainable=False, name='global_step')\n","slots = tf.placeholder(tf.int32, [None, None], name='slots')  # slot ids\n","slot_weights = tf.placeholder(tf.float32, [None, None], name='slot_weights')  # sequence mask\n","intent = tf.placeholder(tf.int32, [None], name='intent')  # intent label\n","\n","with tf.variable_scope('model'):\n","    training_outputs = build_model(input_data, len(in_vocab['vocab']), sequence_length, len(slot_vocab['vocab']) - 2,\n","                                   len(intent_vocab['vocab']), intent_dim,\n","                                   layer_size=arg.layer_size, embed_dim=arg.embed_dim, num_rnn=arg.num_rnn,\n","                                   isTraining=True, iter_slot=arg.iter_slot, iter_intent=arg.iter_intent,\n","                                   re_routing=re_routing)\n","\n","slots_shape = tf.shape(slots)\n","slots_reshape = tf.reshape(slots, [-1])\n","slot_outputs = training_outputs[0]\n","intent_outputs = training_outputs[1]\n","slot_routing_weight = training_outputs[2]\n","intent_routing_weight = training_outputs[3]\n","intent_outputs_norm = tf.norm(intent_outputs, axis=-1)\n","\n","# Define slot loss\n","with tf.variable_scope('slot_loss'):\n","    slots_reshape_onehot = tf.one_hot(slots_reshape, len(slot_vocab['vocab']) - 2)  # [16*18, 74]\n","    crossent = tf.nn.softmax_cross_entropy_with_logits_v2(labels=slots_reshape_onehot, logits=slot_outputs)\n","    crossent = tf.reshape(crossent, slots_shape)\n","    slot_loss = tf.reduce_sum(crossent * slot_weights, 1)\n","    total_size = tf.reduce_sum(slot_weights, 1)\n","    total_size += 1e-12\n","    slot_loss = slot_loss / total_size\n","\n","# Define intent loss\n","with tf.variable_scope('intent_loss'):\n","    intent_onehot = tf.one_hot(intent, len(intent_vocab['vocab']))\n","    marginloss =margin_loss(labels=intent_onehot, raw_logits=intent_outputs_norm, margin=arg.margin,\n","                             downweight=arg.downweight)\n","    intent_loss = tf.reduce_mean(marginloss, axis=-1)\n","\n","# Specify the learning environment\n","params = tf.trainable_variables()\n","slot_params = []\n","for p in params:\n","    if 'slot' in p.name or 'embedding' in p.name:\n","        slot_params.append(p)\n","intent_params = []\n","for p in params:\n","    if 'intent' in p.name:\n","        intent_params.append(p)\n","\n","gradients_slot = tf.gradients(slot_loss, slot_params)\n","gradients_intent = tf.gradients(intent_loss, intent_params)\n","\n","clipped_gradients_slot, norm_slot = tf.clip_by_global_norm(gradients_slot, 5.0)\n","clipped_gradients_intent, norm_intent = tf.clip_by_global_norm(gradients_intent, 5.0)\n","\n","gradient_norm_slot = norm_slot\n","gradient_norm_intent = norm_intent\n","\n","update_slot = opt.apply_gradients(zip(clipped_gradients_slot, slot_params))\n","update_intent = opt.apply_gradients(zip(clipped_gradients_intent, intent_params), global_step=global_step)\n","\n","training_outputs = [global_step, slot_loss, intent_loss, slot_routing_weight, intent_routing_weight, update_slot,\n","                    update_intent, gradient_norm_slot, gradient_norm_intent]\n","inputs = [input_data, sequence_length, slots, slot_weights, intent]\n","\n","# Create Inference Model\n","with tf.variable_scope('model', reuse=True):\n","    inference_outputs = build_model(input_data, len(in_vocab['vocab']), sequence_length, len(slot_vocab['vocab']) - 2,\n","                                    len(intent_vocab['vocab']), intent_dim,\n","                                    layer_size=arg.layer_size, embed_dim=arg.embed_dim, num_rnn=arg.num_rnn,\n","                                    isTraining=False, iter_slot=arg.iter_slot, iter_intent=arg.iter_intent,\n","                                    re_routing=re_routing)\n","\n","inference_intent_outputs_norm = tf.norm(inference_outputs[1], axis=-1)\n","inference_outputs = [inference_outputs[0], inference_outputs[1], inference_intent_outputs_norm, inference_outputs[2],\n","                     inference_outputs[3]]\n","inference_inputs = [input_data, sequence_length]\n","\n","saver = tf.train.Saver()\n","\n","# Start Training\n","with tf.Session(config=tf.ConfigProto(allow_soft_placement=False, log_device_placement=log_device_placement)) as sess:\n","    sess.run(tf.global_variables_initializer())\n","    logging.info('Training Start')\n","    epochs = 0\n","    eval_slot_loss = 0.0\n","    eval_intent_loss = 0.0\n","    eval_slot_p = 0.0\n","    data_processor = None\n","    line = 0\n","    num_loss = 0\n","    step = 0\n","    no_improve = 0\n","\n","    # variables to store highest values among epochs, only use 'valid_err' for now\n","    valid_slot = 0\n","    test_slot = 0\n","    valid_intent = 0\n","    test_intent = 0\n","    valid_err = 0\n","    test_err = 0\n","\n","    # Load from saved checkpoints\n","    # saver.restore(sess, './model/' + arg.run_name + \".ckpt\")\n","    # logging.info(\"Model restored.\")\n","\n","    while True:\n","        if data_processor == None:\n","            data_processor = DataProcessor(os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.input_file),\n","                                           os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.slot_file),\n","                                           os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/train', arg.intent_file), in_vocab, slot_vocab,\n","                                           intent_vocab, shuffle=True)\n","        in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq = data_processor.get_batch(\n","            arg.batch_size)\n","        feed_dict = {input_data.name: in_data, slots.name: slot_data, slot_weights.name: slot_weight,\n","                     sequence_length.name: length, intent.name: intents}\n","\n","        if len(in_data) != 0:\n","            ret = sess.run(training_outputs, feed_dict)\n","            eval_slot_loss += np.mean(ret[1])\n","            eval_intent_loss += np.mean(ret[2])\n","\n","            line += len(in_data)\n","            step = ret[0]\n","            num_loss += 1\n","\n","        if data_processor.end == 1:\n","            line = 0\n","            data_processor = None\n","            epochs += 1\n","            logging.info('Step: ' + str(step))\n","            logging.info('Epochs: ' + str(epochs))\n","            logging.info('Slot Loss: ' + str(eval_slot_loss / num_loss))\n","            logging.info('Intent Loss: ' + str(eval_intent_loss / num_loss))\n","            num_loss = 0\n","            eval_slot_loss = 0.0\n","            eval_slot_p = 0.0\n","            eval_intent_loss = 0.0\n","            save_path = os.path.join(arg.model_path, '_step_' + str(step) + '_epochs_' + str(epochs) + '.ckpt')\n","\n","\n","            def valid(in_path, slot_path, intent_path):\n","                data_processor_valid = DataProcessor(in_path, slot_path, intent_path, in_vocab, slot_vocab,\n","                                                     intent_vocab)\n","                pred_intents = []\n","                correct_intents = []\n","                slot_outputs = []\n","                correct_slots = []\n","                input_words = []\n","\n","                while True:\n","                    in_data, slot_data, slot_weight, length, intents, in_seq, slot_seq, intent_seq = data_processor_valid.get_batch(\n","                        arg.batch_size)\n","                    feed_dict = {input_data.name: in_data, sequence_length.name: length}\n","                    if len(in_data) != 0:\n","                        ret = sess.run(inference_outputs, feed_dict)\n","                        for i in ret[2]:\n","                            pred_intents.append(np.argmax(i))\n","                        for i in intents:\n","                            correct_intents.append(i)\n","\n","                        pred_slots = ret[3][-1, :, :, :].reshape((slot_data.shape[0], slot_data.shape[1], -1))\n","                        for p, t, i, l, s in zip(pred_slots, slot_data, in_data, length, slot_seq):\n","                            p = np.argmax(p, 1)\n","                            tmp_pred = []\n","                            tmp_correct = []\n","                            tmp_input = []\n","                            for j in range(l):\n","                                tmp_pred.append(slot_vocab['rev'][p[j]])\n","                                tmp_correct.append(slot_vocab['rev'][t[j]])\n","                                tmp_input.append(in_vocab['rev'][i[j]])\n","\n","                            slot_outputs.append(tmp_pred)\n","                            correct_slots.append(tmp_correct)\n","                            input_words.append(tmp_input)\n","                    if data_processor_valid.end == 1:\n","                        break\n","                pred_intents = np.array(pred_intents)\n","                correct_intents = np.array(correct_intents)\n","                from sklearn.metrics import classification_report\n","                logging.info(classification_report(y_true=correct_intents, y_pred=pred_intents, digits=4))\n","                accuracy = (pred_intents == correct_intents)\n","                semantic_error = accuracy\n","                accuracy = accuracy.astype(float)\n","                accuracy = np.mean(accuracy) * 100.0\n","\n","                index = 0\n","                for t, p in zip(correct_slots, slot_outputs):\n","                    # Process Semantic Error\n","                    if len(t) != len(p):\n","                        raise ValueError('Error!!')\n","\n","                    for j in range(len(t)):\n","                        if p[j] != t[j]:\n","                            semantic_error[index] = False\n","                            break\n","                    index += 1\n","                semantic_error = semantic_error.astype(float)\n","                semantic_error = np.mean(semantic_error) * 100.0\n","\n","                f1, precision, recall = computeF1Score(correct_slots, slot_outputs)\n","                logging.info('slot f1: ' + str(f1))\n","                logging.info('intent accuracy: ' + str(accuracy))\n","                logging.info('semantic error(intent, slots are all correct): ' + str(semantic_error))\n","\n","                return f1, accuracy, semantic_error, pred_intents, correct_intents, slot_outputs, correct_slots, input_words\n","\n","\n","            logging.info('Valid:')\n","            epoch_valid_slot, epoch_valid_intent, epoch_valid_err, valid_pred_intent, valid_correct_intent, valid_pred_slot, valid_correct_slot, valid_words = valid(\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.slot_file),\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/valid', arg.intent_file))\n","\n","            logging.info('Test:')\n","            epoch_test_slot, epoch_test_intent, epoch_test_err, test_pred_intent, test_correct_intent, test_pred_slot, test_correct_slot, test_words = valid(\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.input_file), os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.slot_file),\n","                os.path.join('/content/drive/My Drive/Capsule-NLU/data/snips/test', arg.intent_file))\n","\n","            if epoch_valid_err <= valid_err:\n","                no_improve += 1\n","            else:\n","                valid_err = epoch_valid_err\n","                no_improve = 0\n","            if epochs == arg.max_epochs:\n","                break\n","            if arg.early_stop:\n","                if no_improve > arg.patience:\n","                    break\n","\n","            save_path = saver.save(sess, './model/' + arg.run_name + \"_\" + str(epochs) + \".ckpt\")\n","            # logging.info(\"Model saved in path: \" + str(save_path))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["batch_size = 8\n","dataset = snips\n","downweight = 0.5\n","early_stop = True\n","embed_dim = 1024\n","input_file = seq.in\n","intent_dim = 128\n","intent_file = label\n","iter_intent = 2\n","iter_slot = 2\n","layer_size = 512\n","learning_rate = 0.001\n","margin = 0.4\n","max_epochs = 20\n","model_path = ./model\n","model_type = full\n","num_rnn = 1\n","optimizer = adam\n","patience = 10\n","run_name = capsule_nlu\n","slot_file = seq.out\n","test_data_path = test\n","train_data_path = train\n","valid_data_path = valid\n","vocab_path = ./vocab\n","\n","use snips dataset\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,007 : INFO : NumExpr defaulting to 2 threads.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,813 : WARNING : \n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-5a5a7f76549c>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,815 : WARNING : From <ipython-input-7-5a5a7f76549c>:9: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-7-5a5a7f76549c>:9: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,819 : WARNING : From <ipython-input-7-5a5a7f76549c>:9: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,853 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:14,855 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,112 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d043080>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,118 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,139 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,266 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d15f9b0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,303 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,456 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa63d02c668>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,614 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa63d02c208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,752 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:From <ipython-input-6-04bbf396d210>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,767 : WARNING : From <ipython-input-6-04bbf396d210>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:15,884 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dddfda0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:16,046 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfc18>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:16,169 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62dbef2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:16,337 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62e5dfcc0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:16,448 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62da21ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,101 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894390>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,229 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8609e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,417 : WARNING : Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>>: AttributeError: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7fa62c894e80>>: AttributeError: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,546 : WARNING : Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicLSTMCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x7fa62c8942e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,650 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,785 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c3b9ac8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:19,935 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c6df898>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:20,045 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c24a550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:20,217 : WARNING : Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Capsule.call of <__main__.Capsule object at 0x7fa62c894438>>: AssertionError: Bad argument number for Name: 3, expecting 4\n","WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:20,330 : WARNING : Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7fa62c0b5208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 16:56:22,445 : INFO : Training Start\n","2020-07-25 17:00:16,759 : INFO : Step: 1636\n","2020-07-25 17:00:16,761 : INFO : Epochs: 1\n","2020-07-25 17:00:16,763 : INFO : Slot Loss: 0.4911196038558451\n","2020-07-25 17:00:16,764 : INFO : Intent Loss: 0.007022488338507196\n","2020-07-25 17:00:16,766 : INFO : Valid:\n","2020-07-25 17:00:19,939 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9897    0.9600    0.9746       100\n","           1     1.0000    0.9600    0.9796       100\n","           2     0.9900    0.9900    0.9900       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9346    1.0000    0.9662       100\n","           5     1.0000    0.9600    0.9796       100\n","           6     0.9615    1.0000    0.9804       100\n","\n","    accuracy                         0.9814       700\n","   macro avg     0.9823    0.9814    0.9815       700\n","weighted avg     0.9823    0.9814    0.9815       700\n","\n","2020-07-25 17:00:19,969 : INFO : slot f1: 76.55076495132127\n","2020-07-25 17:00:19,970 : INFO : intent accuracy: 98.14285714285714\n","2020-07-25 17:00:19,974 : INFO : semantic error(intent, slots are all correct): 46.285714285714285\n","2020-07-25 17:00:19,976 : INFO : Test:\n","2020-07-25 17:00:23,142 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8817    0.9535    0.9162        86\n","           1     0.9808    0.9808    0.9808       104\n","           2     0.9783    0.9783    0.9783        92\n","           3     0.9872    0.9625    0.9747        80\n","           4     0.8947    0.9533    0.9231       107\n","           5     0.8990    0.8318    0.8641       107\n","           6     1.0000    0.9677    0.9836       124\n","\n","    accuracy                         0.9457       700\n","   macro avg     0.9460    0.9468    0.9458       700\n","weighted avg     0.9468    0.9457    0.9457       700\n","\n","2020-07-25 17:00:23,172 : INFO : slot f1: 75.29215358931552\n","2020-07-25 17:00:23,173 : INFO : intent accuracy: 94.57142857142857\n","2020-07-25 17:00:23,178 : INFO : semantic error(intent, slots are all correct): 46.714285714285715\n","2020-07-25 17:04:19,761 : INFO : Step: 3272\n","2020-07-25 17:04:19,762 : INFO : Epochs: 2\n","2020-07-25 17:04:19,766 : INFO : Slot Loss: 0.09829640830980846\n","2020-07-25 17:04:19,767 : INFO : Intent Loss: 0.0017052850364320696\n","2020-07-25 17:04:19,770 : INFO : Valid:\n","2020-07-25 17:04:22,731 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9083    0.9900    0.9474       100\n","           1     1.0000    0.9700    0.9848       100\n","           2     0.9802    0.9900    0.9851       100\n","           3     1.0000    0.9300    0.9637       100\n","           4     0.9894    0.9300    0.9588       100\n","           5     0.8684    0.9900    0.9252       100\n","           6     1.0000    0.9200    0.9583       100\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9637    0.9600    0.9605       700\n","weighted avg     0.9637    0.9600    0.9605       700\n","\n","2020-07-25 17:04:22,761 : INFO : slot f1: 80.0\n","2020-07-25 17:04:22,761 : INFO : intent accuracy: 96.0\n","2020-07-25 17:04:22,762 : INFO : semantic error(intent, slots are all correct): 50.142857142857146\n","2020-07-25 17:04:22,767 : INFO : Test:\n","2020-07-25 17:04:25,890 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.7925    0.9767    0.8750        86\n","           1     0.9904    0.9904    0.9904       104\n","           2     1.0000    0.9783    0.9890        92\n","           3     1.0000    0.9000    0.9474        80\n","           4     0.9798    0.9065    0.9417       107\n","           5     0.8793    0.9533    0.9148       107\n","           6     1.0000    0.9113    0.9536       124\n","\n","    accuracy                         0.9443       700\n","   macro avg     0.9488    0.9452    0.9446       700\n","weighted avg     0.9515    0.9443    0.9456       700\n","\n","2020-07-25 17:04:25,921 : INFO : slot f1: 79.18526785714288\n","2020-07-25 17:04:25,922 : INFO : intent accuracy: 94.42857142857143\n","2020-07-25 17:04:25,923 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 17:08:21,953 : INFO : Step: 4908\n","2020-07-25 17:08:21,955 : INFO : Epochs: 3\n","2020-07-25 17:08:21,958 : INFO : Slot Loss: 0.04321111064458472\n","2020-07-25 17:08:21,960 : INFO : Intent Loss: 0.0014932809205654288\n","2020-07-25 17:08:21,963 : INFO : Valid:\n","2020-07-25 17:08:24,927 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9697    0.9600    0.9648       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    0.9900    0.9950       100\n","           4     0.9789    0.9300    0.9538       100\n","           5     0.9333    0.9800    0.9561       100\n","           6     0.9612    0.9900    0.9754       100\n","\n","    accuracy                         0.9757       700\n","   macro avg     0.9761    0.9757    0.9757       700\n","weighted avg     0.9761    0.9757    0.9757       700\n","\n","2020-07-25 17:08:24,961 : INFO : slot f1: 79.6875\n","2020-07-25 17:08:24,962 : INFO : intent accuracy: 97.57142857142857\n","2020-07-25 17:08:24,964 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n","2020-07-25 17:08:24,966 : INFO : Test:\n","2020-07-25 17:08:28,150 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8817    0.9535    0.9162        86\n","           1     0.9903    0.9808    0.9855       104\n","           2     0.9684    1.0000    0.9840        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9899    0.9159    0.9515       107\n","           5     0.9159    0.9159    0.9159       107\n","           6     0.9840    0.9919    0.9880       124\n","\n","    accuracy                         0.9614       700\n","   macro avg     0.9615    0.9619    0.9612       700\n","weighted avg     0.9626    0.9614    0.9616       700\n","\n","2020-07-25 17:08:28,180 : INFO : slot f1: 79.41996653653095\n","2020-07-25 17:08:28,181 : INFO : intent accuracy: 96.14285714285714\n","2020-07-25 17:08:28,186 : INFO : semantic error(intent, slots are all correct): 51.714285714285715\n","2020-07-25 17:12:24,756 : INFO : Step: 6544\n","2020-07-25 17:12:24,757 : INFO : Epochs: 4\n","2020-07-25 17:12:24,760 : INFO : Slot Loss: 0.02683942362148701\n","2020-07-25 17:12:24,764 : INFO : Intent Loss: 0.0014277433412899622\n","2020-07-25 17:12:24,766 : INFO : Valid:\n","2020-07-25 17:12:27,686 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9898    0.9700    0.9798       100\n","           1     0.9901    1.0000    0.9950       100\n","           2     1.0000    0.9900    0.9950       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     1.0000    0.9700    0.9848       100\n","           5     0.9706    0.9900    0.9802       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9886       700\n","   macro avg     0.9887    0.9886    0.9886       700\n","weighted avg     0.9887    0.9886    0.9886       700\n","\n","2020-07-25 17:12:27,714 : INFO : slot f1: 79.61002785515319\n","2020-07-25 17:12:27,715 : INFO : intent accuracy: 98.85714285714286\n","2020-07-25 17:12:27,716 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 17:12:27,718 : INFO : Test:\n","2020-07-25 17:12:30,944 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8586    0.9884    0.9189        86\n","           1     0.9903    0.9808    0.9855       104\n","           2     0.9579    0.9891    0.9733        92\n","           3     1.0000    0.9625    0.9809        80\n","           4     0.9709    0.9346    0.9524       107\n","           5     0.9406    0.8879    0.9135       107\n","           6     0.9918    0.9758    0.9837       124\n","\n","    accuracy                         0.9586       700\n","   macro avg     0.9586    0.9599    0.9583       700\n","weighted avg     0.9607    0.9586    0.9588       700\n","\n","2020-07-25 17:12:30,976 : INFO : slot f1: 78.45641310383121\n","2020-07-25 17:12:30,978 : INFO : intent accuracy: 95.85714285714285\n","2020-07-25 17:12:30,980 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 17:16:27,820 : INFO : Step: 8180\n","2020-07-25 17:16:27,821 : INFO : Epochs: 5\n","2020-07-25 17:16:27,825 : INFO : Slot Loss: 0.018865554533276693\n","2020-07-25 17:16:27,828 : INFO : Intent Loss: 0.001024726605807549\n","2020-07-25 17:16:27,830 : INFO : Valid:\n","2020-07-25 17:16:30,821 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9789    0.9300    0.9538       100\n","           1     1.0000    0.9700    0.9848       100\n","           2     0.9901    1.0000    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9802    0.9900    0.9851       100\n","           5     0.9794    0.9500    0.9645       100\n","           6     0.9174    1.0000    0.9569       100\n","\n","    accuracy                         0.9771       700\n","   macro avg     0.9780    0.9771    0.9772       700\n","weighted avg     0.9780    0.9771    0.9772       700\n","\n","2020-07-25 17:16:30,853 : INFO : slot f1: 80.83076059500422\n","2020-07-25 17:16:30,854 : INFO : intent accuracy: 97.71428571428571\n","2020-07-25 17:16:30,857 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 17:16:30,859 : INFO : Test:\n","2020-07-25 17:16:34,036 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9011    0.9535    0.9266        86\n","           1     0.9811    1.0000    0.9905       104\n","           2     0.9892    1.0000    0.9946        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9273    0.9533    0.9401       107\n","           5     0.9579    0.8505    0.9010       107\n","           6     0.9685    0.9919    0.9801       124\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9607    0.9606    0.9600       700\n","weighted avg     0.9605    0.9600    0.9596       700\n","\n","2020-07-25 17:16:34,066 : INFO : slot f1: 79.33930571108621\n","2020-07-25 17:16:34,067 : INFO : intent accuracy: 96.0\n","2020-07-25 17:16:34,068 : INFO : semantic error(intent, slots are all correct): 51.857142857142854\n","2020-07-25 17:20:30,089 : INFO : Step: 9816\n","2020-07-25 17:20:30,091 : INFO : Epochs: 6\n","2020-07-25 17:20:30,091 : INFO : Slot Loss: 0.0143467592929049\n","2020-07-25 17:20:30,094 : INFO : Intent Loss: 0.0009288410395225838\n","2020-07-25 17:20:30,095 : INFO : Valid:\n","2020-07-25 17:20:33,054 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9700    0.9700    0.9700       100\n","           1     0.9703    0.9800    0.9751       100\n","           2     1.0000    0.9800    0.9899       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9792    0.9400    0.9592       100\n","           5     0.9524    1.0000    0.9756       100\n","           6     0.9800    0.9800    0.9800       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9788    0.9786    0.9785       700\n","weighted avg     0.9788    0.9786    0.9785       700\n","\n","2020-07-25 17:20:33,084 : INFO : slot f1: 80.37068239258635\n","2020-07-25 17:20:33,085 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 17:20:33,087 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 17:20:33,090 : INFO : Test:\n","2020-07-25 17:20:36,254 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8936    0.9767    0.9333        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     1.0000    1.0000    1.0000        92\n","           3     0.9870    0.9500    0.9682        80\n","           4     0.9541    0.9720    0.9630       107\n","           5     0.9703    0.9159    0.9423       107\n","           6     0.9918    0.9758    0.9837       124\n","\n","    accuracy                         0.9686       700\n","   macro avg     0.9683    0.9687    0.9680       700\n","weighted avg     0.9696    0.9686    0.9687       700\n","\n","2020-07-25 17:20:36,284 : INFO : slot f1: 79.83169705469847\n","2020-07-25 17:20:36,286 : INFO : intent accuracy: 96.85714285714285\n","2020-07-25 17:20:36,287 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["2020-07-25 17:20:38,366 : WARNING : From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","2020-07-25 17:24:32,870 : INFO : Step: 11452\n","2020-07-25 17:24:32,871 : INFO : Epochs: 7\n","2020-07-25 17:24:32,876 : INFO : Slot Loss: 0.009560559338676167\n","2020-07-25 17:24:32,877 : INFO : Intent Loss: 0.0010457240059476632\n","2020-07-25 17:24:32,879 : INFO : Valid:\n","2020-07-25 17:24:35,822 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9898    0.9700    0.9798       100\n","           1     0.9615    1.0000    0.9804       100\n","           2     0.9899    0.9800    0.9849       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9890    0.9000    0.9424       100\n","           5     0.9167    0.9900    0.9519       100\n","           6     0.9900    0.9900    0.9900       100\n","\n","    accuracy                         0.9757       700\n","   macro avg     0.9767    0.9757    0.9756       700\n","weighted avg     0.9767    0.9757    0.9756       700\n","\n","2020-07-25 17:24:35,853 : INFO : slot f1: 80.76383038472339\n","2020-07-25 17:24:35,854 : INFO : intent accuracy: 97.57142857142857\n","2020-07-25 17:24:35,857 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 17:24:35,860 : INFO : Test:\n","2020-07-25 17:24:39,042 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8660    0.9767    0.9180        86\n","           1     0.9630    1.0000    0.9811       104\n","           2     0.9889    0.9674    0.9780        92\n","           3     1.0000    0.9500    0.9744        80\n","           4     1.0000    0.8505    0.9192       107\n","           5     0.8500    0.9533    0.8987       107\n","           6     1.0000    0.9516    0.9752       124\n","\n","    accuracy                         0.9486       700\n","   macro avg     0.9525    0.9499    0.9492       700\n","weighted avg     0.9536    0.9486    0.9491       700\n","\n","2020-07-25 17:24:39,068 : INFO : slot f1: 79.09319899244332\n","2020-07-25 17:24:39,070 : INFO : intent accuracy: 94.85714285714286\n","2020-07-25 17:24:39,073 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n","2020-07-25 17:28:35,232 : INFO : Step: 13088\n","2020-07-25 17:28:35,234 : INFO : Epochs: 8\n","2020-07-25 17:28:35,235 : INFO : Slot Loss: 0.011097641927618054\n","2020-07-25 17:28:35,239 : INFO : Intent Loss: 0.001021456209307522\n","2020-07-25 17:28:35,242 : INFO : Valid:\n","2020-07-25 17:28:38,182 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9083    0.9900    0.9474       100\n","           1     0.9894    0.9300    0.9588       100\n","           2     0.9615    1.0000    0.9804       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     0.9583    0.9200    0.9388       100\n","           5     0.9490    0.9300    0.9394       100\n","           6     0.9898    0.9700    0.9798       100\n","\n","    accuracy                         0.9629       700\n","   macro avg     0.9638    0.9629    0.9628       700\n","weighted avg     0.9638    0.9629    0.9628       700\n","\n","2020-07-25 17:28:38,210 : INFO : slot f1: 80.0\n","2020-07-25 17:28:38,211 : INFO : intent accuracy: 96.28571428571429\n","2020-07-25 17:28:38,215 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 17:28:38,219 : INFO : Test:\n","2020-07-25 17:28:41,357 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8947    0.9884    0.9392        86\n","           1     1.0000    0.9615    0.9804       104\n","           2     0.9388    1.0000    0.9684        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9691    0.8785    0.9216       107\n","           5     0.8909    0.9159    0.9032       107\n","           6     1.0000    0.9758    0.9878       124\n","\n","    accuracy                         0.9557       700\n","   macro avg     0.9562    0.9582    0.9563       700\n","weighted avg     0.9576    0.9557    0.9558       700\n","\n","2020-07-25 17:28:41,386 : INFO : slot f1: 79.88748241912799\n","2020-07-25 17:28:41,387 : INFO : intent accuracy: 95.57142857142857\n","2020-07-25 17:28:41,392 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 17:32:33,689 : INFO : Step: 14724\n","2020-07-25 17:32:33,691 : INFO : Epochs: 9\n","2020-07-25 17:32:33,693 : INFO : Slot Loss: 0.00884121400528288\n","2020-07-25 17:32:33,695 : INFO : Intent Loss: 0.000688177663190327\n","2020-07-25 17:32:33,698 : INFO : Valid:\n","2020-07-25 17:32:36,657 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9434    1.0000    0.9709       100\n","           1     1.0000    0.9600    0.9796       100\n","           2     0.9899    0.9800    0.9849       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9691    0.9400    0.9543       100\n","           5     0.9612    0.9900    0.9754       100\n","           6     1.0000    0.9900    0.9950       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9805    0.9800    0.9800       700\n","weighted avg     0.9805    0.9800    0.9800       700\n","\n","2020-07-25 17:32:36,688 : INFO : slot f1: 81.06591865357643\n","2020-07-25 17:32:36,694 : INFO : intent accuracy: 98.0\n","2020-07-25 17:32:36,698 : INFO : semantic error(intent, slots are all correct): 52.57142857142857\n","2020-07-25 17:32:36,702 : INFO : Test:\n","2020-07-25 17:32:39,857 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.8947    0.9884    0.9392        86\n","           1     1.0000    0.9519    0.9754       104\n","           2     0.9787    1.0000    0.9892        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9604    0.9065    0.9327       107\n","           5     0.8929    0.9346    0.9132       107\n","           6     1.0000    0.9677    0.9836       124\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9610    0.9624    0.9610       700\n","weighted avg     0.9618    0.9600    0.9603       700\n","\n","2020-07-25 17:32:39,887 : INFO : slot f1: 79.7316186748672\n","2020-07-25 17:32:39,888 : INFO : intent accuracy: 96.0\n","2020-07-25 17:32:39,892 : INFO : semantic error(intent, slots are all correct): 54.0\n","2020-07-25 17:36:32,542 : INFO : Step: 16360\n","2020-07-25 17:36:32,544 : INFO : Epochs: 10\n","2020-07-25 17:36:32,548 : INFO : Slot Loss: 0.006772191201929682\n","2020-07-25 17:36:32,550 : INFO : Intent Loss: 0.0006073200187027488\n","2020-07-25 17:36:32,551 : INFO : Valid:\n","2020-07-25 17:36:35,748 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9800    0.9899       100\n","           1     0.9900    0.9900    0.9900       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     1.0000    0.9200    0.9583       100\n","           5     0.9259    1.0000    0.9615       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9843       700\n","   macro avg     0.9852    0.9843    0.9843       700\n","weighted avg     0.9852    0.9843    0.9843       700\n","\n","2020-07-25 17:36:35,777 : INFO : slot f1: 81.72345818079415\n","2020-07-25 17:36:35,778 : INFO : intent accuracy: 98.42857142857143\n","2020-07-25 17:36:35,782 : INFO : semantic error(intent, slots are all correct): 53.57142857142857\n","2020-07-25 17:36:35,785 : INFO : Test:\n","2020-07-25 17:36:38,969 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9880    0.9535    0.9704        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9684    1.0000    0.9840        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9897    0.8972    0.9412       107\n","           5     0.8898    0.9813    0.9333       107\n","           6     1.0000    0.9919    0.9960       124\n","\n","    accuracy                         0.9714       700\n","   macro avg     0.9738    0.9717    0.9720       700\n","weighted avg     0.9731    0.9714    0.9715       700\n","\n","2020-07-25 17:36:38,999 : INFO : slot f1: 80.38170081392084\n","2020-07-25 17:36:39,000 : INFO : intent accuracy: 97.14285714285714\n","2020-07-25 17:36:39,003 : INFO : semantic error(intent, slots are all correct): 54.0\n","2020-07-25 17:40:31,119 : INFO : Step: 17996\n","2020-07-25 17:40:31,120 : INFO : Epochs: 11\n","2020-07-25 17:40:31,123 : INFO : Slot Loss: 0.0058674756517382125\n","2020-07-25 17:40:31,126 : INFO : Intent Loss: 0.0005882671030455237\n","2020-07-25 17:40:31,129 : INFO : Valid:\n","2020-07-25 17:40:34,016 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9800    0.9899       100\n","           1     1.0000    0.9800    0.9899       100\n","           2     0.9804    1.0000    0.9901       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9703    0.9800    0.9751       100\n","           5     0.9800    0.9800    0.9800       100\n","           6     0.9901    1.0000    0.9950       100\n","\n","    accuracy                         0.9886       700\n","   macro avg     0.9887    0.9886    0.9886       700\n","weighted avg     0.9887    0.9886    0.9886       700\n","\n","2020-07-25 17:40:34,067 : INFO : slot f1: 81.22197309417041\n","2020-07-25 17:40:34,068 : INFO : intent accuracy: 98.85714285714286\n","2020-07-25 17:40:34,072 : INFO : semantic error(intent, slots are all correct): 53.142857142857146\n","2020-07-25 17:40:34,075 : INFO : Test:\n","2020-07-25 17:40:37,165 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9043    0.9884    0.9444        86\n","           1     0.9905    1.0000    0.9952       104\n","           2     0.9892    1.0000    0.9946        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     0.9808    0.9533    0.9668       107\n","           5     0.9619    0.9439    0.9528       107\n","           6     1.0000    0.9758    0.9878       124\n","\n","    accuracy                         0.9757       700\n","   macro avg     0.9752    0.9766    0.9756       700\n","weighted avg     0.9766    0.9757    0.9759       700\n","\n","2020-07-25 17:40:37,195 : INFO : slot f1: 80.02232142857143\n","2020-07-25 17:40:37,198 : INFO : intent accuracy: 97.57142857142857\n","2020-07-25 17:40:37,199 : INFO : semantic error(intent, slots are all correct): 53.57142857142857\n","2020-07-25 17:44:29,426 : INFO : Step: 19632\n","2020-07-25 17:44:29,427 : INFO : Epochs: 12\n","2020-07-25 17:44:29,431 : INFO : Slot Loss: 0.004965540246983311\n","2020-07-25 17:44:29,435 : INFO : Intent Loss: 0.0006147113002532562\n","2020-07-25 17:44:29,436 : INFO : Valid:\n","2020-07-25 17:44:32,379 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9800    0.9899       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     1.0000    0.9800    0.9899       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9238    0.9700    0.9463       100\n","           5     0.9694    0.9500    0.9596       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9805    0.9800    0.9801       700\n","weighted avg     0.9805    0.9800    0.9801       700\n","\n","2020-07-25 17:44:32,408 : INFO : slot f1: 80.88565022421525\n","2020-07-25 17:44:32,409 : INFO : intent accuracy: 98.0\n","2020-07-25 17:44:32,414 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 17:44:32,416 : INFO : Test:\n","2020-07-25 17:44:35,546 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9053    1.0000    0.9503        86\n","           1     0.9717    0.9904    0.9810       104\n","           2     1.0000    0.9674    0.9834        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     0.9099    0.9439    0.9266       107\n","           5     0.9490    0.8692    0.9073       107\n","           6     1.0000    0.9839    0.9919       124\n","\n","    accuracy                         0.9614       700\n","   macro avg     0.9623    0.9632    0.9620       700\n","weighted avg     0.9626    0.9614    0.9613       700\n","\n","2020-07-25 17:44:35,576 : INFO : slot f1: 80.3591470258137\n","2020-07-25 17:44:35,576 : INFO : intent accuracy: 96.14285714285714\n","2020-07-25 17:44:35,581 : INFO : semantic error(intent, slots are all correct): 53.85714285714286\n","2020-07-25 17:48:28,601 : INFO : Step: 21268\n","2020-07-25 17:48:28,603 : INFO : Epochs: 13\n","2020-07-25 17:48:28,604 : INFO : Slot Loss: 0.0056929048152534545\n","2020-07-25 17:48:28,609 : INFO : Intent Loss: 0.0006628821806034012\n","2020-07-25 17:48:28,612 : INFO : Valid:\n","2020-07-25 17:48:31,505 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9800    0.9899       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     0.9901    1.0000    0.9950       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9785    0.9100    0.9430       100\n","           5     0.9252    0.9900    0.9565       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9800       700\n","   macro avg     0.9806    0.9800    0.9799       700\n","weighted avg     0.9806    0.9800    0.9799       700\n","\n","2020-07-25 17:48:31,534 : INFO : slot f1: 81.09927089175545\n","2020-07-25 17:48:31,535 : INFO : intent accuracy: 98.0\n","2020-07-25 17:48:31,538 : INFO : semantic error(intent, slots are all correct): 53.142857142857146\n","2020-07-25 17:48:31,541 : INFO : Test:\n","2020-07-25 17:48:34,673 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9432    0.9651    0.9540        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9891    0.9891    0.9891        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     1.0000    0.9065    0.9510       107\n","           5     0.8957    0.9626    0.9279       107\n","           6     0.9919    0.9839    0.9879       124\n","\n","    accuracy                         0.9700       700\n","   macro avg     0.9715    0.9711    0.9708       700\n","weighted avg     0.9714    0.9700    0.9701       700\n","\n","2020-07-25 17:48:34,702 : INFO : slot f1: 80.79507278835386\n","2020-07-25 17:48:34,702 : INFO : intent accuracy: 97.0\n","2020-07-25 17:48:34,706 : INFO : semantic error(intent, slots are all correct): 53.85714285714286\n","2020-07-25 17:52:27,793 : INFO : Step: 22904\n","2020-07-25 17:52:27,794 : INFO : Epochs: 14\n","2020-07-25 17:52:27,795 : INFO : Slot Loss: 0.005465195752705827\n","2020-07-25 17:52:27,799 : INFO : Intent Loss: 0.0005109411572834174\n","2020-07-25 17:52:27,800 : INFO : Valid:\n","2020-07-25 17:52:30,731 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9802    0.9900    0.9851       100\n","           1     0.9703    0.9800    0.9751       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9889    0.8900    0.9368       100\n","           5     0.9091    1.0000    0.9524       100\n","           6     1.0000    0.9800    0.9899       100\n","\n","    accuracy                         0.9771       700\n","   macro avg     0.9784    0.9771    0.9770       700\n","weighted avg     0.9784    0.9771    0.9770       700\n","\n","2020-07-25 17:52:30,757 : INFO : slot f1: 81.28342245989306\n","2020-07-25 17:52:30,759 : INFO : intent accuracy: 97.71428571428571\n","2020-07-25 17:52:30,761 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 17:52:30,763 : INFO : Test:\n","2020-07-25 17:52:33,871 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9213    0.9535    0.9371        86\n","           1     0.9541    1.0000    0.9765       104\n","           2     1.0000    0.9891    0.9945        92\n","           3     1.0000    0.9750    0.9873        80\n","           4     1.0000    0.7850    0.8796       107\n","           5     0.8047    0.9626    0.8766       107\n","           6     1.0000    0.9758    0.9878       124\n","\n","    accuracy                         0.9471       700\n","   macro avg     0.9543    0.9487    0.9485       700\n","weighted avg     0.9537    0.9471    0.9472       700\n","\n","2020-07-25 17:52:33,901 : INFO : slot f1: 80.0224152423648\n","2020-07-25 17:52:33,902 : INFO : intent accuracy: 94.71428571428572\n","2020-07-25 17:52:33,903 : INFO : semantic error(intent, slots are all correct): 52.28571428571429\n","2020-07-25 17:56:26,116 : INFO : Step: 24540\n","2020-07-25 17:56:26,118 : INFO : Epochs: 15\n","2020-07-25 17:56:26,124 : INFO : Slot Loss: 0.003479027239825233\n","2020-07-25 17:56:26,125 : INFO : Intent Loss: 0.0005203490223280087\n","2020-07-25 17:56:26,125 : INFO : Valid:\n","2020-07-25 17:56:29,015 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9898    0.9700    0.9798       100\n","           1     1.0000    0.9800    0.9899       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     0.9709    1.0000    0.9852       100\n","           5     0.9898    0.9700    0.9798       100\n","           6     0.9804    1.0000    0.9901       100\n","\n","    accuracy                         0.9886       700\n","   macro avg     0.9887    0.9886    0.9885       700\n","weighted avg     0.9887    0.9886    0.9885       700\n","\n","2020-07-25 17:56:29,045 : INFO : slot f1: 80.30260577192492\n","2020-07-25 17:56:29,045 : INFO : intent accuracy: 98.85714285714286\n","2020-07-25 17:56:29,049 : INFO : semantic error(intent, slots are all correct): 51.57142857142857\n","2020-07-25 17:56:29,052 : INFO : Test:\n","2020-07-25 17:56:32,207 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9655    0.9767    0.9711        86\n","           1     0.9904    0.9904    0.9904       104\n","           2     0.9785    0.9891    0.9838        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9528    0.9439    0.9484       107\n","           5     0.9245    0.9159    0.9202       107\n","           6     1.0000    0.9919    0.9960       124\n","\n","    accuracy                         0.9714       700\n","   macro avg     0.9713    0.9726    0.9719       700\n","weighted avg     0.9714    0.9714    0.9714       700\n","\n","2020-07-25 17:56:32,235 : INFO : slot f1: 80.3361344537815\n","2020-07-25 17:56:32,239 : INFO : intent accuracy: 97.14285714285714\n","2020-07-25 17:56:32,241 : INFO : semantic error(intent, slots are all correct): 53.714285714285715\n","2020-07-25 18:00:27,387 : INFO : Step: 26176\n","2020-07-25 18:00:27,388 : INFO : Epochs: 16\n","2020-07-25 18:00:27,391 : INFO : Slot Loss: 0.004513938376915193\n","2020-07-25 18:00:27,392 : INFO : Intent Loss: 0.0005018502308101135\n","2020-07-25 18:00:27,393 : INFO : Valid:\n","2020-07-25 18:00:30,329 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9800    0.9800    0.9800       100\n","           1     1.0000    0.9800    0.9899       100\n","           2     0.9901    1.0000    0.9950       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     0.9798    0.9700    0.9749       100\n","           5     0.9804    1.0000    0.9901       100\n","           6     0.9899    0.9800    0.9849       100\n","\n","    accuracy                         0.9871       700\n","   macro avg     0.9872    0.9871    0.9871       700\n","weighted avg     0.9872    0.9871    0.9871       700\n","\n","2020-07-25 18:00:30,362 : INFO : slot f1: 80.76490438695163\n","2020-07-25 18:00:30,364 : INFO : intent accuracy: 98.71428571428571\n","2020-07-25 18:00:30,373 : INFO : semantic error(intent, slots are all correct): 52.0\n","2020-07-25 18:00:30,375 : INFO : Test:\n","2020-07-25 18:00:33,478 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9231    0.9767    0.9492        86\n","           1     0.9903    0.9808    0.9855       104\n","           2     0.9787    1.0000    0.9892        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     1.0000    0.8972    0.9458       107\n","           5     0.8870    0.9533    0.9189       107\n","           6     1.0000    0.9677    0.9836       124\n","\n","    accuracy                         0.9657       700\n","   macro avg     0.9667    0.9680    0.9666       700\n","weighted avg     0.9676    0.9657    0.9659       700\n","\n","2020-07-25 18:00:33,508 : INFO : slot f1: 80.12369974697779\n","2020-07-25 18:00:33,509 : INFO : intent accuracy: 96.57142857142857\n","2020-07-25 18:00:33,514 : INFO : semantic error(intent, slots are all correct): 52.57142857142857\n","2020-07-25 18:04:28,541 : INFO : Step: 27812\n","2020-07-25 18:04:28,543 : INFO : Epochs: 17\n","2020-07-25 18:04:28,546 : INFO : Slot Loss: 0.0036689660271424615\n","2020-07-25 18:04:28,549 : INFO : Intent Loss: 0.000521346566362312\n","2020-07-25 18:04:28,550 : INFO : Valid:\n","2020-07-25 18:04:31,545 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9691    0.9400    0.9543       100\n","           1     0.9703    0.9800    0.9751       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9794    0.9500    0.9645       100\n","           5     0.9434    1.0000    0.9709       100\n","           6     0.9899    0.9800    0.9849       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9789    0.9786    0.9785       700\n","weighted avg     0.9789    0.9786    0.9785       700\n","\n","2020-07-25 18:04:31,572 : INFO : slot f1: 81.16919617762788\n","2020-07-25 18:04:31,574 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 18:04:31,576 : INFO : semantic error(intent, slots are all correct): 53.142857142857146\n","2020-07-25 18:04:31,578 : INFO : Test:\n","2020-07-25 18:04:34,748 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9310    0.9419    0.9364        86\n","           1     0.9626    0.9904    0.9763       104\n","           2     0.9891    0.9891    0.9891        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     1.0000    0.8785    0.9353       107\n","           5     0.8607    0.9813    0.9170       107\n","           6     1.0000    0.9516    0.9752       124\n","\n","    accuracy                         0.9600       700\n","   macro avg     0.9633    0.9618    0.9613       700\n","weighted avg     0.9632    0.9600    0.9603       700\n","\n","2020-07-25 18:04:34,777 : INFO : slot f1: 80.02247822422028\n","2020-07-25 18:04:34,778 : INFO : intent accuracy: 96.0\n","2020-07-25 18:04:34,782 : INFO : semantic error(intent, slots are all correct): 52.142857142857146\n","2020-07-25 18:08:28,950 : INFO : Step: 29448\n","2020-07-25 18:08:28,951 : INFO : Epochs: 18\n","2020-07-25 18:08:28,953 : INFO : Slot Loss: 0.002061110192727603\n","2020-07-25 18:08:28,954 : INFO : Intent Loss: 0.0004300715296332933\n","2020-07-25 18:08:28,956 : INFO : Valid:\n","2020-07-25 18:08:31,905 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9505    0.9600    0.9552       100\n","           1     0.9898    0.9700    0.9798       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     1.0000    1.0000    1.0000       100\n","           4     0.9697    0.9600    0.9648       100\n","           5     0.9709    1.0000    0.9852       100\n","           6     0.9697    0.9600    0.9648       100\n","\n","    accuracy                         0.9786       700\n","   macro avg     0.9787    0.9786    0.9786       700\n","weighted avg     0.9787    0.9786    0.9786       700\n","\n","2020-07-25 18:08:31,930 : INFO : slot f1: 80.92420400112708\n","2020-07-25 18:08:31,932 : INFO : intent accuracy: 97.85714285714285\n","2020-07-25 18:08:31,934 : INFO : semantic error(intent, slots are all correct): 52.714285714285715\n","2020-07-25 18:08:31,936 : INFO : Test:\n","2020-07-25 18:08:35,110 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9333    0.9767    0.9545        86\n","           1     0.9717    0.9904    0.9810       104\n","           2     0.9891    0.9891    0.9891        92\n","           3     0.9877    1.0000    0.9938        80\n","           4     0.9897    0.8972    0.9412       107\n","           5     0.8783    0.9439    0.9099       107\n","           6     1.0000    0.9597    0.9794       124\n","\n","    accuracy                         0.9629       700\n","   macro avg     0.9643    0.9653    0.9641       700\n","weighted avg     0.9646    0.9629    0.9630       700\n","\n","2020-07-25 18:08:35,139 : INFO : slot f1: 80.03369839932603\n","2020-07-25 18:08:35,140 : INFO : intent accuracy: 96.28571428571429\n","2020-07-25 18:08:35,141 : INFO : semantic error(intent, slots are all correct): 52.42857142857142\n","2020-07-25 18:12:30,716 : INFO : Step: 31084\n","2020-07-25 18:12:30,718 : INFO : Epochs: 19\n","2020-07-25 18:12:30,719 : INFO : Slot Loss: 0.0033928790286039735\n","2020-07-25 18:12:30,720 : INFO : Intent Loss: 0.0005550680617460517\n","2020-07-25 18:12:30,723 : INFO : Valid:\n","2020-07-25 18:12:33,659 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9796    0.9600    0.9697       100\n","           1     0.9899    0.9800    0.9849       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     0.9804    1.0000    0.9901       100\n","           4     0.9794    0.9500    0.9645       100\n","           5     0.9802    0.9900    0.9851       100\n","           6     0.9709    1.0000    0.9852       100\n","\n","    accuracy                         0.9829       700\n","   macro avg     0.9829    0.9829    0.9828       700\n","weighted avg     0.9829    0.9829    0.9828       700\n","\n","2020-07-25 18:12:33,685 : INFO : slot f1: 81.61081385525205\n","2020-07-25 18:12:33,687 : INFO : intent accuracy: 98.28571428571429\n","2020-07-25 18:12:33,689 : INFO : semantic error(intent, slots are all correct): 52.85714285714286\n","2020-07-25 18:12:33,690 : INFO : Test:\n","2020-07-25 18:12:36,829 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9432    0.9651    0.9540        86\n","           1     0.9810    0.9904    0.9856       104\n","           2     0.9891    0.9891    0.9891        92\n","           3     1.0000    1.0000    1.0000        80\n","           4     1.0000    0.9439    0.9712       107\n","           5     0.9364    0.9626    0.9493       107\n","           6     0.9919    0.9919    0.9919       124\n","\n","    accuracy                         0.9771       700\n","   macro avg     0.9774    0.9776    0.9773       700\n","weighted avg     0.9776    0.9771    0.9772       700\n","\n","2020-07-25 18:12:36,861 : INFO : slot f1: 81.54627539503386\n","2020-07-25 18:12:36,862 : INFO : intent accuracy: 97.71428571428571\n","2020-07-25 18:12:36,867 : INFO : semantic error(intent, slots are all correct): 54.57142857142857\n","2020-07-25 18:16:32,313 : INFO : Step: 32720\n","2020-07-25 18:16:32,314 : INFO : Epochs: 20\n","2020-07-25 18:16:32,317 : INFO : Slot Loss: 0.0032937556027109512\n","2020-07-25 18:16:32,319 : INFO : Intent Loss: 0.0004714189867080196\n","2020-07-25 18:16:32,322 : INFO : Valid:\n","2020-07-25 18:16:35,293 : INFO :               precision    recall  f1-score   support\n","\n","           0     1.0000    0.9600    0.9796       100\n","           1     1.0000    0.9800    0.9899       100\n","           2     1.0000    1.0000    1.0000       100\n","           3     0.9901    1.0000    0.9950       100\n","           4     0.9796    0.9600    0.9697       100\n","           5     0.9615    1.0000    0.9804       100\n","           6     0.9709    1.0000    0.9852       100\n","\n","    accuracy                         0.9857       700\n","   macro avg     0.9860    0.9857    0.9857       700\n","weighted avg     0.9860    0.9857    0.9857       700\n","\n","2020-07-25 18:16:35,319 : INFO : slot f1: 80.40144967939783\n","2020-07-25 18:16:35,321 : INFO : intent accuracy: 98.57142857142858\n","2020-07-25 18:16:35,322 : INFO : semantic error(intent, slots are all correct): 53.142857142857146\n","2020-07-25 18:16:35,325 : INFO : Test:\n","2020-07-25 18:16:38,515 : INFO :               precision    recall  f1-score   support\n","\n","           0     0.9545    0.9767    0.9655        86\n","           1     0.9904    0.9904    0.9904       104\n","           2     0.9892    1.0000    0.9946        92\n","           3     1.0000    0.9875    0.9937        80\n","           4     1.0000    0.8785    0.9353       107\n","           5     0.8718    0.9533    0.9107       107\n","           6     0.9920    1.0000    0.9960       124\n","\n","    accuracy                         0.9686       700\n","   macro avg     0.9711    0.9695    0.9695       700\n","weighted avg     0.9706    0.9686    0.9687       700\n","\n","2020-07-25 18:16:38,540 : INFO : slot f1: 80.82114735658044\n","2020-07-25 18:16:38,543 : INFO : intent accuracy: 96.85714285714285\n","2020-07-25 18:16:38,544 : INFO : semantic error(intent, slots are all correct): 53.42857142857142\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NiT9DJaWPYFB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595701000446,"user_tz":-330,"elapsed":28,"user":{"displayName":"Archna Bharti","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi_EajrjxYIKV0T5BEsM1T9bI7DeVW_8aGPnT0ziA=s64","userId":"16992543996356656925"}}},"source":[""],"execution_count":8,"outputs":[]}]}